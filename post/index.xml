<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Gertjan Verhoeven</title>
    <link>/post/</link>
    <description>Recent content in Posts on Gertjan Verhoeven</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0100</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Designing an introductory course on Causal Inference</title>
      <link>/post/causal-inference-course/</link>
      <pubDate>Sat, 11 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/causal-inference-course/</guid>
      <description>Introduction(Short intro) This is me learning causal inference (CI) by self-study together with colleagues using online resources.
(Longer intro) A modern data scientist needs to become skilled in at least three topics (I left out visualization):
(Bayesian) Statistical modelingMachine LearningCausal inferenceFor the first two topics, great introductory books exist that
focus on learning-by-doing andare low on math and high on simulation / programming in Rare fun / well writtenFor Bayesian statistical modeling, we have the awesome textbook “Statistical Rethinking” by Richard mcElreath.</description>
    </item>
    
    <item>
      <title>The validation set approach in caret</title>
      <link>/post/validation-set-approach-in-caret/</link>
      <pubDate>Thu, 21 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/validation-set-approach-in-caret/</guid>
      <description>In this blog post, we explore how to implement the validation set approach in caret. This is the most basic form of the train/test machine learning concept. For example, the classic machine learning textbook “An introduction to Statistical Learning” uses the validation set approach to introduce resampling methods.
In practice, one likes to use k-fold Cross validation, or Leave-one-out cross validation, as they make better use of the data. This is probably the reason that the validation set approach is not one of caret’s preset methods.</description>
    </item>
    
    <item>
      <title>Arduino Weather Station with datalogging</title>
      <link>/post/arduino-atmospheric-datalogger/</link>
      <pubDate>Tue, 05 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/arduino-atmospheric-datalogger/</guid>
      <description>In this post, I show how to create a Arduino-based atmospheric sensor circuit capable of storing large amounts of data on a microSD card.
Nowadays, one can buy a commercial Thermo/Hygro datalogger for 50 Euro online (i.e. https://www.vitalitools.nl/lascar-electronics-el-usb-2-datalogger). However, I decided that it would be a nice project to learn more about Arduino, in particular how to interface it with a microSD card. So i made one myself. Working with SD cards has the advantage of having a huge storage capacity.</description>
    </item>
    
    <item>
      <title>Exploring Process Mining in R</title>
      <link>/post/exploring-process-mining/</link>
      <pubDate>Wed, 23 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/exploring-process-mining/</guid>
      <description>In this post, we’ll explore the BupaR suite of Process Mining packages created by Jan Wijffels. After installing all required packages, we can load the whole “bupaverse” by loading the bupaR package.
We start with exploring the patients dataset contained in the eventdataR package.
library(bupaR)df &amp;lt;- eventdataR::patientsstr(df)## Classes &amp;#39;eventlog&amp;#39;, &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;: 5442 obs. of 7 variables:## $ handling : Factor w/ 7 levels &amp;quot;Blood test&amp;quot;,&amp;quot;Check-out&amp;quot;,.</description>
    </item>
    
    <item>
      <title>BART vs Causal forests showdown</title>
      <link>/post/bart_vs_grf/bart-vs-grf-showdown/</link>
      <pubDate>Sat, 15 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/bart_vs_grf/bart-vs-grf-showdown/</guid>
      <description>Load packages# library(devtools)#devtools::install_github(&amp;quot;vdorie/dbarts&amp;quot;)library(dbarts)library(ggplot2)library(tidyverse)## -- Attaching packages ------------------------------------------------------------- tidyverse 1.2.1 --## v tibble 2.0.1 v purrr 0.2.5## v tidyr 0.8.2 v dplyr 0.7.8## v readr 1.3.1 v stringr 1.3.1## v tibble 2.0.1 v forcats 0.3.0## -- Conflicts ---------------------------------------------------------------- tidyverse_conflicts() --## x dplyr::filter() masks stats::filter()## x dplyr::lag() masks stats::lag()library(grf)#devtools::install_github(&amp;quot;vdorie/aciccomp/2017&amp;quot;)library(aciccomp2017)library(cowplot)## ## Attaching package: &amp;#39;cowplot&amp;#39;## The following object is masked from &amp;#39;package:ggplot2&amp;#39;:## ## ggsavesource(&amp;quot;calcPosteriors.</description>
    </item>
    
    <item>
      <title>Improving a parametric regression model using machine learning</title>
      <link>/post/interaction_detection/interaction-detection/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/interaction_detection/interaction-detection/</guid>
      <description>The idea is that comparing the predictions of an RF model with the predictions of an OLS model can inform us in what ways the OLS model fails to capture all non-linearities and interactions between the predictors. Subsequently, using partial dependence plots of the RF model can guide the modelling of the non-linearities in the OLS model. After this step, the discrepancies between the RF predictions and the OLS predictions should be caused by non-modeled interactions.</description>
    </item>
    
  </channel>
</rss>