<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data science | Gertjan Verhoeven</title>
    <link>/categories/data-science/</link>
      <atom:link href="/categories/data-science/index.xml" rel="self" type="application/rss+xml" />
    <description>Data science</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2019-2022</copyright><lastBuildDate>Thu, 25 Jul 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Data science</title>
      <link>/categories/data-science/</link>
    </image>
    
    <item>
      <title>Introducing the fumbbl_replays Python package for Blood Bowl</title>
      <link>/post/fumbbl-replays/</link>
      <pubDate>Thu, 25 Jul 2024 00:00:00 +0000</pubDate>
      <guid>/post/fumbbl-replays/</guid>
      <description>


&lt;p&gt;The &lt;code&gt;fumbbl_replays&lt;/code&gt; package is a Python utility package for the board game Blood Bowl.
It allows users to plot board positions, either from scratch, or from existing (FUMBBL) game logs.
In addition, it has some functionality to analyze FUMBBL game logs.&lt;/p&gt;
&lt;p&gt;On the FUMBBL website, a lot of high quality replay data is available as well as an API to conveniently fetch the data.
In addition, the API provides up to date roster information.
To do useful analyses (aka nufflytics) in Python with this data, we need a utility package / library.
In R, a similar package exists to work with BB2 replays [&lt;a href=&#34;https://github.com/nufflytics/nufflytics&#34; class=&#34;uri&#34;&gt;https://github.com/nufflytics/nufflytics&lt;/a&gt;].
For BB3 replay files, work is ongoing to process them, with a &lt;a href=&#34;https://github.com/tagsemb/bbrdecode&#34;&gt;proof-of-concept example C# Github repo available&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We also need a standard way to describe Blood Bowl games in a compact way, that is both human and machine readable.
In chess, there is the &lt;strong&gt;Portable Game Notation (PGN)&lt;/strong&gt;. PGN has become the de facto standard of describing Chess games.
For Blood Bowl, already in 2002 some work has been done towards this end. David Morgan-Mar developed a notation for the purpose of sharing Blood Bowl game logs over the internet. [&lt;a href=&#34;https://www.dangermouse.net/games/bloodbowl/rules.html&#34; class=&#34;uri&#34;&gt;https://www.dangermouse.net/games/bloodbowl/rules.html&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;If we could converge on a standard &lt;strong&gt;Fantasy Football Game Notation (FFGN)&lt;/strong&gt;, it would serve many purposes, e.g.:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It would allow us to interchange data between software&lt;/li&gt;
&lt;li&gt;it would help to train AI engines.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So the package is being developed with this end goal in mind. As Blood Bowl is a much complexer game than Chess, and I am an amateur programmer, we need some intermediate goals that bring us closer to the end goal. Thus, I started with plotting (new or extracted) board positions using a short hand notation for board pieces (players) and codifying player moves. While developing the package, I benefited greatly from discussions and feedback on the &lt;a href=&#34;https://discord.gg/MTXMuae&#34;&gt;Bot bowl discord forum&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;%pip install -e . --quiet&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;plotting-blood-bowl-board-positions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Plotting Blood Bowl board positions&lt;/h1&gt;
&lt;p&gt;If we want to describe (codify) a Blood Bowl board state, we need to describe the pieces (what type of player is it, what extra skills does it have), the location of the pieces as well as the “state” of the pieces. Player state in Blood Bowl can be either standing, prone, or stunned, and can be in various special states such as “Bone head”, “Rooted”, “Hypnotized” etc.
(A full game state also contains additional information on rerolls, players on the bench etc. This is not yet implemented)&lt;/p&gt;
&lt;p&gt;Let’s start with the location of the pieces. A grid reference system is needed.
The game board of Blood Bowl has dimensions 15 x 26.
It has cognitive benefit to use numbers for one dimension, and letters for the other dimensions. Fancy word: alphanumeric.
Chess over the centuries has had various notations, and this notation is the one that became universally accepted.
[&lt;a href=&#34;https://en.wikipedia.org/wiki/Algebraic_notation_(chess)&#34; class=&#34;uri&#34;&gt;https://en.wikipedia.org/wiki/Algebraic_notation_(chess)&lt;/a&gt;]
The only choice left for us is then, which axis should have letters, and which axis should have the numbers.&lt;/p&gt;
&lt;p&gt;A strong argument was made on the BotBowl discord that distance to the end zone is very important in BB.
By using numbers for the long axis, we can easily deduce that a Gutter Runner at position c15 is in scoring position: It needs 11 movement to score a touchdown at c26.
This notation is also used by Cow Daddy Gaming in his “What´s the play” puzzles.&lt;/p&gt;
&lt;p&gt;I wrote a function &lt;code&gt;show_boardpos()&lt;/code&gt; that displays the name of all the board positions.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import fumbbl_replays as fb

fb.show_boardpos(rotation = &amp;#39;H&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-08-01_fumbbl_replays_files/fumbbl_replays_3_0.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now we need a way to describe the playing pieces, and visualize them. In chess it is easy, there are only six different ones.
In Blood Bowl, there are roughly 200 different playing pieces (30 teams, times 5 positionals, plus 50+ star players).
Here the concept of a roster can help us out.
I wrote a function &lt;code&gt;fetch_roster()&lt;/code&gt; that fetches rosters from FUMBBL and displays the positions.
It also contains links to icons that can represent the piece on the board.&lt;/p&gt;
&lt;p&gt;Take for example the High Elf roster.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;roster = fb.fetch_roster(&amp;quot;High Elf&amp;quot;)
roster&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
&lt;thead&gt;
&lt;tr style=&#34;text-align: right;&#34;&gt;
&lt;th&gt;
&lt;/th&gt;
&lt;th&gt;
positionId
&lt;/th&gt;
&lt;th&gt;
positionName
&lt;/th&gt;
&lt;th&gt;
skillArray
&lt;/th&gt;
&lt;th&gt;
shorthand
&lt;/th&gt;
&lt;th&gt;
icon_path
&lt;/th&gt;
&lt;th&gt;
race
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;
0
&lt;/th&gt;
&lt;td&gt;
39330
&lt;/td&gt;
&lt;td&gt;
Lineman
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
L
&lt;/td&gt;
&lt;td&gt;
&lt;a href=&#34;https://fumbbl.com/i/585638.png&#34; class=&#34;uri&#34;&gt;https://fumbbl.com/i/585638.png&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;
High Elf
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
1
&lt;/th&gt;
&lt;td&gt;
39331
&lt;/td&gt;
&lt;td&gt;
Thrower
&lt;/td&gt;
&lt;td&gt;
[Cloud Burster, Pass, Safe Pass]
&lt;/td&gt;
&lt;td&gt;
T
&lt;/td&gt;
&lt;td&gt;
&lt;a href=&#34;https://fumbbl.com/i/436284.png&#34; class=&#34;uri&#34;&gt;https://fumbbl.com/i/436284.png&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;
High Elf
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
2
&lt;/th&gt;
&lt;td&gt;
39332
&lt;/td&gt;
&lt;td&gt;
Catcher
&lt;/td&gt;
&lt;td&gt;
[Catch]
&lt;/td&gt;
&lt;td&gt;
C
&lt;/td&gt;
&lt;td&gt;
&lt;a href=&#34;https://fumbbl.com/i/585639.png&#34; class=&#34;uri&#34;&gt;https://fumbbl.com/i/585639.png&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;
High Elf
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
3
&lt;/th&gt;
&lt;td&gt;
39333
&lt;/td&gt;
&lt;td&gt;
Blitzer
&lt;/td&gt;
&lt;td&gt;
[Block]
&lt;/td&gt;
&lt;td&gt;
Z
&lt;/td&gt;
&lt;td&gt;
&lt;a href=&#34;https://fumbbl.com/i/436286.png&#34; class=&#34;uri&#34;&gt;https://fumbbl.com/i/436286.png&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;
High Elf
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;It has four different pieces or “positionals”. It turns out that FUMBBL has already solved our problem of denoting them, introducing a shorthand text reference.
So if we want to describe some action involving a High Elf Catcher, and there are four of them on the board, we could denote them by C1, C2, C3 and C4.
This is compact, and has meaning within the context of the High Elf roster.&lt;/p&gt;
&lt;p&gt;If we combine the descriptions of the pieces, and their location, we have enough to describe for example an initial setup formation before kick-off.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;my_setup = [&amp;#39;setup&amp;#39;, [&amp;#39;L1: g13&amp;#39;, &amp;#39;L2: h13&amp;#39;, &amp;#39;L3: i13&amp;#39;, &amp;#39;Z1: c11&amp;#39;, &amp;#39;Z2: m11&amp;#39;, &amp;#39;T1: h6&amp;#39;, &amp;#39;L4: e11&amp;#39;, 
                      &amp;#39;L5: k11&amp;#39;, &amp;#39;C1: l10&amp;#39;, &amp;#39;C2: d10&amp;#39;, &amp;#39;L6: h11&amp;#39;]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I wrote a function &lt;code&gt;create_position()&lt;/code&gt; that combines the roster and the setup annotation to create an object that contains all the information to make a nice plot of the board state. The function &lt;code&gt;print_position()&lt;/code&gt; prints a nicely formatted summary of the position.
As default, a position is created for the home team, denoted as “teamHome”.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;positions = fb.create_position(roster, my_setup)
fb.print_position(positions)&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
&lt;thead&gt;
&lt;tr style=&#34;text-align: right;&#34;&gt;
&lt;th&gt;
&lt;/th&gt;
&lt;th&gt;
home_away
&lt;/th&gt;
&lt;th&gt;
race
&lt;/th&gt;
&lt;th&gt;
short_name
&lt;/th&gt;
&lt;th&gt;
positionName
&lt;/th&gt;
&lt;th&gt;
boardpos
&lt;/th&gt;
&lt;th&gt;
PlayerState
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;
5
&lt;/th&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
High Elf
&lt;/td&gt;
&lt;td&gt;
T1
&lt;/td&gt;
&lt;td&gt;
Thrower
&lt;/td&gt;
&lt;td&gt;
h6
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
9
&lt;/th&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
High Elf
&lt;/td&gt;
&lt;td&gt;
C2
&lt;/td&gt;
&lt;td&gt;
Catcher
&lt;/td&gt;
&lt;td&gt;
d10
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
8
&lt;/th&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
High Elf
&lt;/td&gt;
&lt;td&gt;
C1
&lt;/td&gt;
&lt;td&gt;
Catcher
&lt;/td&gt;
&lt;td&gt;
l10
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
3
&lt;/th&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
High Elf
&lt;/td&gt;
&lt;td&gt;
Z1
&lt;/td&gt;
&lt;td&gt;
Blitzer
&lt;/td&gt;
&lt;td&gt;
c11
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
6
&lt;/th&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
High Elf
&lt;/td&gt;
&lt;td&gt;
L4
&lt;/td&gt;
&lt;td&gt;
Lineman
&lt;/td&gt;
&lt;td&gt;
e11
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
10
&lt;/th&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
High Elf
&lt;/td&gt;
&lt;td&gt;
L6
&lt;/td&gt;
&lt;td&gt;
Lineman
&lt;/td&gt;
&lt;td&gt;
h11
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
7
&lt;/th&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
High Elf
&lt;/td&gt;
&lt;td&gt;
L5
&lt;/td&gt;
&lt;td&gt;
Lineman
&lt;/td&gt;
&lt;td&gt;
k11
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
4
&lt;/th&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
High Elf
&lt;/td&gt;
&lt;td&gt;
Z2
&lt;/td&gt;
&lt;td&gt;
Blitzer
&lt;/td&gt;
&lt;td&gt;
m11
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
0
&lt;/th&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
High Elf
&lt;/td&gt;
&lt;td&gt;
L1
&lt;/td&gt;
&lt;td&gt;
Lineman
&lt;/td&gt;
&lt;td&gt;
g13
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
1
&lt;/th&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
High Elf
&lt;/td&gt;
&lt;td&gt;
L2
&lt;/td&gt;
&lt;td&gt;
Lineman
&lt;/td&gt;
&lt;td&gt;
h13
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
2
&lt;/th&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
High Elf
&lt;/td&gt;
&lt;td&gt;
L3
&lt;/td&gt;
&lt;td&gt;
Lineman
&lt;/td&gt;
&lt;td&gt;
i13
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;Let’s suppose that the High Elf team is playing against a Gnome team. Let’s also fetch a Gnome roster and create a board position on the other half of the pitch.
As we already have a home team, we refer to this team as “teamAway”.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;roster = fb.fetch_roster(&amp;quot;Gnome&amp;quot;)
roster&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
&lt;thead&gt;
&lt;tr style=&#34;text-align: right;&#34;&gt;
&lt;th&gt;
&lt;/th&gt;
&lt;th&gt;
positionId
&lt;/th&gt;
&lt;th&gt;
positionName
&lt;/th&gt;
&lt;th&gt;
skillArray
&lt;/th&gt;
&lt;th&gt;
shorthand
&lt;/th&gt;
&lt;th&gt;
icon_path
&lt;/th&gt;
&lt;th&gt;
race
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;
0
&lt;/th&gt;
&lt;td&gt;
57706
&lt;/td&gt;
&lt;td&gt;
Altern Forest Treeman
&lt;/td&gt;
&lt;td&gt;
[Mighty Blow (+1), Stand Firm, Strong Arm, Thi…
&lt;/td&gt;
&lt;td&gt;
T
&lt;/td&gt;
&lt;td&gt;
&lt;a href=&#34;https://fumbbl.com/i/733781.png&#34; class=&#34;uri&#34;&gt;https://fumbbl.com/i/733781.png&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
1
&lt;/th&gt;
&lt;td&gt;
57707
&lt;/td&gt;
&lt;td&gt;
Gnome Beastmaster
&lt;/td&gt;
&lt;td&gt;
[Jump Up, Wrestle, Guard, Stunty]
&lt;/td&gt;
&lt;td&gt;
B
&lt;/td&gt;
&lt;td&gt;
&lt;a href=&#34;https://fumbbl.com/i/735006.png&#34; class=&#34;uri&#34;&gt;https://fumbbl.com/i/735006.png&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
2
&lt;/th&gt;
&lt;td&gt;
57708
&lt;/td&gt;
&lt;td&gt;
Gnome Illusionist
&lt;/td&gt;
&lt;td&gt;
[Jump Up, Wrestle, Stunty, Trickster]
&lt;/td&gt;
&lt;td&gt;
I
&lt;/td&gt;
&lt;td&gt;
&lt;a href=&#34;https://fumbbl.com/i/735007.png&#34; class=&#34;uri&#34;&gt;https://fumbbl.com/i/735007.png&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
3
&lt;/th&gt;
&lt;td&gt;
57709
&lt;/td&gt;
&lt;td&gt;
Woodland Fox
&lt;/td&gt;
&lt;td&gt;
[Dodge, Side Step, Stunty, My Ball]
&lt;/td&gt;
&lt;td&gt;
F
&lt;/td&gt;
&lt;td&gt;
&lt;a href=&#34;https://fumbbl.com/i/735008.png&#34; class=&#34;uri&#34;&gt;https://fumbbl.com/i/735008.png&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
4
&lt;/th&gt;
&lt;td&gt;
57710
&lt;/td&gt;
&lt;td&gt;
Gnome Lineman
&lt;/td&gt;
&lt;td&gt;
[Jump Up, Wrestle, Right Stuff, Stunty]
&lt;/td&gt;
&lt;td&gt;
L
&lt;/td&gt;
&lt;td&gt;
&lt;a href=&#34;https://fumbbl.com/i/735009.png&#34; class=&#34;uri&#34;&gt;https://fumbbl.com/i/735009.png&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;my_setup = [&amp;#39;setup&amp;#39;, [&amp;#39;T2: j14&amp;#39;, &amp;#39;T1: f14&amp;#39;, &amp;#39;F1: h20&amp;#39;, &amp;#39;I1: b14&amp;#39;, &amp;#39;I2: n14&amp;#39;, &amp;#39;L3: e14&amp;#39;, &amp;#39;L6: k14&amp;#39;, 
                      &amp;#39;B2: m15&amp;#39;, &amp;#39;B1: c15&amp;#39;, &amp;#39;L4: g15&amp;#39;, &amp;#39;F2: i16&amp;#39;]]

positions2 = fb.create_position(roster, my_setup, &amp;#39;teamAway&amp;#39;)

fb.print_position(positions2)&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
&lt;thead&gt;
&lt;tr style=&#34;text-align: right;&#34;&gt;
&lt;th&gt;
&lt;/th&gt;
&lt;th&gt;
home_away
&lt;/th&gt;
&lt;th&gt;
race
&lt;/th&gt;
&lt;th&gt;
short_name
&lt;/th&gt;
&lt;th&gt;
positionName
&lt;/th&gt;
&lt;th&gt;
boardpos
&lt;/th&gt;
&lt;th&gt;
PlayerState
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;
3
&lt;/th&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
I1
&lt;/td&gt;
&lt;td&gt;
Gnome Illusionist
&lt;/td&gt;
&lt;td&gt;
b14
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
5
&lt;/th&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
L3
&lt;/td&gt;
&lt;td&gt;
Gnome Lineman
&lt;/td&gt;
&lt;td&gt;
e14
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
1
&lt;/th&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
T1
&lt;/td&gt;
&lt;td&gt;
Altern Forest Treeman
&lt;/td&gt;
&lt;td&gt;
f14
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
0
&lt;/th&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
T2
&lt;/td&gt;
&lt;td&gt;
Altern Forest Treeman
&lt;/td&gt;
&lt;td&gt;
j14
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
6
&lt;/th&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
L6
&lt;/td&gt;
&lt;td&gt;
Gnome Lineman
&lt;/td&gt;
&lt;td&gt;
k14
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
4
&lt;/th&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
I2
&lt;/td&gt;
&lt;td&gt;
Gnome Illusionist
&lt;/td&gt;
&lt;td&gt;
n14
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
8
&lt;/th&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
B1
&lt;/td&gt;
&lt;td&gt;
Gnome Beastmaster
&lt;/td&gt;
&lt;td&gt;
c15
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
9
&lt;/th&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
L4
&lt;/td&gt;
&lt;td&gt;
Gnome Lineman
&lt;/td&gt;
&lt;td&gt;
g15
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
7
&lt;/th&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
B2
&lt;/td&gt;
&lt;td&gt;
Gnome Beastmaster
&lt;/td&gt;
&lt;td&gt;
m15
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
10
&lt;/th&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
F2
&lt;/td&gt;
&lt;td&gt;
Woodland Fox
&lt;/td&gt;
&lt;td&gt;
i16
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
2
&lt;/th&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
F1
&lt;/td&gt;
&lt;td&gt;
Woodland Fox
&lt;/td&gt;
&lt;td&gt;
h20
&lt;/td&gt;
&lt;td&gt;
Standing
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;As a final step before plotting, we add both positions together.
As both are &lt;code&gt;pandas&lt;/code&gt; DataFrames, we use the &lt;code&gt;concat()&lt;/code&gt; function from &lt;code&gt;pandas&lt;/code&gt; to combine (“concatenate”) them.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import pandas as pd

positions = pd.concat([positions, positions2])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function &lt;code&gt;create_plot()&lt;/code&gt; plots the board position.
By default, it plots a horizontal pitch, with the team denoted as “teamHome” in red, and the other team in blue.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;fb.create_plot(positions)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-08-01_fumbbl_replays_files/fumbbl_replays_17_0.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;create_plot()&lt;/code&gt; function allows us the swap the color of the teams, to change the pitch orientation to vertical, and to add a layer of semi-transparant tacklezones.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;fb.create_plot(positions, red_team = &amp;quot;teamAway&amp;quot;, orientation = &amp;#39;V&amp;#39;, tackle_zones = True)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-08-01_fumbbl_replays_files/fumbbl_replays_19_0.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The library also support moving single pieces (players). It currently only works for pieces that already exist in a board position.
In the plot above, suppose we want to move the Woodland Fox F1 to board position &lt;code&gt;o26&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;positions = fb.move_piece(positions, &amp;quot;teamAway&amp;quot;, &amp;quot;F1&amp;quot;, &amp;quot;o26&amp;quot;)

fb.create_plot(positions, red_team = &amp;quot;teamAway&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-08-01_fumbbl_replays_files/fumbbl_replays_21_0.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Each player also has an associated &lt;code&gt;PlayerState&lt;/code&gt;. This can either be &lt;code&gt;Standing&lt;/code&gt; (the default), &lt;code&gt;HasBall&lt;/code&gt;, &lt;code&gt;Prone&lt;/code&gt; or &lt;code&gt;Stunned&lt;/code&gt;.
The function &lt;code&gt;set_piece_state()&lt;/code&gt; allows to set this for individual players:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;positions = fb.set_piece_state(positions, &amp;quot;teamAway&amp;quot;, &amp;quot;F1&amp;quot;, &amp;quot;HasBall&amp;quot;)
positions = fb.set_piece_state(positions, &amp;quot;teamHome&amp;quot;, &amp;quot;T1&amp;quot;, &amp;quot;Prone&amp;quot;)
positions = fb.set_piece_state(positions, &amp;quot;teamAway&amp;quot;, &amp;quot;B1&amp;quot;, &amp;quot;Stunned&amp;quot;)

fb.create_plot(positions, red_team = &amp;quot;teamAway&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-08-01_fumbbl_replays_files/fumbbl_replays_23_0.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The compact setup description can also describe player states other than standing.
&lt;code&gt;/&lt;/code&gt; is Prone, &lt;code&gt;X&lt;/code&gt; denotes stunned. &lt;code&gt;o&lt;/code&gt; denotes a player that has the ball.&lt;/p&gt;
&lt;p&gt;The compact description for the Gnome position plotted above can be obtained using &lt;code&gt;get_position()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;fb.get_position(positions, home_away = &amp;#39;teamAway&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[&amp;#39;setup&amp;#39;, [&amp;#39;T2: j14&amp;#39;, &amp;#39;T1: f14&amp;#39;, &amp;#39;F1: o26o&amp;#39;, &amp;#39;I1: b14&amp;#39;, &amp;#39;I2: n14&amp;#39;, &amp;#39;L3: e14&amp;#39;, &amp;#39;L6: k14&amp;#39;, &amp;#39;B2: m15&amp;#39;, &amp;#39;B1: c15X&amp;#39;, &amp;#39;L4: g15&amp;#39;, &amp;#39;F2: i16&amp;#39;]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note the notation for Fox F1 with the ball (&lt;code&gt;F1: o26o&lt;/code&gt;) and the notation for the stunned Beastmaster B1 (&lt;code&gt;B1: c15X&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;As the &lt;code&gt;positions&lt;/code&gt; object is a table of players, I added an extra argument to &lt;code&gt;create_plot()&lt;/code&gt; to plot a free ball.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;fb.create_plot(positions, red_team = &amp;quot;teamAway&amp;quot;, ballpos = &amp;#39;e5&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-08-01_fumbbl_replays_files/fumbbl_replays_27_0.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Star players can also be plotted. For this we need to fetch a separate star player “roster” and add it to the team roster.
Lets add Rowana Forestfoot (“RF”) and Rodney Roachbait (“RR”) to the Gnome setup, replacing Gnome linemen L3 and L6.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;positions = positions.query(&amp;#39;home_away == &amp;quot;teamHome&amp;quot;&amp;#39;)

roster = fb.fetch_roster(&amp;quot;Gnome&amp;quot;)
stars = fb.fetch_stars()
roster = pd.concat([roster, stars])

my_setup = [&amp;#39;setup&amp;#39;, [&amp;#39;T2: j14&amp;#39;, &amp;#39;T1: f14&amp;#39;, &amp;#39;F1: o26o&amp;#39;, \
                    &amp;#39;I1: b14&amp;#39;, &amp;#39;I2: n14&amp;#39;, \
                    &amp;#39;RF1: e14&amp;#39;, &amp;#39;RR1: k14&amp;#39;, \
                    &amp;#39;B2: m15&amp;#39;, &amp;#39;B1: c15X&amp;#39;, &amp;#39;L4: g15&amp;#39;, &amp;#39;F2: i16&amp;#39;]]

positions2 = fb.create_position(roster, my_setup, &amp;#39;teamAway&amp;#39;)


positions = pd.concat([positions, positions2])

fb.create_plot(positions, red_team = &amp;quot;teamAway&amp;quot;, ballpos = &amp;#39;e5&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-08-01_fumbbl_replays_files/fumbbl_replays_29_0.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plotting-player-skills-aka-digital-loom-color-bands&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Plotting player skills aka “digital loom color bands”&lt;/h1&gt;
&lt;p&gt;Knowing what extra skills players have is often important in analyzing a given board position (what blocks are possible, can we use the Dodge skill or does the opponent has Tackle etc).
In the FUMBBL client there is a function that allows automatic skill marking using text.
When playing on tabletop there are various ways to mark / denote what extra skills players have.
One popular way is to use colored elastic (“loom”) band.
The most common skills have semi-standardized colors associated with them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Guard is green&lt;/li&gt;
&lt;li&gt;Block is blue&lt;/li&gt;
&lt;li&gt;Wrestle is white&lt;/li&gt;
&lt;li&gt;Dodge is yellow&lt;/li&gt;
&lt;li&gt;Leader is purple&lt;/li&gt;
&lt;li&gt;Mighty Blow is red&lt;/li&gt;
&lt;li&gt;Tackle is orange&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At a typical tournament (I checked this for Thrudball 2024) 80% of skills chosen are one of these seven skills.
Here I decided to make a digital version of the colored elastic band, plotted below the player icon.
If a player has more than one extra skill (“Skill stacking”), the colored bands are stacked on top of each other.&lt;/p&gt;
&lt;p&gt;Here I will demonstrate by setting up the board for a Shambling Undead team with a set of 6 skills often chosen at tournaments.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import fumbbl_replays as fb
roster = fb.fetch_roster(&amp;quot;Shambling Undead&amp;quot;)

my_setup = [&amp;#39;setup&amp;#39;, [&amp;#39;Z1: g14&amp;#39;, &amp;#39;Z2: h14&amp;#39;, &amp;#39;Z3: i14&amp;#39;, 
                      &amp;#39;W1: e16&amp;#39;, &amp;#39;W2: k16&amp;#39;, &amp;#39;G1: h16&amp;#39;, &amp;#39;G2: h17&amp;#39;, 
                      &amp;#39;M1: c16&amp;#39;, &amp;#39;M2: m16&amp;#39;, &amp;#39;Z4: b17&amp;#39;, &amp;#39;Z5: n17&amp;#39;]]

positions = fb.create_position(roster, my_setup)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;fb.add_skill_to_player(positions, &amp;quot;M1&amp;quot;, &amp;quot;Guard&amp;quot;)
fb.add_skill_to_player(positions, &amp;quot;M2&amp;quot;, &amp;quot;Guard&amp;quot;)
fb.add_skill_to_player(positions, &amp;quot;G1&amp;quot;, &amp;quot;Block&amp;quot;)
fb.add_skill_to_player(positions, &amp;quot;G2&amp;quot;, &amp;quot;Block&amp;quot;)
fb.add_skill_to_player(positions, &amp;quot;W1&amp;quot;, &amp;quot;Tackle&amp;quot;)
fb.add_skill_to_player(positions, &amp;quot;W1&amp;quot;, &amp;quot;Mighty Blow&amp;quot;)

fb.create_plot(positions, red_team = &amp;quot;teamAway&amp;quot;, orientation = &amp;#39;H&amp;#39;, skill_bands = True)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-08-01_fumbbl_replays_files/fumbbl_replays_32_0.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It is also possible to remove a (Gained) skill from a player.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;fb.remove_skill_from_player(positions, &amp;quot;W1&amp;quot;, &amp;quot;Tackle&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;(positions
 .filter([&amp;#39;short_name&amp;#39;, &amp;#39;positionName&amp;#39;, &amp;#39;skillArrayRoster&amp;#39;, &amp;#39;learned_skills&amp;#39;, &amp;#39;skill_colors&amp;#39;, &amp;#39;boardpos&amp;#39;])
)
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
&lt;thead&gt;
&lt;tr style=&#34;text-align: right;&#34;&gt;
&lt;th&gt;
&lt;/th&gt;
&lt;th&gt;
short_name
&lt;/th&gt;
&lt;th&gt;
positionName
&lt;/th&gt;
&lt;th&gt;
skillArrayRoster
&lt;/th&gt;
&lt;th&gt;
learned_skills
&lt;/th&gt;
&lt;th&gt;
skill_colors
&lt;/th&gt;
&lt;th&gt;
boardpos
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;
0
&lt;/th&gt;
&lt;td&gt;
Z1
&lt;/td&gt;
&lt;td&gt;
Zombie Lineman
&lt;/td&gt;
&lt;td&gt;
[Regeneration]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
g14
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
1
&lt;/th&gt;
&lt;td&gt;
Z2
&lt;/td&gt;
&lt;td&gt;
Zombie Lineman
&lt;/td&gt;
&lt;td&gt;
[Regeneration]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
h14
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
2
&lt;/th&gt;
&lt;td&gt;
Z3
&lt;/td&gt;
&lt;td&gt;
Zombie Lineman
&lt;/td&gt;
&lt;td&gt;
[Regeneration]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
i14
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
3
&lt;/th&gt;
&lt;td&gt;
W1
&lt;/td&gt;
&lt;td&gt;
Wight Blitzer
&lt;/td&gt;
&lt;td&gt;
[Block, Regeneration]
&lt;/td&gt;
&lt;td&gt;
[Mighty Blow]
&lt;/td&gt;
&lt;td&gt;
[red]
&lt;/td&gt;
&lt;td&gt;
e16
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
4
&lt;/th&gt;
&lt;td&gt;
W2
&lt;/td&gt;
&lt;td&gt;
Wight Blitzer
&lt;/td&gt;
&lt;td&gt;
[Block, Regeneration]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
k16
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
5
&lt;/th&gt;
&lt;td&gt;
G1
&lt;/td&gt;
&lt;td&gt;
Ghoul Runner
&lt;/td&gt;
&lt;td&gt;
[Dodge]
&lt;/td&gt;
&lt;td&gt;
[Block]
&lt;/td&gt;
&lt;td&gt;
[blue]
&lt;/td&gt;
&lt;td&gt;
h16
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
6
&lt;/th&gt;
&lt;td&gt;
G2
&lt;/td&gt;
&lt;td&gt;
Ghoul Runner
&lt;/td&gt;
&lt;td&gt;
[Dodge]
&lt;/td&gt;
&lt;td&gt;
[Block]
&lt;/td&gt;
&lt;td&gt;
[blue]
&lt;/td&gt;
&lt;td&gt;
h17
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
7
&lt;/th&gt;
&lt;td&gt;
M1
&lt;/td&gt;
&lt;td&gt;
Mummy
&lt;/td&gt;
&lt;td&gt;
[Mighty Blow (+1), Regeneration]
&lt;/td&gt;
&lt;td&gt;
[Guard]
&lt;/td&gt;
&lt;td&gt;
[lime]
&lt;/td&gt;
&lt;td&gt;
c16
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
8
&lt;/th&gt;
&lt;td&gt;
M2
&lt;/td&gt;
&lt;td&gt;
Mummy
&lt;/td&gt;
&lt;td&gt;
[Mighty Blow (+1), Regeneration]
&lt;/td&gt;
&lt;td&gt;
[Guard]
&lt;/td&gt;
&lt;td&gt;
[lime]
&lt;/td&gt;
&lt;td&gt;
m16
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
9
&lt;/th&gt;
&lt;td&gt;
Z4
&lt;/td&gt;
&lt;td&gt;
Zombie Lineman
&lt;/td&gt;
&lt;td&gt;
[Regeneration]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
b17
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
10
&lt;/th&gt;
&lt;td&gt;
Z5
&lt;/td&gt;
&lt;td&gt;
Zombie Lineman
&lt;/td&gt;
&lt;td&gt;
[Regeneration]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
n17
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;plotting-board-positions-from-fumbbl-replays&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Plotting board positions from FUMBBL replays&lt;/h1&gt;
&lt;p&gt;Up until now, we created board positions from scratch, using rosters from FUMBBL and a simple way to describe a board position.&lt;/p&gt;
&lt;p&gt;The package also allows us to plot board positions extracted from FUMBBL replay files.
At this moment, only the board position right before kick-off can be plotted.
Suppose we want to plot this position for &lt;a href=&#34;https://www.fumbbl.com/p/match?id=4550284&#34;&gt;match 4550284&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We first need to fetch the replay data. The &lt;code&gt;fetch_data()&lt;/code&gt; function takes the &lt;code&gt;match_id&lt;/code&gt; as argument and returns five objects:
the &lt;code&gt;match_id&lt;/code&gt;, &lt;code&gt;replay_id&lt;/code&gt;, a &lt;code&gt;positions&lt;/code&gt; object containing the board state right before first kick-off, which team is the &lt;code&gt;receiving_team&lt;/code&gt; (i.e. playing offense), and a &lt;code&gt;metadata&lt;/code&gt; list (coach names, race names, and match touchdown result).&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;match_id, replay_id, positions, receiving_team, metadata = fb.fetch_data(match_id = 4550284)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To plot the board state right before kick-off, we can use the &lt;code&gt;create_plot()&lt;/code&gt; function in the same way as above.
We plot the receiving team in red so we can see which team is playing offense and which team is playing defense.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;fb.create_plot(positions, red_team = receiving_team)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-08-01_fumbbl_replays_files/fumbbl_replays_39_0.png&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;(positions.filter([&amp;#39;race&amp;#39;, &amp;#39;home_away&amp;#39;, &amp;#39;short_name&amp;#39;, &amp;#39;positionName&amp;#39;, &amp;#39;playerName&amp;#39;,  &amp;#39;skillArrayRoster&amp;#39;, &amp;#39;learned_skills&amp;#39;, &amp;#39;cost&amp;#39;, &amp;#39;recoveringInjury&amp;#39;])
                    )&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
&lt;thead&gt;
&lt;tr style=&#34;text-align: right;&#34;&gt;
&lt;th&gt;
&lt;/th&gt;
&lt;th&gt;
race
&lt;/th&gt;
&lt;th&gt;
home_away
&lt;/th&gt;
&lt;th&gt;
short_name
&lt;/th&gt;
&lt;th&gt;
positionName
&lt;/th&gt;
&lt;th&gt;
playerName
&lt;/th&gt;
&lt;th&gt;
skillArrayRoster
&lt;/th&gt;
&lt;th&gt;
learned_skills
&lt;/th&gt;
&lt;th&gt;
cost
&lt;/th&gt;
&lt;th&gt;
recoveringInjury
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;
0
&lt;/th&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
T2
&lt;/td&gt;
&lt;td&gt;
Altern Forest Treeman
&lt;/td&gt;
&lt;td&gt;
Caroline Rigol
&lt;/td&gt;
&lt;td&gt;
[Mighty Blow, Stand Firm, Strong Arm, Take Roo…
&lt;/td&gt;
&lt;td&gt;
[+MA]
&lt;/td&gt;
&lt;td&gt;
120000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
1
&lt;/th&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
T1
&lt;/td&gt;
&lt;td&gt;
Altern Forest Treeman
&lt;/td&gt;
&lt;td&gt;
Matthew Ir
&lt;/td&gt;
&lt;td&gt;
[Mighty Blow, Stand Firm, Strong Arm, Take Roo…
&lt;/td&gt;
&lt;td&gt;
[Pro]
&lt;/td&gt;
&lt;td&gt;
120000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
2
&lt;/th&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
L2
&lt;/td&gt;
&lt;td&gt;
Gnome Lineman
&lt;/td&gt;
&lt;td&gt;
Jaiden Netzigon
&lt;/td&gt;
&lt;td&gt;
[Jump Up, Right Stuff, Stunty, Wrestle]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
40000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
5
&lt;/th&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
B1
&lt;/td&gt;
&lt;td&gt;
Gnome Beastmaster
&lt;/td&gt;
&lt;td&gt;
Eloise Celorn
&lt;/td&gt;
&lt;td&gt;
[Guard, Jump Up, Stunty, Wrestle]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
55000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
6
&lt;/th&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
L1
&lt;/td&gt;
&lt;td&gt;
Gnome Lineman
&lt;/td&gt;
&lt;td&gt;
Andre Drumma
&lt;/td&gt;
&lt;td&gt;
[Jump Up, Right Stuff, Stunty, Wrestle]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
40000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
7
&lt;/th&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
B2
&lt;/td&gt;
&lt;td&gt;
Gnome Beastmaster
&lt;/td&gt;
&lt;td&gt;
Sienna Rime
&lt;/td&gt;
&lt;td&gt;
[Guard, Jump Up, Stunty, Wrestle]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
55000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
8
&lt;/th&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
L4
&lt;/td&gt;
&lt;td&gt;
Gnome Lineman
&lt;/td&gt;
&lt;td&gt;
Melanie Kayce
&lt;/td&gt;
&lt;td&gt;
[Jump Up, Right Stuff, Stunty, Wrestle]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
40000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
9
&lt;/th&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
L5
&lt;/td&gt;
&lt;td&gt;
Gnome Lineman
&lt;/td&gt;
&lt;td&gt;
Eliza Elora
&lt;/td&gt;
&lt;td&gt;
[Jump Up, Right Stuff, Stunty, Wrestle]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
40000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
10
&lt;/th&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
L7
&lt;/td&gt;
&lt;td&gt;
Gnome Lineman
&lt;/td&gt;
&lt;td&gt;
Gabriela Lacspor
&lt;/td&gt;
&lt;td&gt;
[Jump Up, Right Stuff, Stunty, Wrestle]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
40000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
11
&lt;/th&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
I1
&lt;/td&gt;
&lt;td&gt;
Gnome Illusionist
&lt;/td&gt;
&lt;td&gt;
Brynlee Tror
&lt;/td&gt;
&lt;td&gt;
[Jump Up, Stunty, Trickster, Wrestle]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
50000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
12
&lt;/th&gt;
&lt;td&gt;
Gnome
&lt;/td&gt;
&lt;td&gt;
teamHome
&lt;/td&gt;
&lt;td&gt;
L3
&lt;/td&gt;
&lt;td&gt;
Gnome Lineman
&lt;/td&gt;
&lt;td&gt;
Chase Kavelin
&lt;/td&gt;
&lt;td&gt;
[Jump Up, Right Stuff, Stunty, Wrestle]
&lt;/td&gt;
&lt;td&gt;
[Sneaky Git]
&lt;/td&gt;
&lt;td&gt;
40000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
14
&lt;/th&gt;
&lt;td&gt;
Shambling Undead
&lt;/td&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
Z3
&lt;/td&gt;
&lt;td&gt;
Zombie Lineman
&lt;/td&gt;
&lt;td&gt;
Rylee Dager
&lt;/td&gt;
&lt;td&gt;
[Regeneration]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
40000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
15
&lt;/th&gt;
&lt;td&gt;
Shambling Undead
&lt;/td&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
Z2
&lt;/td&gt;
&lt;td&gt;
Zombie Lineman
&lt;/td&gt;
&lt;td&gt;
Molly Harven
&lt;/td&gt;
&lt;td&gt;
[Regeneration]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
40000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
16
&lt;/th&gt;
&lt;td&gt;
Shambling Undead
&lt;/td&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
Z1
&lt;/td&gt;
&lt;td&gt;
Zombie Lineman
&lt;/td&gt;
&lt;td&gt;
Asher Meridan
&lt;/td&gt;
&lt;td&gt;
[Regeneration]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
40000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
17
&lt;/th&gt;
&lt;td&gt;
Shambling Undead
&lt;/td&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
M1
&lt;/td&gt;
&lt;td&gt;
Mummy
&lt;/td&gt;
&lt;td&gt;
Brooklyn Biel
&lt;/td&gt;
&lt;td&gt;
[Mighty Blow, Regeneration]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
125000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
18
&lt;/th&gt;
&lt;td&gt;
Shambling Undead
&lt;/td&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
G1
&lt;/td&gt;
&lt;td&gt;
Ghoul Runner
&lt;/td&gt;
&lt;td&gt;
Noelle Vythethi
&lt;/td&gt;
&lt;td&gt;
[Dodge]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
75000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
19
&lt;/th&gt;
&lt;td&gt;
Shambling Undead
&lt;/td&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
Z5
&lt;/td&gt;
&lt;td&gt;
Zombie Lineman
&lt;/td&gt;
&lt;td&gt;
Asher Meegosh
&lt;/td&gt;
&lt;td&gt;
[Regeneration]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
40000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
20
&lt;/th&gt;
&lt;td&gt;
Shambling Undead
&lt;/td&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
M2
&lt;/td&gt;
&lt;td&gt;
Mummy
&lt;/td&gt;
&lt;td&gt;
Bailey Fer
&lt;/td&gt;
&lt;td&gt;
[Mighty Blow, Regeneration]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
125000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
21
&lt;/th&gt;
&lt;td&gt;
Shambling Undead
&lt;/td&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
Z4
&lt;/td&gt;
&lt;td&gt;
Zombie Lineman
&lt;/td&gt;
&lt;td&gt;
Haley Guilomar
&lt;/td&gt;
&lt;td&gt;
[Regeneration]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
40000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
22
&lt;/th&gt;
&lt;td&gt;
Shambling Undead
&lt;/td&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
W1
&lt;/td&gt;
&lt;td&gt;
Wight Blitzer
&lt;/td&gt;
&lt;td&gt;
Corbin Aleemy
&lt;/td&gt;
&lt;td&gt;
[Block, Regeneration]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
90000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
23
&lt;/th&gt;
&lt;td&gt;
Shambling Undead
&lt;/td&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
W2
&lt;/td&gt;
&lt;td&gt;
Wight Blitzer
&lt;/td&gt;
&lt;td&gt;
Lucas Mickal
&lt;/td&gt;
&lt;td&gt;
[Block, Regeneration]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
90000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
24
&lt;/th&gt;
&lt;td&gt;
Shambling Undead
&lt;/td&gt;
&lt;td&gt;
teamAway
&lt;/td&gt;
&lt;td&gt;
G2
&lt;/td&gt;
&lt;td&gt;
Ghoul Runner
&lt;/td&gt;
&lt;td&gt;
Ivy Farate
&lt;/td&gt;
&lt;td&gt;
[Dodge]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
75000
&lt;/td&gt;
&lt;td&gt;
None
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;Adjusting this board position by moving players one-by-one works also in the same way as above.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;positions = fb.move_piece(positions, &amp;quot;teamAway&amp;quot;, &amp;quot;Z1&amp;quot;, &amp;quot;b26&amp;quot;)
positions = fb.move_piece(positions, &amp;quot;teamAway&amp;quot;, &amp;quot;Z2&amp;quot;, &amp;quot;o26&amp;quot;)

fb.create_plot(positions, red_team = receiving_team)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-08-01_fumbbl_replays_files/fumbbl_replays_42_0.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Suppose we think that this Gnome defensive setup is awesome, and we wish to share this setup with other coaches.
Here the compact way to describe a setup using player abbreviations and the alphanumeric grid system comes in handy:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;fb.get_position(positions, home_away = &amp;#39;teamHome&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[&amp;#39;setup&amp;#39;, [&amp;#39;T2: g13&amp;#39;, &amp;#39;T1: i13&amp;#39;, &amp;#39;L2: h13&amp;#39;, &amp;#39;B1: f10&amp;#39;, &amp;#39;L1: e11&amp;#39;, &amp;#39;B2: j10&amp;#39;, &amp;#39;L4: k11&amp;#39;, &amp;#39;L5: h11&amp;#39;, &amp;#39;L7: i10&amp;#39;, &amp;#39;I1: g10&amp;#39;, &amp;#39;L3: h10&amp;#39;]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, suppose we think this setup is nice, but it would be even better if the illusionist in row &lt;code&gt;g&lt;/code&gt; would instead be a Woodland Fox.
We can take the setup (copy-paste), change the setup slightly, and create a new position, with &lt;code&gt;F1: g10&lt;/code&gt;.
As we now only have a single team, we can rotate the pitch and crop to show only the upper part of it.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;roster = fb.fetch_roster(&amp;quot;Gnome&amp;quot;)

my_setup = [&amp;#39;setup&amp;#39;, [&amp;#39;T2: g13&amp;#39;, &amp;#39;T1: i13&amp;#39;, &amp;#39;L2: h13&amp;#39;, &amp;#39;B1: f10&amp;#39;, \
                      &amp;#39;L1: e11&amp;#39;, &amp;#39;B2: j10&amp;#39;, &amp;#39;L4: k11&amp;#39;, &amp;#39;L5: h11&amp;#39;, \
                        &amp;#39;L7: i10&amp;#39;, &amp;#39;F1: g10&amp;#39;, &amp;#39;L3: h10&amp;#39;]]

positions = fb.create_position(roster, my_setup)

fb.create_plot(positions, orientation= &amp;quot;V&amp;quot;, crop = &amp;quot;upper&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2024-08-01_fumbbl_replays_files/fumbbl_replays_46_0.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;working-with-raw-replays-directly&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Working with raw replays directly&lt;/h1&gt;
&lt;p&gt;It is also possible to work with the raw FUMBBL replay files directly.
I made a start with describing the replay file format in &lt;code&gt;doc/fumbbl_replay_file_format.md&lt;/code&gt;.
We can use &lt;code&gt;fetch_replay()&lt;/code&gt; to retrieve a replay in JSON format.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import fumbbl_replays as fb

my_replay = fb.fetch_replay(match_id = 4447439)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;JSON consists of key-value pairs.
We can for example query the value of the key &lt;code&gt;gameStatus&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;my_replay[&amp;#39;gameStatus&amp;#39;]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;#39;uploaded&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or query the &lt;code&gt;rosterName&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;my_replay[&amp;#39;game&amp;#39;][&amp;#39;teamHome&amp;#39;][&amp;#39;roster&amp;#39;][&amp;#39;rosterName&amp;#39;]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;#39;Necromantic Horror&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The replay contains both a game log, as well as full roster information on both teams.
We can extract the roster information from the replay using the function &lt;code&gt;extract_rosters_from_replay()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import pandas as pd
pd.set_option(&amp;#39;display.max_colwidth&amp;#39;, None)

df_positions = fb.extract_rosters_from_replay(my_replay)
(df_positions
 .query(&amp;quot;home_away == &amp;#39;teamAway&amp;#39;&amp;quot;)
 .filter([&amp;#39;short_name&amp;#39;, &amp;#39;positionName&amp;#39;, &amp;#39;skillArrayRoster&amp;#39;, &amp;#39;learned_skills&amp;#39;, &amp;#39;skill_colors&amp;#39;])
)&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
&lt;thead&gt;
&lt;tr style=&#34;text-align: right;&#34;&gt;
&lt;th&gt;
&lt;/th&gt;
&lt;th&gt;
short_name
&lt;/th&gt;
&lt;th&gt;
positionName
&lt;/th&gt;
&lt;th&gt;
skillArrayRoster
&lt;/th&gt;
&lt;th&gt;
learned_skills
&lt;/th&gt;
&lt;th&gt;
skill_colors
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;
14
&lt;/th&gt;
&lt;td&gt;
Tr1
&lt;/td&gt;
&lt;td&gt;
Loren Forest Treeman
&lt;/td&gt;
&lt;td&gt;
[Loner, Mighty Blow, Stand Firm, Strong Arm, Take Root, Thick Skull, Throw Team-Mate]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
15
&lt;/th&gt;
&lt;td&gt;
W1
&lt;/td&gt;
&lt;td&gt;
Wardancer
&lt;/td&gt;
&lt;td&gt;
[Block, Dodge, Leap]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
16
&lt;/th&gt;
&lt;td&gt;
W2
&lt;/td&gt;
&lt;td&gt;
Wardancer
&lt;/td&gt;
&lt;td&gt;
[Block, Dodge, Leap]
&lt;/td&gt;
&lt;td&gt;
[Strip Ball]
&lt;/td&gt;
&lt;td&gt;
[deeppink]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
17
&lt;/th&gt;
&lt;td&gt;
T1
&lt;/td&gt;
&lt;td&gt;
Thrower
&lt;/td&gt;
&lt;td&gt;
[Pass]
&lt;/td&gt;
&lt;td&gt;
[Leader]
&lt;/td&gt;
&lt;td&gt;
[purple]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
18
&lt;/th&gt;
&lt;td&gt;
C1
&lt;/td&gt;
&lt;td&gt;
Catcher
&lt;/td&gt;
&lt;td&gt;
[Catch, Dodge]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
19
&lt;/th&gt;
&lt;td&gt;
C2
&lt;/td&gt;
&lt;td&gt;
Catcher
&lt;/td&gt;
&lt;td&gt;
[Catch, Dodge]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
20
&lt;/th&gt;
&lt;td&gt;
L1
&lt;/td&gt;
&lt;td&gt;
Wood Elf Lineman
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
[Dodge]
&lt;/td&gt;
&lt;td&gt;
[yellow]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
21
&lt;/th&gt;
&lt;td&gt;
L2
&lt;/td&gt;
&lt;td&gt;
Wood Elf Lineman
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
[Dodge]
&lt;/td&gt;
&lt;td&gt;
[yellow]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
22
&lt;/th&gt;
&lt;td&gt;
L3
&lt;/td&gt;
&lt;td&gt;
Wood Elf Lineman
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
23
&lt;/th&gt;
&lt;td&gt;
L4
&lt;/td&gt;
&lt;td&gt;
Wood Elf Lineman
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
[Wrestle]
&lt;/td&gt;
&lt;td&gt;
[floralwhite]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
24
&lt;/th&gt;
&lt;td&gt;
L5
&lt;/td&gt;
&lt;td&gt;
Wood Elf Lineman
&lt;/td&gt;
&lt;td&gt;
[]
&lt;/td&gt;
&lt;td&gt;
[Wrestle]
&lt;/td&gt;
&lt;td&gt;
[floralwhite]
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;I wrote a replay parser that parses the gameLog section of a replay and transforms this into a &lt;code&gt;pandas&lt;/code&gt; DataFrame object, i.e. a flat 2D table with rows and columns.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df = fb.parse_replay(my_replay)
(df[0:4]
 .filter([&amp;#39;commandNr&amp;#39;, &amp;#39;turnNr&amp;#39;, &amp;#39;turnMode&amp;#39;, &amp;#39;Half&amp;#39;, &amp;#39;modelChangeId&amp;#39;, &amp;#39;modelChangeValue&amp;#39;])
)&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
&lt;thead&gt;
&lt;tr style=&#34;text-align: right;&#34;&gt;
&lt;th&gt;
&lt;/th&gt;
&lt;th&gt;
commandNr
&lt;/th&gt;
&lt;th&gt;
turnNr
&lt;/th&gt;
&lt;th&gt;
turnMode
&lt;/th&gt;
&lt;th&gt;
Half
&lt;/th&gt;
&lt;th&gt;
modelChangeId
&lt;/th&gt;
&lt;th&gt;
modelChangeValue
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;
0
&lt;/th&gt;
&lt;td&gt;
1
&lt;/td&gt;
&lt;td&gt;
0
&lt;/td&gt;
&lt;td&gt;
startGame
&lt;/td&gt;
&lt;td&gt;
0
&lt;/td&gt;
&lt;td&gt;
fieldModelAddPlayerMarker
&lt;/td&gt;
&lt;td&gt;
{‘playerId’: ‘15440786’, ‘homeText’: ‘B’, ‘awayText’: ‘B’}
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
1
&lt;/th&gt;
&lt;td&gt;
1
&lt;/td&gt;
&lt;td&gt;
0
&lt;/td&gt;
&lt;td&gt;
startGame
&lt;/td&gt;
&lt;td&gt;
0
&lt;/td&gt;
&lt;td&gt;
fieldModelAddPlayerMarker
&lt;/td&gt;
&lt;td&gt;
{‘playerId’: ‘15440787’, ‘homeText’: ‘G’, ‘awayText’: ‘G’}
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
2
&lt;/th&gt;
&lt;td&gt;
1
&lt;/td&gt;
&lt;td&gt;
0
&lt;/td&gt;
&lt;td&gt;
startGame
&lt;/td&gt;
&lt;td&gt;
0
&lt;/td&gt;
&lt;td&gt;
fieldModelAddPlayerMarker
&lt;/td&gt;
&lt;td&gt;
{‘playerId’: ‘15440788’, ‘homeText’: ‘G’, ‘awayText’: ‘G’}
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
3
&lt;/th&gt;
&lt;td&gt;
1
&lt;/td&gt;
&lt;td&gt;
0
&lt;/td&gt;
&lt;td&gt;
startGame
&lt;/td&gt;
&lt;td&gt;
0
&lt;/td&gt;
&lt;td&gt;
fieldModelAddPlayerMarker
&lt;/td&gt;
&lt;td&gt;
{‘playerId’: ‘15440790’, ‘homeText’: ‘G’, ‘awayText’: ‘G’}
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;We can use the &lt;code&gt;pandas&lt;/code&gt; &lt;code&gt;query()&lt;/code&gt; function to select rows based on conditions.
This query selects all “fieldModelSetPlayerCoordinate” commands during setup before turn 1.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;positions = (df.query(&amp;#39;turnNr == 0 &amp;amp; turnMode == &amp;quot;setup&amp;quot; &amp;amp; Half == 1 &amp;amp; \
                     modelChangeId == &amp;quot;fieldModelSetPlayerCoordinate&amp;quot;&amp;#39;)
                     .groupby(&amp;#39;modelChangeKey&amp;#39;)
                     .tail(1))

(positions[0:4]
 .filter([&amp;#39;commandNr&amp;#39;, &amp;#39;turnNr&amp;#39;, &amp;#39;turnMode&amp;#39;, &amp;#39;Half&amp;#39;, &amp;#39;modelChangeId&amp;#39;, &amp;#39;modelChangeValue&amp;#39;])
)&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
&lt;thead&gt;
&lt;tr style=&#34;text-align: right;&#34;&gt;
&lt;th&gt;
&lt;/th&gt;
&lt;th&gt;
commandNr
&lt;/th&gt;
&lt;th&gt;
turnNr
&lt;/th&gt;
&lt;th&gt;
turnMode
&lt;/th&gt;
&lt;th&gt;
Half
&lt;/th&gt;
&lt;th&gt;
modelChangeId
&lt;/th&gt;
&lt;th&gt;
modelChangeValue
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;
77
&lt;/th&gt;
&lt;td&gt;
20
&lt;/td&gt;
&lt;td&gt;
0
&lt;/td&gt;
&lt;td&gt;
setup
&lt;/td&gt;
&lt;td&gt;
1
&lt;/td&gt;
&lt;td&gt;
fieldModelSetPlayerCoordinate
&lt;/td&gt;
&lt;td&gt;
[12, 6]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
79
&lt;/th&gt;
&lt;td&gt;
21
&lt;/td&gt;
&lt;td&gt;
0
&lt;/td&gt;
&lt;td&gt;
setup
&lt;/td&gt;
&lt;td&gt;
1
&lt;/td&gt;
&lt;td&gt;
fieldModelSetPlayerCoordinate
&lt;/td&gt;
&lt;td&gt;
[12, 7]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
81
&lt;/th&gt;
&lt;td&gt;
22
&lt;/td&gt;
&lt;td&gt;
0
&lt;/td&gt;
&lt;td&gt;
setup
&lt;/td&gt;
&lt;td&gt;
1
&lt;/td&gt;
&lt;td&gt;
fieldModelSetPlayerCoordinate
&lt;/td&gt;
&lt;td&gt;
[12, 8]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
84
&lt;/th&gt;
&lt;td&gt;
24
&lt;/td&gt;
&lt;td&gt;
0
&lt;/td&gt;
&lt;td&gt;
setup
&lt;/td&gt;
&lt;td&gt;
1
&lt;/td&gt;
&lt;td&gt;
fieldModelSetPlayerCoordinate
&lt;/td&gt;
&lt;td&gt;
[10, 4]
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;As I was interested in &lt;strong&gt;defensive&lt;/strong&gt; setup formations, I wrote a function &lt;code&gt;determine_receiving_team_at_start()&lt;/code&gt; that does exactly what you’d expect given its name :)&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;fb.determine_receiving_team_at_start(df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;#39;teamAway&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;towards-ffgn&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Towards FFGN&lt;/h1&gt;
&lt;p&gt;Finally, there is a function &lt;code&gt;fumbbl2ffgn()&lt;/code&gt; that is very much a work in progress.
The idea is to take a FUMBBL game log, and systematically strip away all information that is redundant regarding the actual logging of what happened during the game. A minimal game description would consist of all actions taken, all decisions that were made (i.e. to use the dodge skill) and all dice results.
After we have such a description, we can transform it to a compact annotation that is readable both by humans and machines, and is still a complete description of the game, in that the full game can be reproduced.
The compact annotation would then be candidate to become the official “Fantasy Football Game Notation”, or FFGN for short.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;my_game_log = fb.fumbbl2ffgn(match_id = 4447439)
len(my_game_log)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;866&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is where it currently stands. A single gamelog is now roughly 1000 lines of text.
The table below describes the first turn of a Wood Elf team against Necromantic.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;pd.set_option(&amp;#39;display.max_colwidth&amp;#39;, None)

# Turn 1 for the offensive
(my_game_log
 .query(&amp;quot;Half == 1 &amp;amp; turnNr == 1 &amp;amp; commandNr &amp;gt; 88 &amp;amp; commandNr &amp;lt; 211&amp;quot;)
 .filter([&amp;#39;modelChangeKey&amp;#39;, &amp;#39;modelChangeValue&amp;#39;])
)&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
&lt;thead&gt;
&lt;tr style=&#34;text-align: right;&#34;&gt;
&lt;th&gt;
&lt;/th&gt;
&lt;th&gt;
modelChangeKey
&lt;/th&gt;
&lt;th&gt;
modelChangeValue
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;
29
&lt;/th&gt;
&lt;td&gt;
[‘T1’]
&lt;/td&gt;
&lt;td&gt;
[j17, i17, h17, g17, f17, e17]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
30
&lt;/th&gt;
&lt;td&gt;
[‘C1’]
&lt;/td&gt;
&lt;td&gt;
[g17, f17, e18, d17, c17, b17]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
31
&lt;/th&gt;
&lt;td&gt;
[‘L1’]
&lt;/td&gt;
&lt;td&gt;
[d14, e13, f13]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
32
&lt;/th&gt;
&lt;td&gt;
[‘L4’]
&lt;/td&gt;
&lt;td&gt;
Block roll:[‘!’, ‘!’] | block result: ! (POW/PUSH)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
33
&lt;/th&gt;
&lt;td&gt;
[‘L5’]
&lt;/td&gt;
&lt;td&gt;
[g12]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
34
&lt;/th&gt;
&lt;td&gt;
[‘L4’]
&lt;/td&gt;
&lt;td&gt;
[g13]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
35
&lt;/th&gt;
&lt;td&gt;
0
&lt;/td&gt;
&lt;td&gt;
Armour roll: [3, 5] | Armour of [‘L5’] is not broken
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
36
&lt;/th&gt;
&lt;td&gt;
[‘Tr1’]
&lt;/td&gt;
&lt;td&gt;
Confusion roll: 2 | [‘Tr1’] acts normally
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
37
&lt;/th&gt;
&lt;td&gt;
[‘Tr1’]
&lt;/td&gt;
&lt;td&gt;
Block roll:[‘&amp;gt;’, ‘%’, ’*’] | block result: * (POW)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
38
&lt;/th&gt;
&lt;td&gt;
[‘L2’]
&lt;/td&gt;
&lt;td&gt;
[i12]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
39
&lt;/th&gt;
&lt;td&gt;
[‘Tr1’]
&lt;/td&gt;
&lt;td&gt;
[h13]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
40
&lt;/th&gt;
&lt;td&gt;
0
&lt;/td&gt;
&lt;td&gt;
Armour roll: [4, 2] | Armour of [‘L2’] is not broken
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
41
&lt;/th&gt;
&lt;td&gt;
[‘L5’]
&lt;/td&gt;
&lt;td&gt;
Block roll:[‘&amp;gt;’, ‘!’] | block result: ! (POW/PUSH)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
42
&lt;/th&gt;
&lt;td&gt;
[‘L4’]
&lt;/td&gt;
&lt;td&gt;
[h12]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
43
&lt;/th&gt;
&lt;td&gt;
0
&lt;/td&gt;
&lt;td&gt;
Armour roll: [2, 5] | Armour of [‘L4’] is not broken
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
44
&lt;/th&gt;
&lt;td&gt;
[‘L3’]
&lt;/td&gt;
&lt;td&gt;
[m16, l16, k16, j16, i16, h16]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
45
&lt;/th&gt;
&lt;td&gt;
[‘L2’]
&lt;/td&gt;
&lt;td&gt;
[l15, k15, j15, i15, h15, g15, f15]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
46
&lt;/th&gt;
&lt;td&gt;
[‘C2’]
&lt;/td&gt;
&lt;td&gt;
[c15]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
47
&lt;/th&gt;
&lt;td&gt;
[‘W1’]
&lt;/td&gt;
&lt;td&gt;
[d16, c16, b16]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
48
&lt;/th&gt;
&lt;td&gt;
[‘W2’]
&lt;/td&gt;
&lt;td&gt;
[g18, f18, e18, d18, c18, b18]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
49
&lt;/th&gt;
&lt;td&gt;
[‘W2’]
&lt;/td&gt;
&lt;td&gt;
{‘reportId’: ‘pickUpRoll’, ‘playerId’: ‘[’W2’]’, ‘successful’: True, ‘roll’: 4, ‘minimumRoll’: 2, ‘reRolled’: False}
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
50
&lt;/th&gt;
&lt;td&gt;
[‘W2’]
&lt;/td&gt;
&lt;td&gt;
[c18, d18]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
51
&lt;/th&gt;
&lt;td&gt;
___
&lt;/td&gt;
&lt;td&gt;
End of Turn
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Thrower 1 moves. Catcher 1 moves. Lineman 1 moves. Lineman 4 blocks, chooses pow/push, pows Zombie lineman L5 into square g12, follows up, does not break armor.&lt;/em&gt;
&lt;em&gt;Treeman does not take root, does a 3D block on Zombie lineman 2, chooses pow into square i12, follows up to square h13, does not break armor.&lt;/em&gt;
&lt;em&gt;Lineman 5 blocks zombie lineman L4, pows into h12, does not follow up, does not break armor. Then linemen L3, L2, catcher C2 and wardancer W1 all do a move action.&lt;/em&gt;
&lt;em&gt;Finally Wardancer W2 moves, picks up the ball and moves a bit more. End turn.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This blog post describes the basic functionality of the &lt;code&gt;fumbbl_replays&lt;/code&gt; Python package. I have a second blog post coming up with three applications that use the &lt;code&gt;fumbbl_replays&lt;/code&gt; package to accomplish some Nufflytics goal.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Nufflytics: Analyzing Blood Bowl matches from FUMBBL using Python</title>
      <link>/post/blood-bowl-nufflytics/</link>
      <pubDate>Sun, 20 Mar 2022 00:00:00 +0000</pubDate>
      <guid>/post/blood-bowl-nufflytics/</guid>
      <description>


&lt;p&gt;This blogpost is about &lt;strong&gt;Blood Bowl&lt;/strong&gt;, a strategic boardgame invented in the late 80’s, that I finally started playing last year. Blood bowl is a game of Fantasy Football, where fantasy team races (think “Orcs”, or “Elves”) are pitted against each other. Interestingly, the various teams (there are over 20 different ones) require different play styles, and not all team races are equally strong. On tournaments, this gives rise to various compensation schemes to make all teams “viable” for competition. There exists a lively tournament scene, with thousands of matches played each year.&lt;/p&gt;
&lt;p&gt;The idea of this blog post is to showcase some possible analyses that can be done on the &lt;a href=&#34;https://gsverhoeven.github.io/post/blood-bowl-fumbbl-dataset/&#34;&gt;FUMBBL match data I’ve compiled&lt;/a&gt;. The idea is to make Blood Bowl data analysis (also know as &lt;a href=&#34;https://nufflytics.com&#34;&gt;Nufflytics&lt;/a&gt;, a term coined by Blood Bowler “Schlice” in reference to Nuffle, the god of Blood Bowl) easier and more accessible to others. I took inspiration from various sources, detailed at the end of this post. So lets dive in the world of Blood Bowl stats nerdery.&lt;/p&gt;
&lt;div id=&#34;getting-started-with-the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Getting started with the data&lt;/h1&gt;
&lt;p&gt;Since the previous blog post on FUMBBL data, I decided to make a separate Github repository &lt;a href=&#34;https://github.com/gsverhoeven/fumbbl_datasets&#34;&gt;fumbbl_datasets&lt;/a&gt; that contains the Python code to fetch and construct the FUMBBL datasets. You can either download the latest datasets manually, or clone the entire repo to your local drive, depending on your expertise and preferences.&lt;/p&gt;
&lt;p&gt;The datasets are available both in CSV and HDF5. CSV would be the format of choice for Excel analysis, whereas the HDF5 format is suitable for scripted languages such as Python or R. Here we use Python, with the libraries &lt;code&gt;Pandas&lt;/code&gt; and &lt;code&gt;plotnine&lt;/code&gt; for data analysis and visualization. The code below assumes the datasets are locally stored at the location contained in the &lt;code&gt;path_to_datasets&lt;/code&gt; variable:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import pandas as pd
import numpy as np
import plotnine as p9

# point this to the location of the HDF5 datasets
path_to_datasets = &amp;#39;../../../../fumbbl_datasets/&amp;#39;

# FUMBBL matches
target = &amp;#39;datasets/v0.2/df_matches.h5&amp;#39;
df_matches = pd.read_hdf(path_to_datasets + target) 

# FUMBBL matches by team
target = &amp;#39;datasets/v0.2/df_mbt.h5&amp;#39;
df_mbt = pd.read_hdf(path_to_datasets + target) 

# FUMBBL inducements
target = &amp;#39;datasets/v0.2/inducements.h5&amp;#39;
inducements = pd.read_hdf(path_to_datasets + target) &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;what-data-do-we-have-weekly-game-volumes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What data do we have? Weekly game volumes&lt;/h1&gt;
&lt;p&gt;Let’s see what we’ve got! The pandas DataFrame &lt;code&gt;df_matches&lt;/code&gt; contains records for all matches played on FUMBBL between august 2020 and march 2022.&lt;/p&gt;
&lt;p&gt;Since we have a proper &lt;code&gt;datetime&lt;/code&gt; type variable for each week (&lt;code&gt;week_date&lt;/code&gt;), we can use &lt;code&gt;pandas&lt;/code&gt; and &lt;code&gt;plotnine&lt;/code&gt; to plot the weekly game volume as a time series.&lt;/p&gt;
&lt;p&gt;The introduction of the new &lt;strong&gt;Competitive division&lt;/strong&gt; with BB2020 rules is marked by a vertical red line. I labeled the larger leagues as well a recent tournament I took part in myself.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;res = (df_matches
    .loc[(df_matches[&amp;#39;week_date&amp;#39;] &amp;gt;= &amp;#39;2020-08-01&amp;#39; ) &amp;amp; (df_matches[&amp;#39;week_date&amp;#39;] &amp;lt; &amp;#39;2022-11-25&amp;#39;)]
    .groupby([&amp;#39;week_date&amp;#39;, &amp;#39;week_number&amp;#39;, &amp;#39;division_name&amp;#39;])
    .agg(        
        n_games = (&amp;#39;match_id&amp;#39;, &amp;quot;count&amp;quot;) 
    )
    .reset_index()) # this adds the &amp;quot;group by&amp;quot; variables back as columns of res

(p9.ggplot(data = res, mapping = p9.aes(x = &amp;#39;week_date&amp;#39;, y = &amp;#39;n_games&amp;#39;, color = &amp;#39;division_name&amp;#39;))
+ p9.geom_point() 
+ p9.geom_line()
+ p9.expand_limits(y=[0,2000])
+ p9.geom_vline(xintercept = &amp;#39;2021-09-01&amp;#39;, color = &amp;quot;red&amp;quot;)
+ p9.theme(figure_size = (10, 5))
+ p9.ggtitle(&amp;quot;Weekly game volume on FUMBBL august 2020 - march 2022&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-03-20_nufflytics_blog_post_files/nufflytics_blog_post_4_0.png&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;ggplot: (-9223363302253724542)&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To check the dataset, I compared this plot with the plot of weekly game volumes that FUMBBL itself provides at &lt;a href=&#34;https://fumbbl.com/p/stats&#34; class=&#34;uri&#34;&gt;https://fumbbl.com/p/stats&lt;/a&gt;.
Both plots looked identical at the time of writing, so it seems that we have a complete dataset for the given period.&lt;/p&gt;
&lt;p&gt;The effect of starting the new BB2020 Competitive division is clearly visible, with the weekly game volume almost doubling in september 2021.
The first online NAF tournament using BB2020 rules is also visible, running for 6 weeks in October / November 2021.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;star-player-usage-on-fumbbl&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Star player usage on FUMBBL&lt;/h1&gt;
&lt;p&gt;We can also look at the percentage of matches that involve star players.
I used the various plot aesthetics like symbol shape and size to encode the game volume and ruleset (BB2016 or BB2020 based).&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;divisions = [&amp;#39;Blackbox&amp;#39;, &amp;#39;Competitive&amp;#39;, &amp;#39;Online NAF Tournaments&amp;#39;,  &amp;#39;Ranked&amp;#39;, &amp;#39;Regular_league&amp;#39;]

res = (df_matches
.query(&amp;quot;division_name in @divisions&amp;quot;)
.groupby([&amp;#39;division_name&amp;#39;, &amp;#39;league&amp;#39;, &amp;#39;ruleset&amp;#39;, &amp;#39;ruleset_version&amp;#39;, &amp;#39;week_date&amp;#39;])
.agg(
    n_games = (&amp;#39;match_id&amp;#39;, &amp;#39;count&amp;#39;),
    perc_sp = (&amp;#39;has_sp&amp;#39;, &amp;#39;mean&amp;#39;)
)
.reset_index()
.sort_values(&amp;quot;n_games&amp;quot;, ascending=False)
)

(p9.ggplot(data = res.query(&amp;quot;n_games &amp;gt; 30&amp;quot;), mapping = p9.aes(x = &amp;#39;week_date&amp;#39;, y = &amp;#39;perc_sp*100&amp;#39;, 
group = &amp;#39;factor(division_name)&amp;#39;, color = &amp;#39;factor(division_name)&amp;#39;))
    + p9.geom_point(p9.aes(shape = &amp;#39;factor(ruleset_version)&amp;#39;, size = &amp;#39;n_games&amp;#39;)) 
    + p9.expand_limits(y=[0,1])
    + p9.scale_size_area()
    + p9.geom_vline(xintercept = &amp;#39;2021-09-01&amp;#39;, color = &amp;quot;red&amp;quot;)
    + p9.ggtitle(&amp;quot;Star player usage over time, by division/league&amp;quot;)
    + p9.theme(figure_size = (10, 6))
    + p9.ylab(&amp;quot;% matches with at least one Star Player&amp;quot;))
    &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-03-20_nufflytics_blog_post_files/nufflytics_blog_post_7_0.png&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;ggplot: (-9223363302246313763)&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In above graph, the various online NAF Tournaments are clearly distinguished. &lt;strong&gt;Amorical Cup 2020&lt;/strong&gt; in summer 2020, &lt;strong&gt;Eur’Open Online&lt;/strong&gt; in Nov/dec 2020, &lt;strong&gt;SteelBowl&lt;/strong&gt; in Feb 2021, and &lt;strong&gt;LitBowl&lt;/strong&gt; in May 2021 were all using BB2016 rules.&lt;/p&gt;
&lt;p&gt;Through Googling and using the Wayback Machine, I was able to find the rulepacks of these tournaments. LitBowl featured “big budgets” (up to 1440K) and a requirement of only 10 regular players before inducement, this likely explains the large amount of Star Players in that tournament.&lt;/p&gt;
&lt;p&gt;In contrast, in the GBFU tournament, the first online NAF tournament using the BB2020 rules, only some 15% of matches involved at least one star player.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;are-coach-ratings-predictive-of-match-outcomes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Are coach ratings predictive of match outcomes?&lt;/h1&gt;
&lt;p&gt;For the main divisions on FUMBBL, ELO style coach ratings are available that are updated after each game.
The coach rankings are explained on &lt;a href=&#34;https://fumbbl.com/help:Ranking&#34;&gt;this help page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;According to the ELO ranking system, a coach rating difference of 40 should result in 85% wins for the higher ranked coach.
Coaches of equal rating should have a win rate of 0.5 (with draws weighted at half point).&lt;/p&gt;
&lt;p&gt;The range of coach rankings observed for a particular game tells us something about the relationship between skill and luck.
If a game is pure luck, we will never observe large differences in coach rating, since the outcome will be determined by a coin flip, independent of coach skill.&lt;/p&gt;
&lt;p&gt;On FUMBBL, coach ratings vary roughly between 125 and 175. What do we expect if a coach with a rating of 175 plays a coach of rating 145? Well, the rating difference is 30. According to the formula (assuming equal team strength and equal races), the expected win probability is 1/(1 + 10^0.75) = 85%, and the probability of loss is 15%.&lt;/p&gt;
&lt;p&gt;Since our CR we obtained from the FUMBBL match result page is an overall coach rating (i.e. it ignores division), we can simply pool all matches from divisions where coach rating is tracked.&lt;/p&gt;
&lt;p&gt;The match data contains a &lt;strong&gt;Coach Ranking Difference&lt;/strong&gt; bin (category) that we can each to calculate the Win/draw/loss percentages for each category.&lt;/p&gt;
&lt;p&gt;Let’s see what the actual percentages are:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;main_divisions = [&amp;#39;Blackbox&amp;#39;, &amp;#39;Ranked&amp;#39;, &amp;#39;Competitive&amp;#39;]

res = (df_matches[df_matches[&amp;#39;division_name&amp;#39;].isin(main_divisions)]
    .groupby([&amp;#39;cr_bin&amp;#39;, &amp;#39;team1_win&amp;#39;])
    .agg(        
        n_games = (&amp;#39;cr_bin&amp;#39;, &amp;quot;count&amp;quot;),
    )
    .reset_index()) # this adds the group by variable (now index) as a column

# add total games played within each bin
res[&amp;#39;n_games_bin&amp;#39;] = res.groupby(&amp;#39;cr_bin&amp;#39;).n_games.transform(&amp;#39;sum&amp;#39;)

res[&amp;#39;perc&amp;#39;] = res[&amp;#39;n_games&amp;#39;]/res[&amp;#39;n_games_bin&amp;#39;]

(p9.ggplot(res, p9.aes(x = &amp;#39;factor(cr_bin)&amp;#39;, y = &amp;#39;perc&amp;#39;, fill = &amp;#39;factor(team1_win)&amp;#39;)) 
    + p9.geom_bar(position = &amp;quot;fill&amp;quot;, stat = &amp;quot;identity&amp;quot;) 
    + p9.theme(axis_text_x= p9.element_text(rotation=90, hjust=1))
    + p9.ggtitle(&amp;#39;probability of win/draw/loss as a function of Coach Rating difference&amp;#39;)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-03-20_nufflytics_blog_post_files/nufflytics_blog_post_10_0.png&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;ggplot: (-9223363302350291624)&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(Note that I made the bins for large CR differences (greater than 10) wider to get more games per bin.)&lt;/p&gt;
&lt;p&gt;From above graphs, we can conclude that the coach ratings work as expected, with large coach rating differences indeed showing high win rates for the higher ranked coach. From this we can infer that a highly skilled coach will win 9 times out of ten agains a below average coach. We call Blood Bowl a Strategy game for a reason!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-about-the-passing-game-in-bb2020&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What about the passing game in BB2020?&lt;/h1&gt;
&lt;p&gt;With Blood Bowl 2020 also came a large change to passing the ball. Passing is no longer linked to the &lt;strong&gt;Agility&lt;/strong&gt; statistics, but now has its own &lt;strong&gt;Passing&lt;/strong&gt; (PA) stat. Overall, passing became riskier, and high agility teams do not automatically have good passing stats. For example, only a High Elf thrower has a PA of 2+, whereas the rest of the players have a PA of 4+ or higher. On the Dark Elf team, the player with the best PA stat is the runner, with a PA of 3+, without a built in re-roll. So we can expect quite some changes in the number of completions per match. For more detail I refer to a nice post by king_ghidra at &lt;a href=&#34;https://bloodbowlstrategies.com/en/tactics-blood-bowl-second-season/&#34;&gt;Blood Bowl Strategies&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let’s have a look!&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;divisions = [&amp;#39;Ranked&amp;#39;, &amp;#39;Blackbox&amp;#39;, &amp;#39;Competitive&amp;#39;]

tv_bins = [&amp;#39;1.1M&amp;#39;, &amp;#39;1.4M&amp;#39;, &amp;#39;1.7M&amp;#39;]

res = (df_mbt[df_mbt[&amp;#39;division_name&amp;#39;].isin(divisions)]
    .loc[df_mbt[&amp;#39;tv_bin&amp;#39;].isin(tv_bins)]
    .query(&amp;quot;mirror_match == 0 &amp;amp; has_sp == 0 &amp;amp; tv_bin in @tv_bins &amp;amp; division_name in @divisions&amp;quot;)
    .groupby([&amp;#39;division_name&amp;#39;, &amp;#39;ruleset_version&amp;#39;, &amp;#39;week_date&amp;#39;, &amp;#39;tv_bin&amp;#39;])
    .agg(        
        avg_comp = (&amp;#39;home_comp&amp;#39;, &amp;quot;mean&amp;quot;),
        avg_pass = (&amp;#39;home_pass&amp;#39;, &amp;quot;mean&amp;quot;),
        avg_foul = (&amp;#39;home_foul&amp;#39;, &amp;quot;mean&amp;quot;),
        avg_block = (&amp;#39;home_block&amp;#39;, &amp;quot;mean&amp;quot;),    
        avg_cas = (&amp;#39;home_cas&amp;#39;, &amp;quot;mean&amp;quot;),  
        avg_rcv_cas = (&amp;#39;away_cas&amp;#39;, &amp;quot;mean&amp;quot;),
        n_games = (&amp;#39;race_name&amp;#39;, &amp;quot;count&amp;quot;)
    )
    .sort_values( &amp;#39;n_games&amp;#39;, ascending = False)
    .reset_index()) # this adds the group by variables (now index) as a column

res = res.dropna()

(p9.ggplot(data = res.query(&amp;#39;n_games &amp;gt; 10&amp;#39;), 
            mapping = p9.aes(x = &amp;#39;week_date&amp;#39;, y = &amp;#39;avg_comp&amp;#39;, 
                            size = &amp;#39;n_games&amp;#39;, color = &amp;#39;factor(division_name)&amp;#39;, shape = &amp;#39;factor(tv_bin)&amp;#39;))
    + p9.geom_point()
    + p9.scale_size_area() 
    + p9.geom_vline(xintercept = &amp;#39;2021-09-01&amp;#39;, color = &amp;quot;red&amp;quot;)    
    + p9.theme(figure_size = (10, 5))
    + p9.ggtitle(&amp;quot;average completions per game BB2020 vs BB2016&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;/home/gertjan/venvs/requests_env/lib/python3.6/site-packages/plotnine/scales/scale_shape.py:85: PlotnineWarning: Using shapes for an ordinal variable is not advised.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-03-20_nufflytics_blog_post_files/nufflytics_blog_post_13_1.png&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;ggplot: (-9223363302350371093)&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;divisions = [&amp;#39;Ranked&amp;#39;, &amp;#39;Blackbox&amp;#39;, &amp;#39;Competitive&amp;#39;]

tv_bins = [&amp;#39;1.1M&amp;#39;, &amp;#39;1.4M&amp;#39;, &amp;#39;1.7M&amp;#39;]

res = (df_mbt[df_mbt[&amp;#39;division_name&amp;#39;].isin(divisions)]
    .loc[df_mbt[&amp;#39;tv_bin&amp;#39;].isin(tv_bins)]
    .query(&amp;quot;mirror_match == 0 &amp;amp; has_sp == 0 &amp;amp; tv_bin in @tv_bins &amp;amp; division_name in @divisions&amp;quot;)
    .groupby([&amp;#39;ruleset_version&amp;#39;, &amp;#39;race_name&amp;#39;, &amp;#39;tv_bin&amp;#39;])
    .agg(        
        avg_comp = (&amp;#39;home_comp&amp;#39;, &amp;quot;mean&amp;quot;),
        avg_pass = (&amp;#39;home_pass&amp;#39;, &amp;quot;mean&amp;quot;),
        avg_foul = (&amp;#39;home_foul&amp;#39;, &amp;quot;mean&amp;quot;),
        n_games = (&amp;#39;race_name&amp;#39;, &amp;quot;count&amp;quot;)
    )
    .sort_values( &amp;#39;n_games&amp;#39;, ascending = False)
    .reset_index()) # this adds the group by variables (now index) as a column

res = res.dropna()

(p9.ggplot(data = res.query(&amp;#39;n_games &amp;gt; 10 &amp;amp; tv_bin == &amp;quot;1.1M&amp;quot;&amp;#39;), 
            mapping = p9.aes(y = &amp;#39;reorder(race_name, avg_comp)&amp;#39;, x = &amp;#39;avg_comp&amp;#39;, 
                            size = &amp;#39;n_games&amp;#39;, group = &amp;#39;factor(ruleset_version)&amp;#39;, 
                            color = &amp;#39;factor(ruleset_version)&amp;#39;))
    + p9.geom_point()
    + p9.scale_size_area() 
    + p9.ggtitle(&amp;quot;average completions per game BB2016 vs BB2020 at 1.1M TV&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-03-20_nufflytics_blog_post_files/nufflytics_blog_post_14_0.png&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;ggplot: (-9223363302350232432)&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Across the board we see a decrease in average completions per match. Note that this is for low team values, at around 1.1M, between 950K and 1250K.&lt;/p&gt;
&lt;p&gt;Observations that stand out:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;High agility teams such as Elven Union, Wood Elf and Skaven show large drops,&lt;/li&gt;
&lt;li&gt;Dark elves show the largest relative drop (more than halving in completions),&lt;/li&gt;
&lt;li&gt;High Elves are hardly affected, as well as Humans,&lt;/li&gt;
&lt;li&gt;Halflings show a large increase.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;and-what-about-fouling-in-bb2020&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;And what about fouling in BB2020?&lt;/h1&gt;
&lt;p&gt;Also for fouling Blood Bowl 2020 brought some changes to the rules. The &lt;strong&gt;Sneaky Git&lt;/strong&gt; skill became better, allowing a player to continue moving after the foul has been committed. The &lt;strong&gt;Black Orcs&lt;/strong&gt; were added as a new team, that show fouling potential: they have access to cheap bribes, the &lt;strong&gt;Grab&lt;/strong&gt; skill to set up a foul, and cheap goblin bruisers to quickly move around the pitch. And there was of course the &lt;strong&gt;swarming&lt;/strong&gt; for the Underworld and Snotling teams, that provides a continuous supply of disposable players to foul with. For more detail I refer to a nice post by king_ghidra at &lt;a href=&#34;https://bloodbowlstrategies.com/en/tactics-blood-bowl-second-season/&#34;&gt;Blood Bowl Strategies&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let’s see how the stats were affected!&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;divisions = [&amp;#39;Ranked&amp;#39;, &amp;#39;Blackbox&amp;#39;, &amp;#39;Competitive&amp;#39;]

tv_bins = [&amp;#39;1.1M&amp;#39;, &amp;#39;1.2M&amp;#39;, &amp;#39;1.3M&amp;#39;, &amp;#39;1.4M&amp;#39;]

res = (df_mbt[df_mbt[&amp;#39;division_name&amp;#39;].isin(divisions)]
    .loc[df_mbt[&amp;#39;tv_bin2&amp;#39;].isin(tv_bins)]
    .query(&amp;quot;mirror_match == 0 &amp;amp; has_sp == 0 &amp;amp; tv_bin2 in @tv_bins &amp;amp; division_name in @divisions&amp;quot;)
    .groupby([&amp;#39;ruleset_version&amp;#39;, &amp;#39;race_name&amp;#39;, &amp;#39;tv_bin2&amp;#39;])
    .agg(        
        avg_comp = (&amp;#39;home_comp&amp;#39;, &amp;quot;mean&amp;quot;),
        avg_pass = (&amp;#39;home_pass&amp;#39;, &amp;quot;mean&amp;quot;),
        avg_foul = (&amp;#39;home_foul&amp;#39;, &amp;quot;mean&amp;quot;),
        n_games = (&amp;#39;race_name&amp;#39;, &amp;quot;count&amp;quot;)
    )
    .sort_values( &amp;#39;n_games&amp;#39;, ascending = False)
    .reset_index()) # this adds the group by variables (now index) as a column

res = res.dropna()

(p9.ggplot(data = res.query(&amp;#39;n_games &amp;gt; 10&amp;#39;), 
            mapping = p9.aes(y = &amp;#39;reorder(race_name, avg_foul)&amp;#39;, x = &amp;#39;avg_foul&amp;#39;, 
                            size = &amp;#39;n_games&amp;#39;, color = &amp;#39;factor(ruleset_version)&amp;#39;, 
                            shape = &amp;#39;factor(tv_bin2)&amp;#39;))
    + p9.geom_point()
    + p9.scale_size_area() 
    + p9.ggtitle(&amp;quot;average number of fouls per game BB2016 vs BB2020&amp;quot;)
    + p9.ylab(&amp;quot;&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-03-20_nufflytics_blog_post_files/nufflytics_blog_post_17_1.png&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;ggplot: (8734504437775)&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From this plot, we can see that BB2020 indeed shows increased fouling across the board. As expected, the Black Orcs are high up in the fouling charts, and we see large increases in fouling for Underworld, Goblins, Halflings and Snotlings. We can also see that as teams develop, fouling typically increases, possible related to developing a specialized fouling player with the sneaky git skill. For humans access to cheap agile halfling hopefulls with access to sneaky git increased fouling opportunity. In Orc teams goblins can forfill this role.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;competitive-division-win-rates-and-malta-eurobowl-2022-tiers&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Competitive division win rates and Malta Eurobowl 2022 tiers&lt;/h1&gt;
&lt;p&gt;Last but not least, a win rate analysis. In a tournament setting, elaborate tiering systems are in place to compensate for differences in race strength, skills are selected from skill packs, and player casualties are forgotten with each match played with a “resurrected” fresh team. Furthermore, opponents are randomly assigned and must be played. Contrast this with the FUMBBL Competitive division: Here teams start with 1M gold and without any extra skills. Teams must be developed, like in a league, and opponents can be strategically chosen based on which race they play, their coach rating etc.&lt;/p&gt;
&lt;p&gt;With all this in mind, I tried the impossible: to compare relative team strength as expected by the tournament tiers, with the observed win rates in the Competitive Division. With the Eurobowl 2022 in Malta coming up, I decided to approximate the conditions of that rulepack. Teams are created using 1.15M gold, as well as roughly 36 SPP worth of skills. This translates to 6 primary skills worth 20K, giving us a total team value of 1270K, say around 1.3M.&lt;/p&gt;
&lt;p&gt;To correct for differences in coaching ability, I restricted the match selection for matches where coach ratings are not too different (&amp;lt; 10), and above 150. I excluded matches involving Star players, and mirror matches (I.e. Orcs vs Orcs).
To distinguish the relatively small % differences in win rate, we need to have a bandwidth around 1.3M to get sufficient statistics for each team.
I included confidence intervals to visualize the statistical uncertainty for the win rates.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Function for computing confidence intervals
from statsmodels.stats.proportion import proportion_confint   

divisions = [&amp;#39;Competitive&amp;#39;]

tv_bins = [&amp;#39;1.2M&amp;#39;, &amp;#39;1.3M&amp;#39;, &amp;#39;1.4M&amp;#39;]

res = (df_mbt[df_mbt[&amp;#39;division_name&amp;#39;].isin(divisions)]
    .loc[df_mbt[&amp;#39;tv_bin2&amp;#39;].isin(tv_bins)]
    .query(&amp;#39;mirror_match == 0 &amp;amp; has_sp == 0 &amp;amp; CR_diff &amp;lt; 10 &amp;amp; coach_CR &amp;gt; 150&amp;#39;)
    .groupby([&amp;#39;race_name&amp;#39;, &amp;#39;ruleset_version&amp;#39;, &amp;#39;Malta_2022&amp;#39;])
    .agg(        
        perc_win = (&amp;#39;wins&amp;#39;, &amp;quot;mean&amp;quot;),
        n_wins = (&amp;#39;wins&amp;#39;, &amp;quot;sum&amp;quot;),
        n_games = (&amp;#39;race_name&amp;#39;, &amp;quot;count&amp;quot;)
    )
    .query(&amp;#39;n_games &amp;gt; 0&amp;#39;)
    .reset_index()) # this adds the group by variable (now index) as a column

res[&amp;#39;lower_CI&amp;#39;], res[&amp;#39;upper_CI&amp;#39;] =  proportion_confint(
                                      count = round(res[&amp;#39;n_wins&amp;#39;]).astype(int),
                                      nobs = res[&amp;#39;n_games&amp;#39;],
                                      alpha = 0.05
                                  )

(p9.ggplot(data = res.query(&amp;#39;n_games &amp;gt; 30&amp;#39;), 
            mapping = p9.aes(x = &amp;#39;reorder(race_name, -Malta_2022)&amp;#39;, y = &amp;#39;perc_win&amp;#39;, 
            size = &amp;#39;n_games&amp;#39;, color = &amp;#39;factor(Malta_2022)&amp;#39;))
    + p9.geom_linerange(p9.aes(ymin = &amp;#39;lower_CI&amp;#39;, ymax = &amp;#39;upper_CI&amp;#39;), size = 1)
    + p9.geom_point()
    + p9.scale_size_area() 
    + p9.coord_flip()
    + p9.geom_hline(yintercept = 0.5)
    + p9.ggtitle(&amp;quot;FUMBBL BB2020 win rates around 1.3M&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-03-20_nufflytics_blog_post_files/nufflytics_blog_post_20_0.png&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;ggplot: (-9223363302334269892)&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First off, I think the most important lesson here is that it is really difficult to compare win rates across such different settings.&lt;/p&gt;
&lt;p&gt;But what info can we squeeze from this plot nevertheless:&lt;/p&gt;
&lt;p&gt;It seems that Amazon and Underworld have higher FUMBBL win rates than expected based on their Malta 2022 tier.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For Amazon, this might be due to being able to avoid particular opponents on FUMBBL, such as Dwarves and Chaos Dwarves, with a lot of Tackle.&lt;/li&gt;
&lt;li&gt;For Underworld, this is likely related to their improvements in BB2020, leading the charts at NAF tournaments, that resulted in recent rule changes that weakened them with the November 2021 Games Workshop ruling.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What else do we got:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nurgle has a relatively low win rate compared to other teams with the same tier.&lt;/li&gt;
&lt;li&gt;High Elf has a low tier, but shows an above average win rate, and appears to perform well at NAF tournaments. Curious to see how this race will do this year.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;concluding-remarks-and-acknowledgements&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Concluding Remarks and acknowledgements&lt;/h1&gt;
&lt;p&gt;The analyses above hopefully give you some idea what can be with the rich FUMMBL data available.&lt;/p&gt;
&lt;p&gt;One last application: The data can also be used to search for matches based on highly particular search criteria: for example, if you are interested in Snotling matches that induce Morg N Thorg and play against a skilled Elf coach. The &lt;code&gt;match_id&lt;/code&gt; can then be used to watch the replay on FUMBBL.&lt;/p&gt;
&lt;p&gt;Finally, some acknowledgements. While writing this blog, I drew inspiration from several sources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;most notable the &lt;a href=&#34;https://www.fumbbl.com&#34;&gt;FUMBBL website itself&lt;/a&gt; that has a wealth of statistics available,&lt;/li&gt;
&lt;li&gt;the &lt;a href=&#34;https://fumbbldata.azurewebsites.net/stats.html&#34;&gt;website of FUMBBL coach Koadah&lt;/a&gt; with aggregated FUMBBL stats,&lt;/li&gt;
&lt;li&gt;the &lt;a href=&#34;https://public.tableau.com/app/profile/mike.sann0638.davies/viz/TheNAFReport/Games&#34;&gt;NAF monthly reports&lt;/a&gt; by Mike Davies,&lt;/li&gt;
&lt;li&gt;a &lt;a href=&#34;https://bloodbowlstrategies.com/en/relative-strength-of-teams/&#34;&gt;blog post on team strength&lt;/a&gt; by Taureau Amiral ,&lt;/li&gt;
&lt;li&gt;the &lt;a href=&#34;https://nufflytics.com&#34;&gt;Nufflytics blog&lt;/a&gt; by Blood Bowl 2 coach Schlice,&lt;/li&gt;
&lt;li&gt;the various technical posts of &lt;a href=&#34;https://fumbbl.com/~SzieberthAdam&#34;&gt;FUMBBL coach Adam Szieberth&lt;/a&gt; who followed a similar approach using Python API and web scraping FUMBBL data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Using R to analyse the Roche Antigen Rapid Test: How accurate is it?</title>
      <link>/post/covid_antigen_test_reliability/</link>
      <pubDate>Sun, 06 Jun 2021 00:00:00 +0000</pubDate>
      <guid>/post/covid_antigen_test_reliability/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;&lt;em&gt;(Image is from a different antigen test)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Many people are suspicious about the reliability of rapid self-tests, so I decided to check it out.
For starters, I LOVE measurement. It is where learning from data starts, with technology and statistics involved.
With this post, I’d like to join the swelling ranks of amateur epidemiologists :) I have spent a few years in a molecular biology lab, that should count for something right?&lt;/p&gt;
&lt;p&gt;At home, we now have a box of the &lt;strong&gt;SARS-CoV-2 Rapid Antigen Test Nasal&lt;/strong&gt; kit.
The kit is distributed by Roche, and manufactured in South Korea by a company called SD Biosensor.&lt;/p&gt;
&lt;p&gt;So how reliable is it? A practical approach is to compare it to the golden standard, the PCR test, that public health test centers use to detect COVID-19. Well, the leaflet of the kit describes three experiments that do exactly that!
So I tracked down the data mentioned in the kit’s leaflet, and decided to check them out.&lt;/p&gt;
&lt;p&gt;But before we analyze the data, you want to know how they were generated, right? RIGHT?
For this we use cause-effect diagrams (a.k.a. DAGs), which we can quickly draw using &lt;a href=&#34;http://dagitty.net&#34;&gt;DAGitty&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;a-causal-model-of-the-measurement-process&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A causal model of the measurement process&lt;/h1&gt;
&lt;p&gt;The cool thing about DAGitty is that we can use a point-n-click interface to draw the diagram, and then export code that contains an exact description of the graph to include in R. (You can also view the &lt;a href=&#34;http://dagitty.net/dags.html?id=whqGBx&#34;&gt;graph for this blog post at DAGitty.net&lt;/a&gt;):&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021_05_14_covid_rapid_test_reliability_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The graph is based on the following description of the various cause-effect pairs:&lt;/p&gt;
&lt;p&gt;It all starts with whether someone is infected. After infection, virus particles start to build up. These particles can be in the lungs, in the throat, nose etc.
These particles either do or do not cause symptoms. Whether there are symptoms will likely influence the decision to test, but there will also be people without symptoms that will be tested (i.e. if a family member was tested positive).&lt;/p&gt;
&lt;p&gt;In the experiments we analyze, two samples were taken, one for the PCR test and one for the antigen test. The way the samples were taken differed as well: “shallow” nose swabs for the rapid antigen test, and a combination of “deep” nose and throat swabs for the PCR test.&lt;/p&gt;
&lt;p&gt;Now that we now a bit about the measurement process, lets look at how the accuracy of the antigen test is quantified.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;quantifying-the-accuracy-of-an-covid-19-test&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Quantifying the accuracy of an COVID-19 test&lt;/h1&gt;
&lt;p&gt;The PCR test result serves as the ground truth, the standard to which the antigen test is compared.
Both tests are binary tests, either it detects the infection or it does not (to a first approximation).&lt;/p&gt;
&lt;p&gt;For this type of outcome, two concepts are key: the &lt;strong&gt;sensitivity&lt;/strong&gt; (does the antigen test detect COVID when the PCR test has detected it) and &lt;strong&gt;specificity&lt;/strong&gt; of the test (does the antigen test ONLY detect COVID, or also other flu types or even unrelated materials, for which the PCR test produces a negative result).&lt;/p&gt;
&lt;p&gt;The leaflet contains information on both.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sensitivity 83.3% (95%CI: 74.7% - 90.0%)&lt;/li&gt;
&lt;li&gt;Specificity 99.1% (95%CI: 97.7% - 99.7%)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But what does this really tell us? And where do these numbers come from?&lt;/p&gt;
&lt;p&gt;Before we go to the data, we first need to know a bit more detail on what we are actually trying to measure, the viral load, and what factors influence this variable.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;viral-load-as-target-for-measurement&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Viral load as target for measurement&lt;/h1&gt;
&lt;p&gt;So, both tests work by detecting viral particles in a particular sample. The amount of virus particles present in the sample depends on, among others:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Time since infection&lt;/li&gt;
&lt;li&gt;How and where the sample is taken (throat, nose, lungs, using a swab etc)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’ll discuss both.&lt;/p&gt;
&lt;div id=&#34;time-since-infection&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Time since infection&lt;/h2&gt;
&lt;p&gt;When you have just been infected, your body will contain only a small amount of virus.
The &lt;strong&gt;viral load&lt;/strong&gt; is a function of time since infection, because it takes time for the virus to multiply itself. Even PCR cannot detect an infection on the first day, and even after 8 days, there are still some 20% of cases that go undetected by PCR (presumably because the amount of viral particle is too low) (Ref: Kucirka et al 2020).&lt;/p&gt;
&lt;p&gt;If you want to know more about the ability of PCR to detect COVID infections go check out &lt;a href=&#34;https://github.com/HopkinsIDD/covidRTPCR&#34;&gt;the covidRTPCR Github repository&lt;/a&gt;. It is completely awesome, with open data, open code, and Bayesian statistics using &lt;a href=&#34;https://mc-stan.org/&#34;&gt;Stan&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-and-where-the-sample-is-taken&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How and where the sample is taken&lt;/h2&gt;
&lt;p&gt;There are many ways to obtain a sample from a person.&lt;/p&gt;
&lt;p&gt;Here the golden standard is a so-called &lt;strong&gt;Nasopharyngeal swab&lt;/strong&gt;. This goes through your nose all the way (~ 5 cm) into the back of the throat, and is highly uncomfortable. Typically, only professional health workers perform &lt;strong&gt;nasopharyngeal&lt;/strong&gt; swabs.
In these experiments, this deep nose swab was combined with a swab from the throat (&lt;strong&gt;oroharyngeal&lt;/strong&gt;). This is also how test centers in the Netherlands operated during the last year.&lt;/p&gt;
&lt;p&gt;There are various alternatives: We have spit, saliva, we can cough up “sputum” (slime from the lungs) or we can take swab from the front part of the nose (“nasal”).&lt;/p&gt;
&lt;p&gt;The Roche antigen test is a &lt;strong&gt;nasal&lt;/strong&gt; test that only goes up to 2 cm in the nose and can be used by patients themselves (“self-collected”).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;the-dataset-results-from-the-three-berlin-studies&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The dataset: results from the three Berlin studies&lt;/h1&gt;
&lt;p&gt;Now that we have some background info, we are ready to check the data!&lt;/p&gt;
&lt;p&gt;As mentioned above, this data came from three experiments on samples from in total 547 persons.&lt;/p&gt;
&lt;p&gt;After googling a bit, I found out that the experiments were performed by independent researchers in a famous University hospital in Berlin, &lt;a href=&#34;https://de.wikipedia.org/wiki/Charit%C3%A9&#34;&gt;Charité&lt;/a&gt;. After googling a bit more and mailing with one of the researchers involved, Dr. Andreas Lindner, I received a list of papers that describe the research mentioned in the leaflet (References at the end of this post).&lt;/p&gt;
&lt;p&gt;The dataset for the blog post compares &lt;strong&gt;nasal&lt;/strong&gt; samples tested with the Roche Antigen test kit, to PCR-tested &lt;strong&gt;nasopharyngeal&lt;/strong&gt; plus &lt;strong&gt;oropharyngeal&lt;/strong&gt; samples taken by professionals.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This blog post is possible because the three papers by Lindner and co-workers all contain the raw data as a table in the paper. Cool!&lt;/strong&gt;
Unfortunately, this means the data is not &lt;strong&gt;machine readable&lt;/strong&gt;. However, with a combination of manual tweaking / find-replace and some coding, I tidied the data of the three studies into a single &lt;code&gt;tibble&lt;/code&gt; data frame. You can grab the code and data from my &lt;a href=&#34;https://github.com/gsverhoeven/hugo_source/tree/master/content/post/sars_test&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;UPDATE&lt;/strong&gt;: Rein Halbersma showed me how to use web scraping to achieve the same result, with a mere 20 lines of code of either Python or R! Cool! I added his scripts to my &lt;a href=&#34;https://github.com/gsverhoeven/hugo_source/tree/master/content/post/sars_test&#34;&gt;Github&lt;/a&gt; as well, go check them out, I will definitely go this route next time.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# creates df_pcr_pos
source(&amp;quot;sars_test/dataprep_roche_test.R&amp;quot;)

# creates df_leaflet
source(&amp;quot;sars_test/dataprep_roche_test_leaflet.R&amp;quot;)

# see below
source(&amp;quot;sars_test/bootstrap_conf_intervals.R&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The dataset &lt;code&gt;df_pcr_pos&lt;/code&gt; contains, for each &lt;strong&gt;PCR positive&lt;/strong&gt; patient:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ct_value&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;viral_load&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;days_of_symptoms&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mm_value&lt;/code&gt; (Result of a &lt;strong&gt;nasal&lt;/strong&gt; antigen test measurement, 1 is positive, 0 is negative)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To understand the PCR data, we need to know a bit more about the PCR method.&lt;/p&gt;
&lt;div id=&#34;the-pcr-method&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The PCR method&lt;/h2&gt;
&lt;p&gt;The PCR method not only measures &lt;strong&gt;if&lt;/strong&gt; someone is infected, it also provides an estimate of the viral load in the sample.
How does this work? PCR can amplify, in so-called cycles, really low quantities of viral material in a biological sample. The amount of cycles of the PCR device needed to reach a threshold of signal is called the cycle threshold or &lt;strong&gt;Ct value&lt;/strong&gt;. The less material we have in our sample, the more cycles we need to amplify the signal to reach a certain threshold.&lt;/p&gt;
&lt;p&gt;Because the amplification is an exponential process, if we take the log of the number of virus particles, we get a linear inverse (negative) relationship between &lt;strong&gt;ct_value&lt;/strong&gt; and &lt;strong&gt;viral_load&lt;/strong&gt;. For example, &lt;span class=&#34;math inline&#34;&gt;\(10^6\)&lt;/span&gt; particles is a viral load of 6 on the log10 scale.&lt;/p&gt;
&lt;p&gt;So let’s plot the &lt;code&gt;ct_value&lt;/code&gt; of the PCR test vs the &lt;code&gt;viral_load&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
ggplot(df_pcr_pos, aes(x = ct_value, y = viral_load, color = factor(pcr_assay_type))) + 
  geom_point() + ggtitle(&amp;quot;Calibration curves for viral load (log10 scale)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021_05_14_covid_rapid_test_reliability_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;
This plot shows that &lt;code&gt;viral_load&lt;/code&gt; is directly derived from the &lt;code&gt;ct_value&lt;/code&gt; through a calibration factor.
PCR Ct values of &amp;gt; 35 are considered as the threshold value for detecting a COVID infection using the PCR test, so the values in this plot make sense for COVID positive samples.&lt;/p&gt;
&lt;p&gt;Take some time to appreciate the huge range difference in the samples on display here.
From only 10.000 viral particles (&lt;span class=&#34;math inline&#34;&gt;\(log_{10}{(10^4)} = 4\)&lt;/span&gt; ) to almost 1 billion (&lt;span class=&#34;math inline&#34;&gt;\(log_{10}{(10^9)} = 9\)&lt;/span&gt; ) particles.&lt;/p&gt;
&lt;p&gt;We can also see that apparently, there were two separate PCR assays (test types), each with a separate conversion formula used to obtain the estimated viral load.&lt;/p&gt;
&lt;p&gt;(&lt;strong&gt;N.b.&lt;/strong&gt; The missings for &lt;code&gt;pcr_assay_type&lt;/code&gt; are because for two of three datasets, it was difficult to extract this information from the PDF file. From the plot, we can conclude that for these datasets, the same two assays were used since the values map onto the same two calibration lines)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sensitivity-of-the-antigen-test&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sensitivity of the Antigen test&lt;/h2&gt;
&lt;p&gt;The dataset contains all samples for which the PCR test was positive.
Let’s start by checking the raw percentage of antigen test measurements that are positive as well.
This is called the &lt;strong&gt;sensitivity&lt;/strong&gt; of a test.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res &amp;lt;- df_pcr_pos %&amp;gt;%
  summarize(sensitivity = mean(mm_value), 
            N = n())

res&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   sensitivity     N
##         &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1       0.792   120&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So for all PCR positive samples, 79.2 % is positive as well.
This means that, on average, if we would use the antigen test kit, we have a one in five (20%) probability of not detecting COVID-19, compared to when we would have used the method used by test centers operated by the public health agencies.&lt;/p&gt;
&lt;p&gt;This value is slightly lower, but close to what is mentioned in the Roche kit’s leaflet.&lt;/p&gt;
&lt;p&gt;Let’s postpone evaluation of this fact for a moment and look a bit closer at the data.
For example, we can example the relationship between &lt;code&gt;viral_load&lt;/code&gt; and a positive antigen test result (&lt;code&gt;mm_value&lt;/code&gt; = 1):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(df_pcr_pos$mm_value, df_pcr_pos_np$mm_value)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    
##      0  1
##   0 20  5
##   1  5 90&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
ggplot(df_pcr_pos, aes(x = viral_load, y = mm_value)) + 
  geom_jitter(height = 0.1) +
  geom_smooth() + 
  geom_vline(xintercept = c(5.7, 7), col = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021_05_14_covid_rapid_test_reliability_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;From this plot, we can see that the probability of obtaining a false negative result (&lt;code&gt;mm_value&lt;/code&gt; of 0) on the antigen test decreases as the viral load &lt;strong&gt;of the PCR sample&lt;/strong&gt; increases.&lt;/p&gt;
&lt;p&gt;From the data we also see that before the antigen test to work about half of the time (blue line at 0.5), the PCR sample needs to contain around &lt;span class=&#34;math inline&#34;&gt;\(5 \cdot 10^5\)&lt;/span&gt; viral particles (log10 scale 5.7), and for it to work reliably, we need around &lt;span class=&#34;math inline&#34;&gt;\(10^7\)&lt;/span&gt; particles (“high” viral load) in the PCR sample (which is a combination of &lt;strong&gt;oropharyngeal and nasopharyngeal swab&lt;/strong&gt;). This last bit is important: the researchers did not measure the viral load in the nasal swabs used for the antigen test, these are likely different.&lt;/p&gt;
&lt;p&gt;For really high viral loads, above &lt;span class=&#34;math inline&#34;&gt;\(10^7\)&lt;/span&gt; particles in the &lt;strong&gt;NP/OP sample&lt;/strong&gt;, the probability of a false negative result is only a few percent:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_pcr_pos %&amp;gt;% filter(viral_load &amp;gt;= 7) %&amp;gt;%
  summarize(sensitivity = mean(mm_value), 
            N = n())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   sensitivity     N
##         &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1       0.972    71&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;viral-loads-varies-with-days-of-symptoms&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Viral loads varies with days of symptoms&lt;/h1&gt;
&lt;p&gt;Above, we already discussed that the viral load varies with the time since infection.&lt;/p&gt;
&lt;p&gt;If we want to use the antigen test &lt;strong&gt;instead&lt;/strong&gt; of taking a PCR test, we don’t have information on the viral load. What we often do have is the days since symptoms, and we know that in the first few days of symptoms viral load is highest.&lt;/p&gt;
&lt;p&gt;We can check this by plotting the &lt;code&gt;days_of_symptoms&lt;/code&gt; versus &lt;code&gt;viral_load&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df_pcr_pos, aes(x = days_of_symptoms, y = viral_load)) + 
  geom_smooth() + expand_limits(x = -4) + geom_vline(xintercept = 1, linetype = &amp;quot;dashed&amp;quot;) +
  geom_vline(xintercept = c(3, 7), col = &amp;quot;red&amp;quot;) + geom_hline(yintercept = 7, col = &amp;quot;grey&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) +
  geom_jitter(height = 0, width = 0.2) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021_05_14_covid_rapid_test_reliability_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;
From this plot, we learn that the viral load is highest on the onset of symptoms day (typically 5 days after infection) and decreases afterwards.&lt;/p&gt;
&lt;p&gt;Above, we saw that the sensitivity in the whole sample was not equal to the sensitivity mentioned in the leaflet.
When evaluating rapid antigen tests, sometimes thresholds for days of symptoms are used, for example &amp;lt;= 3 days or &amp;lt;= 7 days (plotted in red).&lt;/p&gt;
&lt;p&gt;For the sensitivity in the leaflet, a threshold of &amp;lt;= 7 days was used on the days of symptoms.&lt;/p&gt;
&lt;p&gt;Let us see how sensitive the antigen test is for these subgroups:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res &amp;lt;- df_pcr_pos %&amp;gt;%
  filter(days_of_symptoms &amp;lt;= 3) %&amp;gt;%
  summarize(label = &amp;quot;&amp;lt; 3 days&amp;quot;,
            sensitivity = mean(mm_value), 
            N = n())

res2 &amp;lt;- df_pcr_pos %&amp;gt;%
  filter(days_of_symptoms &amp;lt;= 7) %&amp;gt;%
  summarize(label = &amp;quot;&amp;lt; 7 days&amp;quot;,
            sensitivity = mean(mm_value), 
            N = n())

bind_rows(res, res2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 3
##   label    sensitivity     N
##   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1 &amp;lt; 3 days       0.857    49
## 2 &amp;lt; 7 days       0.85    100&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The sensitivity in both subgroups is increased to 85.7 % and 85 %.
Now only 1 in 7 cases is missed by the antigen test.
This sensitivity is now very close to that in the leaflet. The dataset in the leaflet has N = 102, whereas here we have N = 100.
Given that the difference is very small, I decided to not look into this any further.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;is-there-a-swab-effect&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Is there a swab effect?&lt;/h1&gt;
&lt;p&gt;Ok, so the rapid antigen test is less sensitive than PCR.
What about the effect of using self-administered nasal swabs, versus professional health workers taking a nasopharyngeal swab (and often a swab in the back of the throat as well)?&lt;/p&gt;
&lt;p&gt;Interestingly, the three Berlin studies all contain a head-to-head comparison of &lt;strong&gt;nasal&lt;/strong&gt; versus &lt;strong&gt;nasopharygeal (NP)&lt;/strong&gt; swabs. Lets have a look, shall we?&lt;/p&gt;
&lt;p&gt;The dataset &lt;code&gt;df_pcr_pos_np&lt;/code&gt; is identical to &lt;code&gt;df_pcr_pos&lt;/code&gt;, but contains the measurement results for the &lt;strong&gt;nasopharygeal&lt;/strong&gt; swabs.&lt;/p&gt;
&lt;p&gt;To compare both measurement methods, we can plot the relationship between the probability of obtaining a positive result versus viral load. If one method gathers systematically more viral load from the patient, we expect that method to detect infection at lower patient viral loads, and the curves (nasal vs NP) would be shifted relative to each other.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)

ggplot(df_pcr_pos_np , aes(x = viral_load, y = mm_value)) + 
  geom_jitter(data = df_pcr_pos, height = 0.05, col = &amp;quot;blue&amp;quot;) +
  geom_jitter(height = 0.05, col = &amp;quot;orange&amp;quot;) +
  geom_smooth(data = df_pcr_pos , col = &amp;quot;blue&amp;quot;) + 
  geom_smooth(col = &amp;quot;orange&amp;quot;) +
  ggtitle(&amp;quot;nasal (blue) versus nasopharyngeal (orange) swabs&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021_05_14_covid_rapid_test_reliability_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;By fitting a smoother through the binary data, we obtain an estimate of the relationship between the probability of obtaining a positive result, and the viral load of the patient as measured by PCR on a combined NP/OP swab.&lt;/p&gt;
&lt;p&gt;From this plot, I conclude that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The sensitivity of a test is strongly dependent on the distribution of viral loads in the population the measurement was conducted in&lt;/li&gt;
&lt;li&gt;There is no evidence for any differences in sensitivity between nasal and nasopharyngeal swabs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This last conclusion came as a surprise for me, as nasopharygeal swabs are long considered to be the golden standard for obtaining samples for PCR detection of respiratory viruses, such as influenza and COVID-19 (Seaman &lt;em&gt;et al.&lt;/em&gt; (2019), (Lee &lt;em&gt;et al.&lt;/em&gt; 2021) ). So let’s look a bit deeper still.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;double-check-rotterdam-vs-berlin&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Double-check: Rotterdam vs Berlin&lt;/h1&gt;
&lt;p&gt;We can compare the results from the three Berlin studies with a recent Dutch study that also used the Roche antigen test (ref: Igloi &lt;em&gt;et al.&lt;/em&gt; 2021). The study was conducted in Rotterdam, and used nasopharygeal swabs to obtain the sample for the antigen test.&lt;/p&gt;
&lt;p&gt;Cool! Lets try and create two comparable groups in both studies so we can compare the sensitivity.&lt;/p&gt;
&lt;p&gt;The Igloi et al. paper reports results for a particular subset that we can also create in the Berlin dataset.
They report that for the subset of samples with high viral load (viral load &lt;span class=&#34;math inline&#34;&gt;\(2.17 \cdot 10^5\)&lt;/span&gt; particles / ml = 5.35 on the log10 scale, ct_value &amp;lt;= 30) &lt;strong&gt;AND&lt;/strong&gt; who presented within 7 days of symptom onset, they found a sensitivity of 95.8% (CI95% 90.5-98.2). The percentage is based on N = 159 persons (or slightly less because of not subsetting on &amp;lt;= 7 days of symptoms, the paper is not very clear here).&lt;/p&gt;
&lt;p&gt;We can check what the sensitivity is for this subgroup in the Berlin dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_pcr_pos %&amp;gt;% filter(viral_load &amp;gt;= 5.35 &amp;amp; days_of_symptoms &amp;lt;= 7) %&amp;gt;%
  summarize(sensitivity = mean(mm_value), 
            N = n())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   sensitivity     N
##         &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1       0.898    88&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the same subgroup of high viral load, sensitivity of the nasal swab test is 6% lower than the nasopharyngeal swab test, across the two studies. But how do we have to weigh this evidence? N = 88 is not so much data, and the studies are not identical in design.&lt;/p&gt;
&lt;p&gt;Importantly, since the threshold to be included in this comparison (ct value &amp;lt;= 30, viral_load &amp;gt; 5.35) contains a large part of the region where the probability of a positive result is between 0 and 1, we need to compare the distributions of viral loads for both studies to make an apples to apples comparison.&lt;/p&gt;
&lt;p&gt;The Igloi study reports their distribution of viral loads for PCR-positive samples (N=186) in five bins (Table 1 in their paper):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cat &amp;lt;- c(&amp;quot;ct &amp;lt;= 20&amp;quot;, &amp;quot;ct 20-25&amp;quot;, &amp;quot;ct 25-30&amp;quot;, &amp;quot;ct 30-35&amp;quot;, &amp;quot;ct 35+&amp;quot;)
counts &amp;lt;- c(31, 82, 46, 27, 1)

ggplot(data.frame(cat, counts), aes(x = cat, y = counts)) +
  geom_col()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021_05_14_covid_rapid_test_reliability_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;
Lets create those same bins in the Berlin dataset as well:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_pcr_pos$ct_bin &amp;lt;- cut(df_pcr_pos$ct_value, breaks = c(-Inf,20,25,30,35,Inf))

ggplot(df_pcr_pos, aes(x = ct_bin)) +
  geom_histogram(stat = &amp;quot;count&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021_05_14_covid_rapid_test_reliability_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;
For the subset where we can compare the sensitivities (ct_value &amp;lt;= 30), the Berlin clinical population has a higher viral load than the Rotterdam clinical population! So that does not explain why the Rotterdam study reports a higher sensitivity.&lt;/p&gt;
&lt;p&gt;I use simulation to create distributions of plausible values for the sensitivity, assuming the observed values in both studies (89.7% for the Berlin studies, and 95.8% for the Rotterdam study) to be the true data generating values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)

# Berlin
sample_size = 88
prior_probability = 0.898

est_p &amp;lt;- rbinom(10000, sample_size, p=prior_probability)/sample_size

# Rotterdam
sample_size2 = 159 # derived from Table 1 (Ct value distribution of PCR+ samples, &amp;lt;= 30)
prior_probability2 = 0.958

est_p2 &amp;lt;- rbinom(10000, sample_size2, p=prior_probability2)/sample_size2

ggplot(data.frame(est_p), aes(x = est_p)) +
  geom_histogram(binwidth = 0.005) +
    geom_histogram(data = data.frame(est_p = est_p2), fill = &amp;quot;gray60&amp;quot;, alpha = 0.5, binwidth = 0.005) +
  geom_vline(xintercept = prior_probability, linetype = &amp;quot;dashed&amp;quot;, col= &amp;quot;red&amp;quot;) +
geom_vline(xintercept = prior_probability2, linetype = &amp;quot;dashed&amp;quot;, col= &amp;quot;blue&amp;quot;) +
  ggtitle(&amp;quot;Berlin (black bars) vs Rotterdam (grey bars) sensitivity for higher viral loads&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021_05_14_covid_rapid_test_reliability_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;
There is a region of overlap between the two distributions, so the difference between the studies could be (in part) attributed to statistical sampling variation for the same underlying process.&lt;/p&gt;
&lt;p&gt;I conclude that the Berlin study, who does a head to head comparison of NP versus nasal swabs, finds them to be highly comparable, and reports sensitivities that are close to those reported by the Rotterdam study.&lt;/p&gt;
&lt;p&gt;Surprisingly, nasal swabs appear to give results that are comparable to those of nasopharyngeal swabs, while having not having the disadvantages of them (unpleasant, can only be performed by professional health worker).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;that-other-metric-the-specificity&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;That other metric: the specificity&lt;/h1&gt;
&lt;p&gt;So far, the discussion centered around the &lt;strong&gt;sensitivity&lt;/strong&gt; of the test.
Equally important is the &lt;strong&gt;specificity&lt;/strong&gt; of the test. This quantifies if the test result of the antigen test is specific for COVID-19. It would be bad if the test would also show a result for other viruses, or even unrelated molecules.&lt;/p&gt;
&lt;p&gt;To examine this, we use the aggregated data supplied on the leaflet from the kit, &lt;code&gt;df_leaflet&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;N.b.&lt;/strong&gt; The aggregated data is a subset of all the data from the three studies, because the data was subsetted for cases with &lt;code&gt;&amp;lt;= 7 days_of_symptoms&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This dataset contains for each sample one of four possibilities:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Both tests are negative,&lt;/li&gt;
&lt;li&gt;both tests are positive,&lt;/li&gt;
&lt;li&gt;the PCR test is positive but the antigen test negative,&lt;/li&gt;
&lt;li&gt;the PCR test is negative but the antigen positive.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We use the &lt;code&gt;yardstick&lt;/code&gt; package of R’s &lt;code&gt;tidymodels&lt;/code&gt; family to create the 2x2 table and analyze the specificity.&lt;/p&gt;
&lt;p&gt;(&lt;strong&gt;Overthinking&lt;/strong&gt;: Note that the &lt;code&gt;yardstick&lt;/code&gt; package is used to quantify the performance of statistical prediction models by comparing the model predictions to the true values contained in the training data. This provides us with an analogy where the antigen test can be viewed as a model that is trying the predict the outcome of the PCR test.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;options(yardstick.event_first = FALSE)

conf_matrix &amp;lt;- yardstick::conf_mat(df_leaflet, pcr_result, ag_result)

autoplot(conf_matrix, 
         type = &amp;quot;heatmap&amp;quot;, 
         title = &amp;quot;Truth = PCR test, Prediction = Antigen test&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021_05_14_covid_rapid_test_reliability_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;288&#34; /&gt;
From the heatmap (confusingly called a confusion matrix among ML practioners), we see that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For most samples (N = 431), both tests are COVID-19 negative.&lt;/li&gt;
&lt;li&gt;85 + 17 = 102 samples tested COVID-19 positive using the PCR-test&lt;/li&gt;
&lt;li&gt;85 out of 102 samples that are PCR positive, are antigen test positive as well&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the specificity, we have to look at the samples where the PCR test is negative, but the antigen test is positive, and compare these to all the samples that are PCR-test negative. These are the number of tests where the antigen test picked up a non-specific signal. One minus this percentage gives the specificity (1 - 4/435 = 431/435):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;yardstick::spec(df_leaflet, pcr_result, ag_result)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 spec    binary         0.991&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thus, we find that the antigen test is highly specific, with around 1% of false positives.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;uncertainty-in-the-estimated-specificity-and-sensitivity&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Uncertainty in the estimated specificity and sensitivity&lt;/h1&gt;
&lt;p&gt;So far, we did not discuss the sampling variability in the estimated specificity and sensitivity.&lt;/p&gt;
&lt;p&gt;The kit leaflet mentions the following confidence intervals:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sensitivity 83.3% (95%CI: 74.7% - 90.0%)&lt;/li&gt;
&lt;li&gt;Specificity 99.1% (95%CI: 97.7% - 99.7%)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The R-package &lt;code&gt;yardstick&lt;/code&gt; does not yet include confidence intervals, so I generated these using bootstrapping. I calculate both metrics for 10.000 samples sampled from the raw data. For brevity I omitted the code here, go check out my &lt;a href=&#34;https://github.com/gsverhoeven/hugo_source/tree/master/content/post/sars_test&#34;&gt;Github&lt;/a&gt; for the R script.&lt;/p&gt;
&lt;p&gt;The bootstrapping approach yields the following range of plausible values given the data (95% interval):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(spec_vec, probs = c(0.025, 0.975))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      2.5%     97.5% 
## 0.9811765 0.9977477&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(sens_vec, probs = c(0.025, 0.975))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      2.5%     97.5% 
## 0.7570030 0.9029126&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The amount of data (N = 537) prevents us from getting an exact match to the leaflet’s confidence intervals, that are based on theoretic formulas. But we do get pretty close.&lt;/p&gt;
&lt;p&gt;Especially for the sensitivity, there is quite some uncertainty, we see that plausible values range from 76% up to 90% &lt;em&gt;for this particular cohort of cases with this particular mix of viral loads that showed up during the last four months of 2020 in the University hospital in Berlin&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;To summarise: we found that the numbers of the kit’s leaflet are reliable, reproducible, and published in full detail in the scientific literature.
Hurray!&lt;/p&gt;
&lt;p&gt;We also found that even the gold standard PCR is not able to detect all infected persons, it all depends on how much virus is present, and how the sample is obtained.&lt;/p&gt;
&lt;p&gt;But all in all, the PCR test is clearly more accurate. Why would we want to use an antigen test then?
To do the PCR test you need a lab with skilled people, equipment such as PCR devices and pipets, and time, as the process takes at least a few hours to complete. The advantage of an antigen test is to have a low-tech, faster alternative that can be self-administered. But that comes at a cost, because the antigen tests are less sensitive.&lt;/p&gt;
&lt;p&gt;From the analysis, it is clear that the rapid Antigen tests need more virus present to reliably detect infection. It is ALSO clear that the test is highly specific, with less than 1% false positives. Note that a false positive rate of 1% still means that in a healthy population of 1000, 10 are falsely detected as having COVID-19.&lt;/p&gt;
&lt;p&gt;Surprisingly, nasal swabs appear to give results that are comparable to those of nasopharyngeal swabs, while having not having the disadvantages of them (unpleasant, can only be performed by professional health worker).&lt;/p&gt;
&lt;p&gt;So the antigen tests are less sensitive than PCR tests. But now comes the key insight: the persons that produce the largest amounts of virus get detected, irrespective of whether they have symptoms or not. To me, this seems like a “Unique Selling Point” of the rapid tests: the ability to rapidly detect the most contagious persons in a group, after which these persons can go into quarantine and help reduce spread.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to dr. Andreas Lindner for providing helpful feedback and pointing out flaws in my original blog post. This should not be seen as an endorsement of the conclusions of this post, and any remaining mistakes are all my own!&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Head-to-head comparison of SARS-CoV-2 antigen-detecting rapid test with self-collected nasal swab versus professional-collected nasopharyngeal swab&lt;/em&gt;:
Andreas K. Lindner, Olga Nikolai, Franka Kausch, Mia Wintel, Franziska Hommes, Maximilian Gertler, Lisa J. Krüger, Mary Gaeddert, Frank Tobian, Federica Lainati, Lisa Köppel, Joachim Seybold, Victor M. Corman, Christian Drosten, Jörg Hofmann, Jilian A. Sacks, Frank P. Mockenhaupt, Claudia M. Denkinger, &lt;a href=&#34;https://erj.ersjournals.com/content/57/4/2003961&#34;&gt;European Respiratory Journal 2021 57: 2003961&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Head-to-head comparison of SARS-CoV-2 antigen-detecting rapid test with professional-collected nasal versus nasopharyngeal swab&lt;/em&gt;:
Andreas K. Lindner, Olga Nikolai, Chiara Rohardt, Susen Burock, Claudia Hülso, Alisa Bölke, Maximilian Gertler, Lisa J. Krüger, Mary Gaeddert, Frank Tobian, Federica Lainati, Joachim Seybold, Terry C. Jones, Jörg Hofmann, Jilian A. Sacks, Frank P. Mockenhaupt, Claudia M. Denkinger &lt;a href=&#34;https://erj.ersjournals.com/content/57/5/2004430&#34;&gt;European Respiratory Journal 2021 57: 2004430&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;SARS-CoV-2 patient self-testing with an antigen-detecting rapid test: a head-to-head comparison with professional testing&lt;/em&gt;:
Andreas K. Lindner, Olga Nikolai, Chiara Rohardt, Franka Kausch, Mia Wintel, Maximilian Gertler, Susen Burock, Merle Hörig, Julian Bernhard, Frank Tobian, Mary Gaeddert, Federica Lainati, Victor M. Corman, Terry C. Jones, Jilian A. Sacks, Joachim Seybold, Claudia M. Denkinger, Frank P. Mockenhaupt, under review, &lt;a href=&#34;https://www.medrxiv.org/content/10.1101/2021.01.06.20249009v1&#34;&gt;preprint on medrxiv.org&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Variation in False-Negative Rate of Reverse Transcriptase Polymerase Chain Reaction–Based SARS-CoV-2 Tests by Time Since Exposure&lt;/em&gt;: Lauren M. Kucirka, Stephen A. Lauer, Oliver Laeyendecker, Denali Boon, Justin Lessler &lt;a href=&#34;https://www.acpjournals.org/doi/full/10.7326/M20-1495&#34;&gt;Link to paper&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Clinical evaluation of the Roche/SD Biosensor rapid antigen test with symptomatic, non-hospitalized patients in a municipal health service drive-through testing site&lt;/em&gt;:
Zsὁfia Iglὁi, Jans Velzing, Janko van Beek, David van de Vijver, Georgina Aron, Roel Ensing, KimberleyBenschop, Wanda Han, Timo Boelsums, Marion Koopmans, Corine Geurtsvankessel, Richard Molenkamp &lt;a href=&#34;https://www.medrxiv.org/content/10.1101/2020.11.18.20234104v1&#34;&gt;Link on medrxiv.org&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Performance of Saliva, Oropharyngeal Swabs, and Nasal Swabs for SARS-CoV-2 Molecular Detection: a Systematic Review and Meta-analysis&lt;/em&gt;:
Rose A. Lee, Joshua C. Herigona, Andrea Benedetti, Nira R. Pollock, Claudia M. Denkinger &lt;a href=&#34;https://journals.asm.org/doi/10.1128/JCM.02881-20&#34;&gt;Link to paper&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Self-collected compared with professional-collected swabbing in the diagnosis of influenza in symptomatic individuals: A meta-analysis and assessment of validity&lt;/em&gt;:
Seaman et al 2019 &lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/31400670/&#34;&gt;Link to paper&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Simulating Fake Data in R</title>
      <link>/post/simulating-fake-data/</link>
      <pubDate>Sat, 26 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/post/simulating-fake-data/</guid>
      <description>
&lt;link href=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This blog post is on simulating fake data. I&#39;m interested in creating synthetic versions of real datasets. For example if the data is too sensitive to be shared, or we only have summary statistics available (for example tables from a published research paper).&lt;/p&gt;
&lt;p&gt;If we want to mimic an existing dataset, it is desirable to&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make sure that the simulated variables have the proper data type and comparable distribution of values and&lt;/li&gt;
&lt;li&gt;correlations between the variables in the real dataset are taken into account.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition, it would be nice if such functionality is available in a standard R package. After reviewing several R packages that can simulate data, I picked the &lt;a href=&#34;https://www.rdatagen.net/page/simstudy/&#34;&gt;simstudy&lt;/a&gt; package as most promising to explore in more detail. &lt;code&gt;simstudy&lt;/code&gt; is created by &lt;strong&gt;Keith Goldfeld&lt;/strong&gt; from New York University.&lt;/p&gt;
&lt;p&gt;In this blog post, I explain how &lt;code&gt;simstudy&lt;/code&gt; is able to generate correlated variables, having either continuous or binary values. Along the way, we learn about fancy statistical slang such as copula&#39;s and tetrachoric correlations. It turns out there is a close connection with psychometrics, which we&#39;ll briefly discuss.&lt;/p&gt;
&lt;p&gt;Let&#39;s start with correlated continuous variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Loading required packages
library(simstudy)
library(data.table)
library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;copulas-simulating-continuous-correlated-variables&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Copulas: Simulating continuous correlated variables&lt;/h1&gt;
&lt;p&gt;Copulas are a fancy word for correlated (&amp;quot;coupled&amp;quot;) variables that each have a uniform distribution between 0 and 1.&lt;/p&gt;
&lt;p&gt;Using copulas, we can convert correlated multivariate normal data to data from any known continuous probability distribution, while keeping exactly the same correlation matrix. The normal data is something we can easily simulate, and by choosing appropriate probability distributions, we can approximate the variables in real datasets.&lt;/p&gt;
&lt;p&gt;Ok let&#39;s do it!&lt;/p&gt;
&lt;div id=&#34;step-1-correlated-multivariate-normal-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 1: correlated multivariate normal data&lt;/h2&gt;
&lt;p&gt;The workhorse for our simulated data is a function to simulate multivariate normal data. We&#39;ll use the &lt;code&gt;MASS&lt;/code&gt; package function &lt;code&gt;mvrnorm()&lt;/code&gt;. Other slightly faster (factor 3-4) implementations exist, see e.g. &lt;code&gt;mvnfast&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The trick is to first generate multivariate normal data with the required correlation structure, with mean 0 and standard deviation 1. This gives us correlated data, where each variable is marginally (by itself) normal distributed.&lt;/p&gt;
&lt;p&gt;Here I simulate two variables, but the same procedure holds for N variables. The Pearson correlation is set at &lt;code&gt;0.7&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)

corr &amp;lt;- 0.7

cov.mat &amp;lt;- matrix(c(1, corr, 
                  corr, 1), nrow = 2)

df &amp;lt;- data.frame(MASS::mvrnorm(n = 1e4, 
                               mu = c(0, 0), 
                               Sigma = cov.mat))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(The diagonal of &lt;code&gt;1&lt;/code&gt; makes sure the variables have SD of 1. The off diagonal value of 0.7 gives us a Pearson correlation of 0.7)&lt;/p&gt;
&lt;p&gt;Did it work?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df, aes(x = X1, y = X2)) +
  geom_point(alpha = 0.3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-31-simulating-fake-data-in-R_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(df$X1, df$X2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.6985089&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-transform-variables-to-uniform-distribution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 2: transform variables to uniform distribution&lt;/h2&gt;
&lt;p&gt;Using the normal cumulative distribution function &lt;code&gt;pnorm()&lt;/code&gt;, we can transform our normally distributed variables to have a uniform distribution, while keeping the correlation structure intact!!!!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df$X1_U &amp;lt;- pnorm(df$X1)
df$X2_U &amp;lt;- pnorm(df$X2)

ggplot(df, aes(x = X1_U)) + geom_histogram(boundary = 0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-31-simulating-fake-data-in-R_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df, aes(x = X1_U, y = X2_U)) +
  geom_point(alpha = 0.3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-31-simulating-fake-data-in-R_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And here&#39;s our copula! Two variables, each marginally (by itself) uniform, but with pre-specified correlation intact!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(df$X1_U, df$X2_U)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.677868&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3-from-uniform-to-any-standard-probability-distribution-we-like&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 3: from uniform to any standard probability distribution we like&lt;/h2&gt;
&lt;p&gt;Now, if we plug in uniformly distributed data in a &lt;strong&gt;quantile function&lt;/strong&gt; of any arbitrary (known) probability distribution, we can make the variables have any distribution we like.&lt;/p&gt;
&lt;p&gt;Let&#39;s pick for example a &lt;strong&gt;Gamma&lt;/strong&gt; distribution (Continuous, positive) with shape 4 and rate 1 for X1, and Let&#39;s pick a &lt;strong&gt;Normal&lt;/strong&gt; distribution (Continuous, symmetric) with mean 10 and sd 2 for X2.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df$X1_GAM &amp;lt;- qgamma(df$X1_U, shape = 4, rate =1)
df$X2_NORM &amp;lt;- qnorm(df$X2_U, mean = 10, sd = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df, aes(x = X1_GAM)) + 
  geom_histogram(boundary = 0) +
  geom_vline(xintercept = 4, col = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-31-simulating-fake-data-in-R_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df, aes(x = X2_NORM)) + 
  geom_histogram(boundary = 0) +
  geom_vline(xintercept = 10, col = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-31-simulating-fake-data-in-R_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Ok, that worked nicely. But what about their correlation?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(df$X1_GAM, df$X2_NORM)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.682233&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Whoa!! They still have (almost) the same correlation we started out with before all our transformation magic.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;simstudy-in-action&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simstudy in action&lt;/h1&gt;
&lt;p&gt;Now let&#39;s see how &lt;code&gt;simstudy&lt;/code&gt; helps us generating this type of simulated data. Simstudy works with &amp;quot;definition tables&amp;quot; that allow us to specify, for each variable, which distribution and parameters to use, as well as the desired correlations between the variables.&lt;/p&gt;
&lt;p&gt;After specifing a definition table, we can call one of its workhorse functions &lt;code&gt;genCorFlex()&lt;/code&gt; to generate the data.&lt;/p&gt;
&lt;p&gt;N.b. Simstudy uses different parameters for the Gamma distribution, compared to R&#39;s &lt;code&gt;rgamma()&lt;/code&gt; function. Under water, it uses the &lt;code&gt;gammaGetShapeRate()&lt;/code&gt; to transform the &amp;quot;mean&amp;quot; and &amp;quot;variance/ dispersion&amp;quot; to the more conventional &amp;quot;shape&amp;quot; and &amp;quot;rate&amp;quot; parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)

corr &amp;lt;- 0.7

corr.mat &amp;lt;- matrix(c(1, corr, 
                  corr, 1), nrow = 2)

# check that gamma parameters correspond to same shape and rate pars as used above
#simstudy::gammaGetShapeRate(mean = 4, dispersion = 0.25)


def &amp;lt;- defData(varname = &amp;quot;X1_GAM&amp;quot;, 
               formula = 4, variance = 0.25, dist = &amp;quot;gamma&amp;quot;)

def &amp;lt;- defData(def, varname = &amp;quot;X2_NORM&amp;quot;, 
               formula = 10, variance = 2, dist = &amp;quot;normal&amp;quot;)



dt &amp;lt;- genCorFlex(1e4, def, corMatrix = corr.mat)

cor(dt[,-&amp;quot;id&amp;quot;])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            X1_GAM   X2_NORM
## X1_GAM  1.0000000 0.6823006
## X2_NORM 0.6823006 1.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(dt, aes(x = X1_GAM)) + 
  geom_histogram(boundary = 0) +
  geom_vline(xintercept = 4, col = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-31-simulating-fake-data-in-R_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;generate-correlated-binary-variables&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Generate correlated binary variables&lt;/h1&gt;
&lt;p&gt;As it turns out, the copula approach does not work for binary variables. Well, it sort of works, but the correlations we get are lower than we actually specify.&lt;/p&gt;
&lt;p&gt;Come to think of it: two binary variables cannot have all the correlations we like. To see why, check this out.&lt;/p&gt;
&lt;div id=&#34;feasible-correlations-for-two-binary-variables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Feasible correlations for two binary variables&lt;/h2&gt;
&lt;p&gt;Let&#39;s suppose we have a binary variable that equals 1 with probability 0.2, and zero otherwise. This variable will never be fully correlated with a binary variable that equals 1 with probability 0.8, and zero otherwise.&lt;/p&gt;
&lt;p&gt;To see this, I created two binary vectors that have a fraction 0.2 and 0.8 of 1&#39;s, and let&#39;s see if we can arrange the values in both vectors in such a way that minimizes and maximizes their correlation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# maximal correlation
x1 &amp;lt;- c(0, 0, 0, 0, 1)
x2 &amp;lt;- c(0, 1, 1, 1, 1)

mean(x1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(x2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(x1, x2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.25&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# minimal correlation
x1 &amp;lt;- c(1, 0, 0, 0, 0)
x2 &amp;lt;- c(0, 1, 1, 1, 1)

cor(x1, x2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To get these vectors to be maximally correlated, we need to match &lt;code&gt;1&lt;/code&gt;&#39;s in &lt;code&gt;x1&lt;/code&gt; as much as possible with &lt;code&gt;1&lt;/code&gt;s in &lt;code&gt;x2&lt;/code&gt;. To get these vectors to be maximally anti-correlated, we need to match &lt;code&gt;1&lt;/code&gt;s in &lt;code&gt;x1&lt;/code&gt; with as many &lt;code&gt;0&lt;/code&gt;s in &lt;code&gt;x2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In this example, we conclude that the feasible correlation range is &lt;code&gt;{-1, 0.25}&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;simstudy&lt;/code&gt; package contains a function to check for feasible boundaries, that contains this piece of code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 &amp;lt;- 0.2
p2 &amp;lt;- 0.8

# lowest correlation
l &amp;lt;- (p1 * p2)/((1 - p1) * (1 - p2))

max(-sqrt(l), -sqrt(1/l))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# highest correlation
u &amp;lt;- (p1 * (1 - p2))/(p2 * (1 - p1))

min(sqrt(u), sqrt(1/u))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.25&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This confirms our example above.&lt;/p&gt;
&lt;p&gt;Note that if we want to mimic a real dataset with binary correlated variables, the correlations are a given, and are obviously all feasible because we obtain them from actual data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-model-for-two-correlated-binary-variables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A model for two correlated binary variables&lt;/h2&gt;
&lt;p&gt;Ok let&#39;s suppose we want a two binary vectors &lt;code&gt;B1&lt;/code&gt; and &lt;code&gt;B2&lt;/code&gt; , with means &lt;code&gt;p1 = 0.2&lt;/code&gt; and &lt;code&gt;p2 = 0.8&lt;/code&gt; and (feasible) Pearson correlation 0.1.&lt;/p&gt;
&lt;p&gt;How? How?&lt;/p&gt;
&lt;p&gt;The idea is that to get two binary variables to have an exact particular correlation, we imagine an underlying (&amp;quot;latent&amp;quot;) bivariate (2D) normal distribution. This normal distribution has the means fixed to 0, and the standard deviations fixed to 1.&lt;/p&gt;
&lt;p&gt;Why? Because a) we know it very well theoretically and b) we know how to simulate efficiently from such a distribution, using &lt;code&gt;mvrnorm()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In this bivariate normal distribution, we draw a quadrant (i.e. two thresholds). The thresholds define transformations to binary variables. Below the threshold, the binary value is 0, above it is 1. We have to pick the thresholds such that the resulting binary variables have the desired mean (i.e. percentage of 1&#39;s).&lt;/p&gt;
&lt;p&gt;This approach reduces the problem to finding the right values of three parameters: multivariate normal correlation, and the two thresholds (above, we already fixed the means and variance to zero and one respectively).&lt;/p&gt;
&lt;p&gt;For now, we&#39;ll just pick some value for the correlation in the bivariate normal, say 0.5, and focus on where to put the threshholds.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)

corr &amp;lt;- 0.5

cov.mat &amp;lt;- matrix(c(1, corr, 
                  corr, 1), nrow = 2)

df &amp;lt;- data.frame(MASS::mvrnorm(n = 10000, 
                               mu = c(0, 0), 
                               Sigma = cov.mat))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(The diagonal of &lt;code&gt;1&lt;/code&gt; makes sure the variables have SD of 1. The off diagonal value of 0.7 gives us a Pearson correlation of 0.7)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df, aes(x = X1, y = X2)) +
  geom_point(alpha = 0.3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-31-simulating-fake-data-in-R_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Ok, where to put the thresholds? That&#39;s simple, we just need to use the &lt;code&gt;quantile distribution function&lt;/code&gt; to partition the marginal normal variables into 0 and 1 portions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df$B1 &amp;lt;- ifelse(df$X1 &amp;lt; qnorm(0.2), 1, 0)
df$B2 &amp;lt;- ifelse(df$X2 &amp;lt; qnorm(0.8), 1, 0)

mean(df$B1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.197&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(df$B2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7988&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&#39;s check it out visually:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df, aes(x = X1, y = X2)) +
  geom_point(alpha = 0.3) + 
  geom_vline(xintercept = qnorm(0.2), col = &amp;quot;red&amp;quot;) +
  geom_hline(yintercept = qnorm(0.8), col = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-31-simulating-fake-data-in-R_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Nice.&lt;/p&gt;
&lt;p&gt;Ok, so now what is the correlation for these two binary variables?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(df$B1, df$B2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1877482&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, so if X1 and X2 have a correlation of 0.5, this results in a correlation of 0.19 between the binary variables B1 and B2.&lt;/p&gt;
&lt;p&gt;But we need B1 and B2 to have a correlation of 0.1!&lt;/p&gt;
&lt;p&gt;At this point, there is only one free parameter left, the correlation of the normally distributed variables &lt;code&gt;X1&lt;/code&gt; and &lt;code&gt;X2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We could of course manually try to find which correlation we must choose between &lt;code&gt;X1&lt;/code&gt; and &lt;code&gt;X2&lt;/code&gt; to get the desired correlation of 0.1 in the binary variables. But that would be very unpractical.&lt;/p&gt;
&lt;p&gt;Fortunately, Emrich and Piedmonte (1991) published an iterative method to solve this puzzle. And this method has been implemented in &lt;code&gt;simstudy&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simstudy:::.findRhoBin(p1 = 0.2, 
                       p2 = 0.8, d = 0.1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2218018&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&#39;s see if it works:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)

corr &amp;lt;- 0.2218018

cov.mat &amp;lt;- matrix(c(1, corr, 
                  corr, 1), nrow = 2)

df &amp;lt;- data.frame(MASS::mvrnorm(n = 1e6, 
                               mu = c(0, 0), 
                               Sigma = cov.mat))

df$B1 &amp;lt;- ifelse(df$X1 &amp;lt; qnorm(0.2), 1, 0)
df$B2 &amp;lt;- ifelse(df$X2 &amp;lt; qnorm(0.8), 1, 0)

cor(df$B1, df$B2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.09957392&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;relation-to-psychometrics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Relation to psychometrics&lt;/h1&gt;
&lt;p&gt;So what has psychometrics to do with all this simulation of correlated binary vector stuff?&lt;/p&gt;
&lt;p&gt;Well, psychometrics is all about theorizing about unobserved, latent, imaginary &amp;quot;constructs&amp;quot;, such as &lt;strong&gt;attitude&lt;/strong&gt;, &lt;strong&gt;general intelligence&lt;/strong&gt; or a &lt;strong&gt;personality trait&lt;/strong&gt;. To measure these constructs, questionnaires are used. The questions are called &lt;strong&gt;items&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Now imagine a situation where we are interested in a particular construct, say &lt;strong&gt;general intelligence&lt;/strong&gt;, and we design two questions to measure (hope to learn more about) the construct. Furthermore, assume that one question is more difficult than the other question. The answers to both questions can either be wrong or right.&lt;/p&gt;
&lt;p&gt;We can model this by assuming that the (imaginary) variable &amp;quot;intelligence&amp;quot; of each respondent is located on a two-dimensional plane, with the distribution of the respondents determined by a bivariate normal distribution. Dividing this plane into four quadrants then gives us the measurable answers (right or wrong) to both questions. Learning the answers to both questions then gives us an approximate location of a respondent on our &amp;quot;intelligence&amp;quot; plane!&lt;/p&gt;
&lt;div id=&#34;phi-tetrachoric-correlation-and-the-psych-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Phi, tetrachoric correlation and the psych package&lt;/h2&gt;
&lt;p&gt;Officially, the Pearson correlation between two binary vectors is called the &lt;a href=&#34;https://en.wikipedia.org/wiki/Phi_coefficient&#34;&gt;Phi coefficient&lt;/a&gt;. This name was actually chosen by Karl Pearson himself.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;psych&lt;/strong&gt; packages contains a set of convenient functions for calculating Phi coefficients from empirical two by two tables (of two binary vectors), and finding the corresponding Pearson coefficient for the 2d (latent) normal. This coefficient is called the &lt;strong&gt;tetrachoric correlation&lt;/strong&gt;. Again a fine archaic slang word for again a basic concept.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(psych)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;psych&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:ggplot2&amp;#39;:
## 
##     %+%, alpha&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert simulated binary vectors B1 and B2 to 2x2 table
twobytwo &amp;lt;- table(df$B1, df$B2)/nrow(df)

phi(twobytwo, digits = 6)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.099574&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(df$B1, df$B2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.09957392&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# both give the same result&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can use &lt;strong&gt;phi2tetra&lt;/strong&gt; to find the tetrachoric correlation that corresponds to the combination of a &amp;quot;Phi coefficient&amp;quot;, i.e. the correlation between the two binary vectors, as well as their marginals. This is a wrapper that builds the two by two frequency table and then calls &lt;code&gt;tetrachoric()&lt;/code&gt; . This in turn uses &lt;code&gt;optimize&lt;/code&gt; (Maximum Likelihood method?) to find the tetrachoric correlation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;phi2tetra(0.1, c(0.2, 0.8))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2217801&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# compare with EP method
simstudy:::.findRhoBin(0.2, 0.8, 0.1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2218018&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Comparing with the Emrich and Piedmonte method, we find that they give identical answers. Great, case closed!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;simstudy-in-action-ii&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simstudy in action II&lt;/h1&gt;
&lt;p&gt;Now that we feel confident in our methods and assumptions, let&#39;s see &lt;code&gt;simstudy&lt;/code&gt; in action.&lt;/p&gt;
&lt;p&gt;Let&#39;s generate two binary variables, that have marginals of 20% and 80% respectively, and a Pearson correlation coefficient of 0.1.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
corr &amp;lt;- 0.1

corr.mat &amp;lt;- matrix(c(1, corr, 
                  corr, 1), nrow = 2)

res &amp;lt;- simstudy::genCorGen(10000, nvars = 2, 
                 params1 = c(0.2, 0.8),
                 corMatrix = corr.mat,
                 dist = &amp;quot;binary&amp;quot;, 
                 method = &amp;quot;ep&amp;quot;, wide = TRUE)

# let&amp;#39;s check the result
cor(res[, -c(&amp;quot;id&amp;quot;)])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            V1         V2
## V1 1.00000000 0.09682531
## V2 0.09682531 1.00000000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Awesome, it worked!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Recall, my motivation for simulating fake data with particular variable types and correlation structure is to mimic real datasets.&lt;/p&gt;
&lt;p&gt;So are we there yet? Well, we made some progress. We now can handle correlated continuous data, as well as correlated binary data.&lt;/p&gt;
&lt;p&gt;But we need to solve two more problems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;To simulate a particular dataset, we still need to determine for each variable its data type (binary or continuous), and if it&#39;s continuous, what is the most appropriate probability distribution (Normal, Gamma, Log-normal, etc).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;we haven&#39;t properly solved correlation between dissimilar data types, e.g. a correlation between a continuous and a binary variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Judging from the literature (Amatya &amp;amp; Demirtas 2016) and packages such as &lt;code&gt;SimMultiCorrData&lt;/code&gt; by Allison Fialkowski, these are both solved, and I only need to learn about them! So, to be continued.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Exploring Process Mining in R</title>
      <link>/post/exploring-process-mining/</link>
      <pubDate>Thu, 20 Jun 2019 00:00:00 +0000</pubDate>
      <guid>/post/exploring-process-mining/</guid>
      <description>
&lt;link href=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In this post, we&#39;ll explore the &lt;a href=&#34;https://www.bupar.net&#34;&gt;BupaR&lt;/a&gt; suite of &lt;em&gt;Process Mining&lt;/em&gt; packages created by &lt;em&gt;Gert Janssenswillen&lt;/em&gt; from Hasselt University.&lt;/p&gt;
&lt;p&gt;We start with exploring the &lt;code&gt;patients&lt;/code&gt; dataset contained in the &lt;code&gt;eventdataR&lt;/code&gt; package. According to the documentation, this is an &amp;quot;Artifical eventlog about patients&amp;quot;.&lt;/p&gt;
&lt;div id=&#34;getting-started&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Getting started&lt;/h1&gt;
&lt;p&gt;After installing all required packages, we can load the whole &amp;quot;bupaverse&amp;quot; by loading the &lt;code&gt;bupaR&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(bupaR)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in library(package, lib.loc = lib.loc, character.only = TRUE,
## logical.return = TRUE, : there is no package called &amp;#39;xesreadR&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in library(package, lib.loc = lib.loc, character.only = TRUE,
## logical.return = TRUE, : there is no package called &amp;#39;processmonitR&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in library(package, lib.loc = lib.loc, character.only = TRUE,
## logical.return = TRUE, : there is no package called &amp;#39;petrinetR&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(processmapR)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, our dataset is already in &lt;code&gt;eventlog&lt;/code&gt; format, but typically this not the case. Here&#39;s how to turn a data.frame into an object of class &lt;code&gt;eventlog&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;patients &amp;lt;- eventdataR::patients

df &amp;lt;- eventlog(patients,
               case_id = &amp;quot;patient&amp;quot;,
               activity_id = &amp;quot;handling&amp;quot;,
               activity_instance_id = &amp;quot;handling_id&amp;quot;,
               lifecycle_id = &amp;quot;registration_type&amp;quot;,
               timestamp = &amp;quot;time&amp;quot;,
               resource_id = &amp;quot;employee&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: The `add` argument of `group_by()` is deprecated as of dplyr 1.0.0.
## Please use the `.add` argument instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&#39;s check it out.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Number of events:  5442
## Number of cases:  500
## Number of traces:  7
## Number of distinct activities:  7
## Average trace length:  10.884
## 
## Start eventlog:  2017-01-02 11:41:53
## End eventlog:  2018-05-05 07:16:02&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                   handling      patient          employee  handling_id       
##  Blood test           : 474   Length:5442        r1:1000   Length:5442       
##  Check-out            : 984   Class :character   r2:1000   Class :character  
##  Discuss Results      : 990   Mode  :character   r3: 474   Mode  :character  
##  MRI SCAN             : 472                      r4: 472                     
##  Registration         :1000                      r5: 522                     
##  Triage and Assessment:1000                      r6: 990                     
##  X-Ray                : 522                      r7: 984                     
##  registration_type      time                         .order    
##  complete:2721     Min.   :2017-01-02 11:41:53   Min.   :   1  
##  start   :2721     1st Qu.:2017-05-06 17:15:18   1st Qu.:1361  
##                    Median :2017-09-08 04:16:50   Median :2722  
##                    Mean   :2017-09-02 20:52:34   Mean   :2722  
##                    3rd Qu.:2017-12-22 15:44:11   3rd Qu.:4082  
##                    Max.   :2018-05-05 07:16:02   Max.   :5442  
## &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we learn that there are 500 &amp;quot;cases&amp;quot;, i.e. patients. There are 7 different activities.&lt;/p&gt;
&lt;p&gt;Let&#39;s check out the data for a single patient:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df %&amp;gt;% filter(patient == 1) %&amp;gt;% 
  arrange(handling_id) #%&amp;gt;% &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Log of 12 events consisting of:
## 1 trace 
## 1 case 
## 6 instances of 6 activities 
## 6 resources 
## Events occurred from 2017-01-02 11:41:53 until 2017-01-09 19:45:45 
##  
## Variables were mapped as follows:
## Case identifier:     patient 
## Activity identifier:     handling 
## Resource identifier:     employee 
## Activity instance identifier:    handling_id 
## Timestamp:           time 
## Lifecycle transition:        registration_type 
## 
## # A tibble: 12 x 7
##    handling patient employee handling_id registration_ty… time               
##    &amp;lt;fct&amp;gt;    &amp;lt;chr&amp;gt;   &amp;lt;fct&amp;gt;    &amp;lt;chr&amp;gt;       &amp;lt;fct&amp;gt;            &amp;lt;dttm&amp;gt;             
##  1 Registr… 1       r1       1           start            2017-01-02 11:41:53
##  2 Registr… 1       r1       1           complete         2017-01-02 12:40:20
##  3 Blood t… 1       r3       1001        start            2017-01-05 08:59:04
##  4 Blood t… 1       r3       1001        complete         2017-01-05 14:34:27
##  5 MRI SCAN 1       r4       1238        start            2017-01-05 21:37:12
##  6 MRI SCAN 1       r4       1238        complete         2017-01-06 01:54:23
##  7 Discuss… 1       r6       1735        start            2017-01-07 07:57:49
##  8 Discuss… 1       r6       1735        complete         2017-01-07 10:18:08
##  9 Check-o… 1       r7       2230        start            2017-01-09 17:09:43
## 10 Check-o… 1       r7       2230        complete         2017-01-09 19:45:45
## 11 Triage … 1       r2       501         start            2017-01-02 12:40:20
## 12 Triage … 1       r2       501         complete         2017-01-02 22:32:25
## # … with 1 more variable: .order &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt; # select(handling, handling_id, registration_type) # does not work&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We learn that each &amp;quot;handling&amp;quot; has a separate start and complete timestamp.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;traces&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Traces&lt;/h1&gt;
&lt;p&gt;The summary info of the event log also counts so-called &amp;quot;traces&amp;quot;. A trace is defined a unique sequence of events in the event log. Apparently, there are only seven different traces (possible sequences). Let&#39;s visualize them.&lt;/p&gt;
&lt;p&gt;To visualize all traces, we set &lt;code&gt;coverage&lt;/code&gt; to 1.0.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df %&amp;gt;% processmapR::trace_explorer(type = &amp;quot;frequent&amp;quot;, coverage = 1.0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `rename_()` is deprecated as of dplyr 0.7.0.
## Please use `rename()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-01-23-exploring-process-mining_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt; So there are a few traces (0.6%) that do not end with a check-out. Ignoring these rare cases, we find that there are two types of cases:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cases that get an X-ray&lt;/li&gt;
&lt;li&gt;Cases that get a blood test followed by an MRI scan&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;the-dotted-chart&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The dotted chart&lt;/h1&gt;
&lt;p&gt;A really powerful visualization in process mining comes in the form of a &amp;quot;dotted chart&amp;quot;. The dotted chart function produces a &lt;code&gt;ggplot&lt;/code&gt; graph, which is nice, because so we can actually tweak the graph as we can with regular ggplot objects.&lt;/p&gt;
&lt;p&gt;It has two nice use cases. The first is when we plot actual time on the x-axis, and sort the cases by starting date.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df %&amp;gt;% dotted_chart(x = &amp;quot;absolute&amp;quot;, sort = &amp;quot;start&amp;quot;) + ggtitle(&amp;quot;All cases&amp;quot;) +
  theme_gray()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;patient&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-01-23-exploring-process-mining_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The slope of this graphs learns us the rate of new cases, and if this changes over time. Here it appears constant, with 500 cases divided over five quarter years.&lt;/p&gt;
&lt;p&gt;The second is to align all cases relative to the first event, and sort on duration of the whole sequence of events.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df %&amp;gt;% dotted_chart(x = &amp;quot;relative&amp;quot;, sort = &amp;quot;duration&amp;quot;) + ggtitle(&amp;quot;All cases&amp;quot;) +
  theme_gray()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;patient&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-01-23-exploring-process-mining_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A nice pattern emerges, where all cases start with registration, then quickly proceed to triage and assessment, after that, a time varying period of 1-10 days follows where either the blood test + MRI scan, or the X-ray is performed, followed by discussing the results. Finally, check out occurs.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;To conclude, the process mining approach to analyze time series event data appears highly promising. The dotted chart is a great addition to my data visualization repertoire, and the process mining folks appear to have at lot more goodies, such as Trace Alignment.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
