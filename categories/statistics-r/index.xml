<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistics, R | Gertjan Verhoeven</title>
    <link>/categories/statistics-r/</link>
      <atom:link href="/categories/statistics-r/index.xml" rel="self" type="application/rss+xml" />
    <description>Statistics, R</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2019, 2020</copyright><lastBuildDate>Sun, 06 Jun 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Statistics, R</title>
      <link>/categories/statistics-r/</link>
    </image>
    
    <item>
      <title>A close examination of the Roche Rapid Antigen Test Nasal: How reliable is it?</title>
      <link>/post/covid_antigen_test_reliability/</link>
      <pubDate>Sun, 06 Jun 2021 00:00:00 +0000</pubDate>
      <guid>/post/covid_antigen_test_reliability/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Many people are suspicious about the reliability of rapid self-tests, so I decided to check it out.
For starters, I LOVE measurement. It is where learning from data starts, with technology involved, and models.
With this post, I’d like to join the swelling ranks of amateur epidemiologists :) I have spent a few years in a molecular biology lab, that should count for something right?&lt;/p&gt;
&lt;p&gt;At home, we now have a box of the &lt;code&gt;SARS-CoV-2 Rapid Antigen Test Nasal&lt;/code&gt; kit.
The kit is distributed by Roche, but manufactured in South Korea by a company called SD Biosensor.&lt;/p&gt;
&lt;p&gt;So where to start? We can make a small causal model of the measurement process using &lt;a href=&#34;http://dagitty.net/dags.html?id=whqGBx&#34;&gt;DAGitty&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021_05_14_covid_rapid_test_reliability_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It all starts with whether someone is infected. After infection, virus particles start to build up. These particles can be in the lungs, in the throat, nose etc.
These particles either do or do not cause symptoms. Whether there are symptoms will likely influence the decision to test (do a nose swab), but there will also be people without symptoms that will be tested (i.e. if a family member was tested positive).&lt;/p&gt;
&lt;p&gt;In the experiments we analyse, two samples were taken, one for the PCR test and one for the antigen test.&lt;/p&gt;
&lt;p&gt;To do the PCR test you need a lab with skilled people, equipment such as PCR devices and pipets, and some time, as the process takes at least a few hours to complete.
The advantage of an antigen test, such as the kit from Roche, is to have a low-tech, faster alternative that can be self-administered.
But that comes at a cost, because the antigen tests are less sensitive.
How much less? Lets find out.&lt;/p&gt;
&lt;div id=&#34;information-on-the-leaflet&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Information on the leaflet&lt;/h1&gt;
&lt;p&gt;The leaflet contains information on the &lt;strong&gt;sensitivity&lt;/strong&gt; (does it detect COVID when you are infected) and &lt;strong&gt;specificity&lt;/strong&gt; of the test
(does it ONLY detect COVID, or also other flu types or even unrelated materials).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sensitivity 83.3% (95%CI: 74.7% - 90.0%)&lt;/li&gt;
&lt;li&gt;Specificity 99.1% (95%CI: 97.7% - 99.7%)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But what does this really tell us? And where do these numbers come from?&lt;/p&gt;
&lt;p&gt;According to the leaflet, this data came from three experiments on samples from in total 547 persons. After googling a bit, I found out that the experiments were performed by independent researchers in a famous University hospital in Berlin, &lt;a href=&#34;https://de.wikipedia.org/wiki/Charit%C3%A9&#34;&gt;Charité&lt;/a&gt;. After googling a bit more and mailing with one of the researchers involved, Prof. Andreas Lindner, I received a list of papers that describe the research mentioned in the leaflet (References at the end of this post).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;viral-load-as-target-for-measurement&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Viral load as target for measurement&lt;/h1&gt;
&lt;p&gt;As already mentioned, both tests work by detecting viral particles in a particular sample. The amount of virus particles present in the sample depends on, for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Time since infection&lt;/li&gt;
&lt;li&gt;How and where the sample is taken (throat, nose, lungs, using a swab etc)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’ll discuss both.&lt;/p&gt;
&lt;div id=&#34;time-since-infection&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Time since infection&lt;/h2&gt;
&lt;p&gt;When you have just been infected, your body will contain only a small amount of virus.
The &lt;strong&gt;viral load&lt;/strong&gt; is a function of time since infection, because it takes time for the virus to multiply itself. Even PCR cannot detect an infection on the first day, and even after 8 days, there are still some 20% of cases that go undetected by PCR (presumably because the amount of viral particle is too low) (source: covidRTPCR Github repo).&lt;/p&gt;
&lt;p&gt;If you want to know more about the ability of PCR to detect COVID go check out &lt;a href=&#34;https://github.com/HopkinsIDD/covidRTPCR&#34;&gt;the covidRTPCR Github repository&lt;/a&gt;. It is completely awesome, with open data, open code, and Bayesian statistics using &lt;a href=&#34;https://mc-stan.org/&#34;&gt;Stan&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-and-where-the-sample-is-taken&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How and where the sample is taken&lt;/h2&gt;
&lt;p&gt;There are many ways to obtain a sample from a person.&lt;/p&gt;
&lt;p&gt;Here the golden standard is a so-called &lt;strong&gt;Nasopharyngeal swab&lt;/strong&gt;. This goes through your nose all the way (~ 5 cm) into the back of the throat, and is highly uncomfortable. Typically, only professional health workers perform &lt;strong&gt;nasopharyngeal&lt;/strong&gt; swabs.
In these experiments, this deep nose swab was combined with a swab from the throat (&lt;strong&gt;oroharyngeal&lt;/strong&gt;). This is also how test centers in the Netherlands operated during the last year.&lt;/p&gt;
&lt;p&gt;There are various alternatives: We have spit, saliva, we can cough up “sputum” (slime from the lungs) or we can take swab from the nose (“nasal”) or from the throat (“oral”).&lt;/p&gt;
&lt;p&gt;The Roche antigen test is a &lt;strong&gt;nasal&lt;/strong&gt; test that only goes up to 2 cm in the nose and can be used by patients themselves (“self-collected”).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;the-dataset-results-from-the-three-berlin-studies&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The dataset: results from the three Berlin studies&lt;/h1&gt;
&lt;p&gt;Now that we have some background info, we are ready to check the data!&lt;/p&gt;
&lt;p&gt;The dataset for the blog post compares &lt;strong&gt;nasal&lt;/strong&gt; samples tested with the Roche Antigen test kit, to PCR-tested &lt;strong&gt;nasopharyngeal&lt;/strong&gt; plus &lt;strong&gt;oropharyngeal&lt;/strong&gt; samples taken by professionals.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This blog post is possible because the three papers all contain the raw data as a table in the paper. Cool!&lt;/strong&gt;
Unfortunately, this means the data is not &lt;strong&gt;machine readable&lt;/strong&gt;. However, with a combination of manual tweaking / find-replace and some coding, I tidied the data of the three studies into a single &lt;code&gt;tibble&lt;/code&gt; data frame. You can grab the code and data from my &lt;a href=&#34;https://github.com/gsverhoeven/hugo_source/tree/master/content/post/sars_test&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# creates df_pcr_pos
source(&amp;quot;sars_test/dataprep_roche_test.R&amp;quot;)

# creates df_leaflet
source(&amp;quot;sars_test/dataprep_roche_test_leaflet.R&amp;quot;)

# see below
source(&amp;quot;sars_test/bootstrap_conf_intervals.R&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The dataset &lt;code&gt;df_pcr_pos&lt;/code&gt; contains, for each &lt;strong&gt;PCR positive&lt;/strong&gt; patient:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ct_value&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;viral_load&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;days_of_symptoms&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mm_value&lt;/code&gt; (Result of the antigen test measurement, 1 is positive, 0 is negative)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To understand the PCR data, we need to know a bit more about the PCR method.&lt;/p&gt;
&lt;div id=&#34;the-pcr-method&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The PCR method&lt;/h2&gt;
&lt;p&gt;The PCR method not only measures &lt;strong&gt;if&lt;/strong&gt; someone is infected, it also provides an estimate of the viral load in the sample.
How does this work? PCR can amplify, in so-called cycles, really low quantities of viral material in a biological sample. The amount of cycles of the PCR device needed to reach a threshold of signal is called the cycle threshold or &lt;strong&gt;Ct value&lt;/strong&gt;. The less material we have in our sample, the more cycles we need to amplify the signal to reach a certain threshold.&lt;/p&gt;
&lt;p&gt;Because the amplification is an exponential process, if we take the log of the number of virus particles, we get a linear inverse (negative) relationship between &lt;strong&gt;ct_value&lt;/strong&gt; and &lt;strong&gt;viral_load&lt;/strong&gt;. For example, &lt;span class=&#34;math inline&#34;&gt;\(10^6\)&lt;/span&gt; particles is a viral load of 6 on the log10 scale.&lt;/p&gt;
&lt;p&gt;So let’s plot the &lt;code&gt;ct_value&lt;/code&gt; of the PCR test vs the viral load:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
ggplot(df_pcr_pos, aes(x = ct_value, y = viral_load, color = factor(pcr_assay_type))) + 
  geom_point() + ggtitle(&amp;quot;Calibration curves for viral load (log10 scale)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021_05_14_covid_rapid_test_reliability_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;
This plot shows that &lt;code&gt;viral_load&lt;/code&gt; is directly derived from the &lt;code&gt;ct_value&lt;/code&gt; through a calibration factor.
PCR Ct values of &amp;gt; 35 are considered as the threshold value for detecting a COVID infection using the PCR test, so the values in this plot make sense for COVID positive samples.&lt;/p&gt;
&lt;p&gt;Take some time to appreciate the huge range difference in the samples on display here.
From only 10.000 viral particles (&lt;span class=&#34;math inline&#34;&gt;\(log_{10}{(10^4)} = 4\)&lt;/span&gt; ) to almost 1 billion (&lt;span class=&#34;math inline&#34;&gt;\(log_{10}{(10^9)} = 9\)&lt;/span&gt; ) particles.&lt;/p&gt;
&lt;p&gt;We can also see that apparently, there were two separate PCR assays (test types), each with a separate conversion formula used to obtain the estimated viral load.&lt;/p&gt;
&lt;p&gt;(&lt;strong&gt;N.b.&lt;/strong&gt; The missings for &lt;code&gt;pcr_assay_type&lt;/code&gt; are because for two of three datasets, it was difficult to extract this information from the PDF file. From the plot, we can conclude that for these datasets, the same two assays were used since the values map onto the same two calibration lines)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sensitivity-of-the-antigen-test&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sensitivity of the Antigen test&lt;/h2&gt;
&lt;p&gt;The dataset contains all samples for which the PCR test was positive.
Let’s start by checking the raw percentage of antigen test measurements that are positive as well.
This is called the &lt;strong&gt;sensitivity&lt;/strong&gt; of a test.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res &amp;lt;- df_pcr_pos %&amp;gt;%
  summarize(sensitivity = mean(mm_value), 
            N = n())

res&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   sensitivity     N
##         &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1       0.792   120&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So for all PCR positive samples, 79.1666667 % is positive as well.
This means that, on average, if we would use the antigen test kit, we have a one in five (20%) probability of not detecting COVID-19, compared to when we would have used the method used by test centers operated by the public health agencies.&lt;/p&gt;
&lt;p&gt;This value is slightly lower, but close to what is mentioned in the Roche kit’s leaflet.&lt;/p&gt;
&lt;p&gt;Let’s postpone evaluation of this fact for a moment and look a bit closer at the data.
For example, we can example the relationship between viral load and a positive antigen test result (&lt;code&gt;mm_value&lt;/code&gt; = 1):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
ggplot(df_pcr_pos, aes(x = viral_load, y = mm_value)) + 
  geom_jitter(height = 0.1) +
  geom_smooth() + 
  geom_vline(xintercept = c(5.7, 7), col = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021_05_14_covid_rapid_test_reliability_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;
From this plot, we can see that the probability of obtaining a False negative result (&lt;code&gt;mm_value&lt;/code&gt; of 0) on the Antigen test decreases as the viral load &lt;em&gt;of the PCR sample&lt;/em&gt; increases.&lt;/p&gt;
&lt;p&gt;From the data we also see that before the antigen test to work about half of the time (blue line at 0.5), the &lt;strong&gt;nasopharyngeal swab&lt;/strong&gt; needs to contain around &lt;span class=&#34;math inline&#34;&gt;\(5 \cdot 10^5\)&lt;/span&gt; viral particles (log10 scale 5.7), and for it to work reliably, we need around &lt;span class=&#34;math inline&#34;&gt;\(10^7\)&lt;/span&gt; particles (“high” viral load) in the &lt;strong&gt;oro- + naso-pharyngeal swab&lt;/strong&gt;. This last bit is important: the researchers did not measure the viral load in the nasal swabs used for the antigen test, these could well be lower.&lt;/p&gt;
&lt;p&gt;For really high viral loads, above &lt;span class=&#34;math inline&#34;&gt;\(10^7\)&lt;/span&gt; particles in the &lt;strong&gt;NP/OP sample&lt;/strong&gt;, the probability of a false negative result is only a few percent:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_pcr_pos %&amp;gt;% filter(viral_load &amp;gt;= 7) %&amp;gt;%
  summarize(sensitivity = mean(mm_value), 
            N = n())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   sensitivity     N
##         &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1       0.972    71&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;viral-loads-varies-with-days-of-symptoms&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Viral loads varies with days of symptoms&lt;/h1&gt;
&lt;p&gt;Above, we already discussed that the viral load varies with the time since infection.&lt;/p&gt;
&lt;p&gt;If we want to use the antigen test &lt;strong&gt;INSTEAD&lt;/strong&gt; of taking a PCR test, we don’t have information on the viral load. What we often do have is the days since symptoms, and we know that in the first few days of symptoms viral load is highest.&lt;/p&gt;
&lt;p&gt;We can check this by plotting the &lt;code&gt;days_of_symptoms&lt;/code&gt; versus &lt;code&gt;viral_load&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df_pcr_pos, aes(x = days_of_symptoms, y = viral_load)) + 
  geom_smooth() + expand_limits(x = -4) + geom_vline(xintercept = 1, linetype = &amp;quot;dashed&amp;quot;) +
  geom_vline(xintercept = c(3, 7), col = &amp;quot;red&amp;quot;) + geom_hline(yintercept = 7, col = &amp;quot;grey&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) +
  geom_jitter(height = 0, width = 0.2) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021_05_14_covid_rapid_test_reliability_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;
From this plot, we learn that the viral load is highest on the onset of symptoms day (typically 5 days after infection) and decreases afterwards.&lt;/p&gt;
&lt;p&gt;Above, we saw that the sensitivity in the whole sample was not equal to the sensitivity mentioned in the leaflet.
When evaluating rapid antigen tests, sometimes thresholds for days of symptoms are used, for example &amp;lt;= 3 days or &amp;lt;= 7 days (plotted in red).&lt;/p&gt;
&lt;p&gt;For the sensitivity in the leaflet, a threshold of &amp;lt;= 7 days was used on the days of symptoms.&lt;/p&gt;
&lt;p&gt;Let us see how sensitive the antigen test is for these subgroups:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res &amp;lt;- df_pcr_pos %&amp;gt;%
  filter(days_of_symptoms &amp;lt;= 3) %&amp;gt;%
  summarize(label = &amp;quot;&amp;lt; 3 days&amp;quot;,
            sensitivity = mean(mm_value), 
            N = n())

res2 &amp;lt;- df_pcr_pos %&amp;gt;%
  filter(days_of_symptoms &amp;lt;= 7) %&amp;gt;%
  summarize(label = &amp;quot;&amp;lt; 7 days&amp;quot;,
            sensitivity = mean(mm_value), 
            N = n())

bind_rows(res, res2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 3
##   label    sensitivity     N
##   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1 &amp;lt; 3 days       0.857    49
## 2 &amp;lt; 7 days       0.85    100&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The sensitivity in both subgroups is increased to 85.7142857 % and 85 %.
Now only 1 in 7 cases is missed by the antigen test.
This sensitivity is now very close to that in the leaflet. The dataset in the leaflet has N = 102, whereas here we have N = 100.
Given that the difference is very small, I decided to not look into this any further.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;nasal-vs-nasopharyngeal-swabs&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Nasal vs nasopharyngeal swabs&lt;/h1&gt;
&lt;p&gt;There exists also a version of the Roche kit that uses nasopharyngeal swabs.
A recent Dutch Study, with samples from a test center in Rotterdam, used this kit (ref: Igloi et al 2021).
For the subset of samples with high viral load (ct_value &amp;lt; 30) AND who presented within 7 days of symptom onset, they found a sensitivity of 95.8% (CI95% 90.5-98.2).&lt;/p&gt;
&lt;p&gt;We can check what the sensitivity is for this subgroup in the Berlin dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_pcr_pos %&amp;gt;% filter(viral_load &amp;gt;= 5.7 &amp;amp; days_of_symptoms) %&amp;gt;%
  summarize(sensitivity = mean(mm_value), 
            N = n())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   sensitivity     N
##         &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1       0.894    94&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The sensitivity of the nasal swab test is 7% lower (ignoring statistical uncertainty).&lt;/p&gt;
&lt;p&gt;These results are consistent with a recent systematic study by Lee et al, who find that&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Three specimen types captured lower % positives (Nasal Swabs [82%, 95% CI: 73 to 90%], oropharyngeal swabs [84%, 95% CI: 57 to 100%], and saliva [88%, 95% CI: 81 to 93%]) than nasopharyngeal swabs&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This is important to realize: a large portion of the reduction in sensitivity is caused by the way the sample is taken, not by using a different device!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;specificity&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Specificity&lt;/h1&gt;
&lt;p&gt;So far, the discussion centered around the &lt;strong&gt;sensitivity&lt;/strong&gt; of the test.
Equally important is the &lt;strong&gt;specificity&lt;/strong&gt; of the test. This quantifies if the test result of the antigen test is specific for COVID-19. It would be bad if the test would also show a result for other viruses, or even unrelated molecules.&lt;/p&gt;
&lt;p&gt;To examine this, we use the aggregated data supplied on the leaflet from the kit, &lt;code&gt;df_leaflet&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;N.b.&lt;/strong&gt; The data from the leaflet is a subset of all the data from the three studies, because the data was subsetted for cases with &lt;code&gt;&amp;lt;= 7 days_of_symptoms&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This dataset contains for each sample one of four possibilities:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Both tests are negative,&lt;/li&gt;
&lt;li&gt;both tests are positive,&lt;/li&gt;
&lt;li&gt;the PCR test is positive but the antigen test negative,&lt;/li&gt;
&lt;li&gt;the PCR test is negative but the antigen positive.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We use the &lt;code&gt;yardstick&lt;/code&gt; package of R&lt;code&gt;s&lt;/code&gt;tidymodels` family to create the 2x2 table and analyze the specificity.&lt;/p&gt;
&lt;p&gt;(&lt;strong&gt;Overthinking&lt;/strong&gt;: Note that the &lt;code&gt;yardstick&lt;/code&gt; package is used to quantify the performance of statistical prediction models by comparing the model predictions to the true values contained in the training data. This provides us with an analogy where the antigen test can be viewed as a model that is trying the predict the outcome of the PCR test.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;options(yardstick.event_first = FALSE)

conf_matrix &amp;lt;- yardstick::conf_mat(df_leaflet, pcr_result, ag_result)

autoplot(conf_matrix, type = &amp;quot;heatmap&amp;quot;, title = &amp;quot;Truth = PCR test, Prediction = Antigen test&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021_05_14_covid_rapid_test_reliability_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;288&#34; /&gt;
From the heatmap (confusingly called a confusion matrix), we see that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For most samples (N = 431), both tests are COVID-19 negative.&lt;/li&gt;
&lt;li&gt;85 + 17 = 102 samples tested COVID-19 positive using the PCR-test&lt;/li&gt;
&lt;li&gt;85 out of 102 samples that are PCR positive, are antigen test positive as well&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the specificity, we have to look at the samples were the PCR test is negative, but the antigen test is positive, and compare these to all the samples that are PCR-test negative. These are the number of tests where the antigen test picked up a non-specific signal. One minus this percentage gives the specificity (1 - 4/435 = 431/435):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;yardstick::spec(df_leaflet, pcr_result, ag_result)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 spec    binary         0.991&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thus, we find that the antigen test is highly specific, with around 1% of false positives.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;specificity-and-sensitivity-credible-intervals-consistent-with-the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Specificity and Sensitivity: credible intervals consistent with the data&lt;/h1&gt;
&lt;p&gt;So far, we did not discuss the sampling variability in the estimated specificity and sensitivity.&lt;/p&gt;
&lt;p&gt;The kit leaflet mentions the following confidence intervals:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sensitivity 83.3% (95%CI: 74.7% - 90.0%)&lt;/li&gt;
&lt;li&gt;Specificity 99.1% (95%CI: 97.7% - 99.7%)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The R-package &lt;code&gt;yardstick&lt;/code&gt; does not yet include confidence intervals, so I generated these using bootstrapping. I calculate both metrics for 10.000 samples sampled from the raw data. For brevity I omitted the code here, go check out my Github for the R script.&lt;/p&gt;
&lt;p&gt;The bootstrapping approach yields the following range of plausible values given the data (95% interval):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(spec_vec, probs = c(0.025, 0.975))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      2.5%     97.5% 
## 0.9811765 0.9977477&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(sens_vec, probs = c(0.025, 0.975))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      2.5%     97.5% 
## 0.7570030 0.9029126&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The amount of data (N = 537) prevents us from getting an exact match to the leaflet’s confidence intervals, that are based on theoretic formulas. But we do get pretty close.&lt;/p&gt;
&lt;p&gt;Especially for the sensitivity, there is quite some uncertainty, we see that plausible values range from 76% up to 90% &lt;em&gt;for this particular cohort of patients&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;To summarise: we found that the numbers of the kit’s leaflet are reliable and published in full detail in the scientific literature.
Hurray!&lt;/p&gt;
&lt;p&gt;We also found that even the gold standard PCR is not able to detect all infected persons, it all depends on how much virus is present, and how the sample is obtained. From the analysis, it is clear that the rapid Antigen tests need more virus present to reliably detect infection. It is ALSO clear that the test is highly specific, with less than 1% false positives. Note that a false positive rate of 1% still means that in a healthy population of 1000, 10 are falsely detected as having COVID-19.
Finally, we find that the nasal swabs are less sensitive than the nasopharyngeal (“deep nose”) swabs, this reduces sensitivity by 5-10% (Igloi &lt;em&gt;et al.&lt;/em&gt; 2021, Lee &lt;em&gt;et al.&lt;/em&gt; 2021).&lt;/p&gt;
&lt;p&gt;So both the measurement device, and the self-collection of sample contribute to reduce the sensitivity. But now comes the key insight: the persons that produce the largest amounts of virus get detected, irrespective of whether they have symptoms or not. To me, this seems a “Unique Selling Point” of the rapid tests: the ability to rapidly detect the most contagious persons in a group, after which these persons can go into quarantine and help reduce spread.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Head-to-head comparison of SARS-CoV-2 antigen-detecting rapid test with self-collected nasal swab versus professional-collected nasopharyngeal swab
Andreas K. Lindner, Olga Nikolai, Franka Kausch, Mia Wintel, Franziska Hommes, Maximilian Gertler, Lisa J. Krüger, Mary Gaeddert, Frank Tobian, Federica Lainati, Lisa Köppel, Joachim Seybold, Victor M. Corman, Christian Drosten, Jörg Hofmann, Jilian A. Sacks, Frank P. Mockenhaupt, Claudia M. Denkinger, &lt;a href=&#34;https://erj.ersjournals.com/content/57/4/2003961&#34;&gt;European Respiratory Journal 2021 57: 2003961&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Head-to-head comparison of SARS-CoV-2 antigen-detecting rapid test with professional-collected nasal versus nasopharyngeal swab
Andreas K. Lindner, Olga Nikolai, Chiara Rohardt, Susen Burock, Claudia Hülso, Alisa Bölke, Maximilian Gertler, Lisa J. Krüger, Mary Gaeddert, Frank Tobian, Federica Lainati, Joachim Seybold, Terry C. Jones, Jörg Hofmann, Jilian A. Sacks, Frank P. Mockenhaupt, Claudia M. Denkinger &lt;a href=&#34;https://erj.ersjournals.com/content/57/5/2004430&#34;&gt;European Respiratory Journal 2021 57: 2004430&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;SARS-CoV-2 patient self-testing with an antigen-detecting rapid test: a head-to-head comparison with professional testing
Andreas K. Lindner, Olga Nikolai, Chiara Rohardt, Franka Kausch, Mia Wintel, Maximilian Gertler, Susen Burock, Merle Hörig, Julian Bernhard, Frank Tobian, Mary Gaeddert, Federica Lainati, Victor M. Corman, Terry C. Jones, Jilian A. Sacks, Joachim Seybold, Claudia M. Denkinger, Frank P. Mockenhaupt, under review, &lt;a href=&#34;https://www.medrxiv.org/content/10.1101/2021.01.06.20249009v1&#34;&gt;preprint on medrxiv.org&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Clinical evaluation of the Roche/SD Biosensor rapid antigen test with symptomatic, non-hospitalized patients in a municipal health service drive-through testing site.
Zsὁfia Iglὁi, Jans Velzing, Janko van Beek, David van de Vijver, Georgina Aron, Roel Ensing, KimberleyBenschop, Wanda Han, Timo Boelsums, Marion Koopmans, Corine Geurtsvankessel, Richard Molenkamp &lt;a href=&#34;https://www.medrxiv.org/content/10.1101/2020.11.18.20234104v1&#34;&gt;Link on medrxiv.org&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Performance of Saliva, Oropharyngeal Swabs, and Nasal Swabs for SARS-CoV-2 Molecular Detection: a Systematic Review and Meta-analysis
Rose A. Lee, Joshua C. Herigona, Andrea Benedetti, Nira R. Pollock, Claudia M. Denkinger &lt;a href=&#34;(https://journals.asm.org/doi/epub/10.1128/JCM.02881-20)&#34;&gt;Link to paper&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
