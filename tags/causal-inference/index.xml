<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>causal inference | Gertjan Verhoeven</title>
    <link>/tags/causal-inference/</link>
      <atom:link href="/tags/causal-inference/index.xml" rel="self" type="application/rss+xml" />
    <description>causal inference</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2019, 2020</copyright><lastBuildDate>Fri, 04 Sep 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>causal inference</title>
      <link>/tags/causal-inference/</link>
    </image>
    
    <item>
      <title>Using posterior predictive distributions to get the Average Treatment Effect (ATE) with uncertainty</title>
      <link>/post/posterior-distribution-average-treatment-effect/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      <guid>/post/posterior-distribution-average-treatment-effect/</guid>
      <description>
&lt;link href=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;gertjan-verhoeven-misja-mikkers&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Gertjan Verhoeven &amp;amp; Misja Mikkers&lt;/h2&gt;
&lt;p&gt;Here we show how to use &lt;a href=&#34;https://mc-stan.org&#34;&gt;Stan&lt;/a&gt; with the &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;brms&lt;/a&gt; R-package to calculate the posterior predictive distribution of a covariate-adjusted average treatment effect. We fit a model on simulated data that mimics a (very clean) experiment with random treatment assignment.&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction&lt;/h3&gt;
&lt;p&gt;Suppose we have data from a Randomized Controlled Trial (RCT) and we want to estimate the average treatment effect (ATE). Patients get treated, or not, depending only on a coin flip. This is encoded in the &lt;code&gt;Treatment&lt;/code&gt; variable. The outcome is a count variable &lt;code&gt;Admissions&lt;/code&gt;, representing the number of times the patient gets admitted to the hospital. The treatment is expected to reduce the number of hospital admissions for patients.&lt;/p&gt;
&lt;p&gt;To complicate matters (a bit): As is often the case with patients, not all patients are identical. Suppose that older patients have on average more Admissions. So &lt;code&gt;Age&lt;/code&gt; is a covariate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;average-treatment-effect-ate&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Average treatment effect (ATE)&lt;/h3&gt;
&lt;p&gt;Now, after we fitted a model to the data, we want to actually &lt;strong&gt;use&lt;/strong&gt; our model to answer &amp;quot;What-if&amp;quot; questions (counterfactuals). Here we answer the following question:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What would the average reduction in Admissions be if we had treated &lt;strong&gt;ALL&lt;/strong&gt; the patients in the sample, compared to a situation where &lt;strong&gt;NO&lt;/strong&gt; patient in the sample would have received treatment?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Well, that is easy, we just take the fitted model, change treatment from zero to one for each, and observe the (&amp;quot;marginal&amp;quot;) effect on the outcome, right?&lt;/p&gt;
&lt;p&gt;Yes, but the uncertainty is harder. We have uncertainty in the estimated coefficients of the intercept and covariate, as well as in the coefficient of the treatment variable. And these uncertainties can be correlated (for example between the coefficients of intercept and covariate).&lt;/p&gt;
&lt;p&gt;Here we show how to use &lt;code&gt;posterior_predict()&lt;/code&gt; to simulate outcomes of the model using the sampled parameters. If we do this for two counterfactuals, all patients treated, and all patients untreated, and subtract these, we can easily calculate the posterior predictive distribution of the average treatment effect.&lt;/p&gt;
&lt;p&gt;Let&#39;s do it!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;load-packages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Load packages&lt;/h3&gt;
&lt;p&gt;This tutorial uses &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;brms&lt;/a&gt;, a user friendly interface to full Bayesian modelling with &lt;a href=&#34;https://mc-stan.org/&#34;&gt;Stan&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(rstan)
library(brms) &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-simulation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data simulation&lt;/h3&gt;
&lt;p&gt;We generate fake data that matches our problem setup.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Admissions&lt;/code&gt; are determined by patient &lt;code&gt;Age&lt;/code&gt;, whether the patient has &lt;code&gt;Treatment&lt;/code&gt;, and some random &lt;code&gt;Noise&lt;/code&gt; to capture unobserved effects that influence &lt;code&gt;Admissions&lt;/code&gt;. We exponentiate them to always get a positive number, and plug it in the Poisson distribution using &lt;code&gt;rpois()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123) 

id &amp;lt;- 1:200   
n_obs &amp;lt;- length(id)
b_tr &amp;lt;- -0.7
b_age &amp;lt;- 0.1

df_sim &amp;lt;- as.data.frame(id) %&amp;gt;% 
mutate(Age = rgamma(n_obs, shape = 5, scale = 2)) %&amp;gt;% # positive cont predictor
mutate(Noise = rnorm(n_obs, mean = 0, sd = 0.5)) %&amp;gt;% # add noise
mutate(Treatment = ifelse(runif(n_obs) &amp;lt; 0.5, 0, 1)) %&amp;gt;% # Flip a coin for treatment
mutate(Lambda = exp(b_age * Age + b_tr * Treatment + Noise)) %&amp;gt;% # generate lambda for the poisson dist
mutate(Admissions = rpois(n_obs, lambda = Lambda))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;summarize-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Summarize data&lt;/h3&gt;
&lt;p&gt;Ok, so what does our dataset look like?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(df_sim)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        id              Age             Noise            Treatment    
##  Min.   :  1.00   Min.   : 1.794   Min.   :-1.32157   Min.   :0.000  
##  1st Qu.: 50.75   1st Qu.: 6.724   1st Qu.:-0.28614   1st Qu.:0.000  
##  Median :100.50   Median : 8.791   Median : 0.04713   Median :0.000  
##  Mean   :100.50   Mean   : 9.474   Mean   : 0.02427   Mean   :0.495  
##  3rd Qu.:150.25   3rd Qu.:11.713   3rd Qu.: 0.36025   3rd Qu.:1.000  
##  Max.   :200.00   Max.   :24.835   Max.   : 1.28573   Max.   :1.000  
##      Lambda          Admissions    
##  Min.   : 0.2479   Min.   : 0.000  
##  1st Qu.: 1.1431   1st Qu.: 1.000  
##  Median : 1.8104   Median : 2.000  
##  Mean   : 2.6528   Mean   : 2.485  
##  3rd Qu.: 3.0960   3rd Qu.: 3.000  
##  Max.   :37.1296   Max.   :38.000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Treatment variable should reduce admissions. Lets visualize the distribution of Admission values for both treated and untreated patients.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = df_sim, aes(x = Admissions)) +
  geom_histogram(stat=&amp;quot;count&amp;quot;) +
  facet_wrap(~ Treatment) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-09-04-brms_posterior_pred_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The effect of the treatment on reducing admissions is clearly visible.&lt;/p&gt;
&lt;p&gt;We can also visualize the relationship between &lt;code&gt;Admissions&lt;/code&gt; and &lt;code&gt;Age&lt;/code&gt;, for both treated and untreated patients. We use the &lt;code&gt;viridis&lt;/code&gt; scales to provide colour maps that are designed to be perceived by viewers with common forms of colour blindness.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = df_sim, aes(x = Age, y = Admissions, color = as.factor(Treatment))) +
  geom_point() +
  scale_color_viridis_d(labels = c(&amp;quot;No Treatment&amp;quot;, &amp;quot;Treatment&amp;quot;)) +
  labs(color = &amp;quot;Treatment&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-09-04-brms_posterior_pred_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now lets fit our Bayesian Poisson regression model to it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fit model&lt;/h3&gt;
&lt;p&gt;We use &lt;code&gt;brms&lt;/code&gt; default priors for convenience here. For a real application we would of course put effort into into crafting priors that reflect our current knowledge of the problem at hand.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model1 &amp;lt;- brm(
  formula = as.integer(Admissions) ~  Age + Treatment,
   data = df_sim,
  family = poisson(),
  warmup = 2000, iter = 5000, 
  cores = 2, 
  chains = 4,
  seed = 123,
  silent = TRUE,
  refresh = 0,
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Compiling Stan program...&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Start sampling&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;check-model-fit&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Check model fit&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(model1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: poisson 
##   Links: mu = log 
## Formula: as.integer(Admissions) ~ Age + Treatment 
##    Data: df_sim (Number of observations: 200) 
## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1;
##          total post-warmup samples = 12000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    -0.05      0.12    -0.28     0.18 1.00     7410     7333
## Age           0.12      0.01     0.10     0.14 1.00     8052     8226
## Treatment    -0.83      0.10    -1.02    -0.63 1.00     7794     7606
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that the posterior dists for &lt;span class=&#34;math inline&#34;&gt;\(\beta_{Age}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_{Treatment}\)&lt;/span&gt; cover the true values, so looking good. To get a fuller glimpse into the (correlated) uncertainty of the model parameters we make a pairs plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pairs(model1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-09-04-brms_posterior_pred_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As expected, the coefficients &lt;span class=&#34;math inline&#34;&gt;\(\beta_{Intercept}\)&lt;/span&gt; (added by &lt;code&gt;brms&lt;/code&gt;) and &lt;span class=&#34;math inline&#34;&gt;\(\beta_{Age}\)&lt;/span&gt; are highly correlated.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;first-attempt-calculate-individual-treatment-effects-using-the-model-fit-object&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;First attempt: Calculate Individual Treatment effects using the model fit object&lt;/h3&gt;
&lt;p&gt;Conceptually, the simplest approach for prediction is to take the most likely values for all the model parameters, and use these to calculate for each patient an individual treatment effect. This is what plain OLS regression does when we call &lt;code&gt;predict.lm()&lt;/code&gt; on a fitted model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;est_intercept &amp;lt;- fixef(model1, pars = &amp;quot;Intercept&amp;quot;)[,1]
est_age_eff &amp;lt;- fixef(model1, pars = &amp;quot;Age&amp;quot;)[,1]
est_t &amp;lt;- fixef(model1, pars = &amp;quot;Treatment&amp;quot;)[,1]

# brm fit parameters (intercept plus treatment)
ites &amp;lt;- exp(est_intercept + (est_age_eff * df_sim$Age) +  est_t) - exp(est_intercept + (est_age_eff * df_sim$Age))

ggplot(data.frame(ites), aes(x = ites)) + 
  geom_histogram() +
  geom_vline(xintercept = mean(ites), col = &amp;quot;red&amp;quot;) +
  ggtitle(&amp;quot;Effect of treatment on Admissions for each observation&amp;quot;) +
   expand_limits(x = 0) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-09-04-brms_posterior_pred_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Averaging the ITEs gives us the ATE, displayed in red.&lt;/p&gt;
&lt;p&gt;Ok, so &lt;strong&gt;on average&lt;/strong&gt;, our treatment reduces the number of Admissions by -1.9.&lt;/p&gt;
&lt;p&gt;You may wonder: why do we even have a distribution of treatment effects here? Should it not be the same for each patient? Here a peculiarity of the Poisson regression model comes to surface: The effect of changing &lt;code&gt;Treatment&lt;/code&gt; from 0 to 1 on the outcome depends on the value of &lt;code&gt;Age&lt;/code&gt; of the patient. This is because we &lt;strong&gt;exponentiate&lt;/strong&gt; the linear model before we plug it into the Poisson distribution.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;next-the-uncertainty-in-the-ate&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Next, the uncertainty in the ATE&lt;/h3&gt;
&lt;p&gt;How to get all this underlying, correlated uncertainty in the model parameters, that have varying effects depending on the covariates of patients, and properly propagate that to the ATE? What is the range of plausible values of the ATE consistent with the data &amp;amp; model?&lt;/p&gt;
&lt;p&gt;At this point, using only the summary statistics of the model fit (i.e. the coefficients), we hit a wall. To make progress we have to work with the full posterior distribution of model parameters, and use this to make predictions. That is why it is often called &amp;quot;the posterior predictive distribution&amp;quot; (Check &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/book/BDA3.pdf&#34;&gt;BDA3&lt;/a&gt; for the full story).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;posterior-predictive-distribution-ppd-two-tricks&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Posterior predictive distribution (PPD): two tricks&lt;/h3&gt;
&lt;p&gt;Ok, you say, a Posterior Predictive Distribution, let&#39;s have it! Where can I get one?&lt;/p&gt;
&lt;p&gt;Luckily for us, most of the work is already done, because we have fitted our model. And thus we have a large collection of parameter draws (or samples, to confuse things a bit). All the correlated uncertainty is contained in these draws.&lt;/p&gt;
&lt;p&gt;This is the first trick. Conceptually, we imagine that each separate draw of the posterior represents a particular version of our model.&lt;/p&gt;
&lt;p&gt;In our example model fit, we have 12.000 samples from the posterior. In our imagination, we now have 12.000 versions of our model, where unlikely parameter combinations are present less often compared to likely parameter combinations. The full uncertainty of our model parameters is contained in this &amp;quot;collection of models&amp;quot; .&lt;/p&gt;
&lt;p&gt;The second trick is that we simulate (generate) predictions for all observations, from each of these 12.000 models. Under the hood, this means computing for each model (we have 12.000), for each observation (we have 200) the predicted lambda value given the covariates, and drawing a single value from a Poisson distribution with that &lt;span class=&#34;math inline&#34;&gt;\(\Lambda\)&lt;/span&gt; value (e.g. running &lt;code&gt;rpois(n = 1, lambda)&lt;/code&gt; ).&lt;/p&gt;
&lt;p&gt;This gives us a 12.000 x 200 matrix, that we can compute with.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;computing-with-the-ppd-brmsposterior_predict&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Computing with the PPD: brms::posterior_predict()&lt;/h3&gt;
&lt;p&gt;To compute PPD&#39;s, we can use &lt;code&gt;brms::posterior_predict()&lt;/code&gt;. We can feed it any dataset using the &lt;code&gt;newdata&lt;/code&gt; argument, and have it generate a PPD.&lt;/p&gt;
&lt;p&gt;For our application, the computation can be broken down in two steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 1: use &lt;code&gt;posterior_predict()&lt;/code&gt; on our dataset with &lt;code&gt;Treatment&lt;/code&gt; set to zero, do the same for our dataset with &lt;code&gt;Treatment&lt;/code&gt; set to one, and subtract the two matrices. This gives us a matrix of outcome differences / treatment effects.&lt;/li&gt;
&lt;li&gt;Step 2: Averaging over all cols (the N=200 simulated outcomes for each draw) should give us the distribution of the ATE. This distribution now represents the variability (uncertainty) of the estimate.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ok, step 1:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create two versions of our dataset, with all Tr= 0 and all Tr=1
df_sim_t0 &amp;lt;- df_sim %&amp;gt;% mutate(Treatment = 0)

df_sim_t1 &amp;lt;- df_sim %&amp;gt;% mutate(Treatment = 1)

# simulate the PPDs
pp_t0 &amp;lt;- posterior_predict(model1, newdata = df_sim_t0)

pp_t1 &amp;lt;- posterior_predict(model1, newdata = df_sim_t1)

diff &amp;lt;- pp_t1 - pp_t0

dim(diff)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 12000   200&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And step 2 (averaging by row over the cols):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ATE_per_draw &amp;lt;- apply(diff, 1, mean)

# equivalent expression for tidyverse fans
#ATE_per_draw &amp;lt;- data.frame(diff) %&amp;gt;% rowwise() %&amp;gt;% summarise(avg = mean(c_across(cols = everything())))

length(ATE_per_draw)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 12000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, a distribution of plausible ATE values. Oo, that is so nice. Lets visualize it!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data.frame(ATE_per_draw), aes(x = ATE_per_draw)) +
  geom_histogram() + 
  geom_vline(xintercept = mean(ites), col = &amp;quot;red&amp;quot;) +
  ggtitle(&amp;quot;Posterior distribution of the Average Treatment Effect (ATE)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-09-04-brms_posterior_pred_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can compare this distribution with the point estimate of the ATE we obtained above using the model coefficients. It sits right in the middle (red line), just as it should be!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;demonstrating-the-versatility-uncertainty-in-the-sum-of-treatment-effects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Demonstrating the versatility: uncertainty in the sum of treatment effects&lt;/h3&gt;
&lt;p&gt;Now suppose we are a policy maker, and we want to estimate the total reduction in Admissions if all patients get the treatment. And we want to quantify the range of plausible values of this summary statistic.&lt;/p&gt;
&lt;p&gt;To do so, we can easily adjust our code to summing instead of averaging all the treatment effects within each draw (i.e. by row):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;TTE_per_draw &amp;lt;- apply(diff, 1, sum)

ggplot(data.frame(TTE_per_draw), aes(x = TTE_per_draw)) +
  geom_histogram() + 
  geom_vline(xintercept = sum(ites), col = &amp;quot;red&amp;quot;) +
  ggtitle(&amp;quot;Posterior distribution of the Total Treatment Effect (TTE)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-09-04-brms_posterior_pred_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So our model predicts for the aggregate reduction of patient Admissions a value in the range of -500 to -250.&lt;/p&gt;
&lt;p&gt;This distribution can then be used to answer questions such as &amp;quot;what is the probability that our treatment reduces Admissions by at least 400&amp;quot;?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;TTE &amp;lt;- data.frame(TTE_per_draw) %&amp;gt;%
  mutate(counter = ifelse(TTE_per_draw &amp;lt; -400, 1, 0)) 

mean(TTE$counter) * 100&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 38.1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;take-home-message-ppd-with-brms-is-easy-and-powerful&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Take home message: PPD with brms is easy and powerful&lt;/h3&gt;
&lt;p&gt;We hope to have demonstrated that when doing a full bayesian analysis with &lt;code&gt;brms&lt;/code&gt; and &lt;code&gt;Stan&lt;/code&gt;, it is very easy to create Posterior Predictive Distributions using &lt;code&gt;posterior_predict()&lt;/code&gt;. And that if we &lt;em&gt;have&lt;/em&gt; a posterior predictive distribution, incorporating uncertainty in various &amp;quot;marginal effects&amp;quot; type analyses becomes dead-easy. These analyses include what-if scenarios using the original data, or scenarios using new data with different covariate distributions (for example if we have an RCT that is enriched in young students, and we want to apply it to the general population). Ok, that it is for today, happy modelling!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Designing an introductory course on Causal Inference</title>
      <link>/post/causal-inference-course/</link>
      <pubDate>Sat, 11 May 2019 00:00:00 +0000</pubDate>
      <guid>/post/causal-inference-course/</guid>
      <description>
&lt;link href=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;(Short intro) This is me learning causal inference (CI) by self-study together with colleagues using online resources.&lt;/p&gt;
&lt;p&gt;(Longer intro) A modern data scientist needs to become skilled in at least three topics (I left out visualization):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(Bayesian) Statistical modeling&lt;/li&gt;
&lt;li&gt;Machine Learning&lt;/li&gt;
&lt;li&gt;Causal inference&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the first two topics, great introductory books exist that&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;focus on learning-by-doing and&lt;/li&gt;
&lt;li&gt;are low on math and high on simulation / programming in R&lt;/li&gt;
&lt;li&gt;are fun / well written&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For Bayesian statistical modeling, we have the awesome textbook &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;&amp;quot;Statistical Rethinking&amp;quot;&lt;/a&gt; by Richard mcElreath.&lt;/p&gt;
&lt;p&gt;For Machine Learning, we have the (free) book &lt;a href=&#34;http://www-bcf.usc.edu/~gareth/ISL/&#34;&gt;&amp;quot;Introduction to Statistical Learning&amp;quot;&lt;/a&gt; by James, Witten, Hastie &amp;amp; Tibshirani.&lt;/p&gt;
&lt;p&gt;However, for Causal Inference, such a book does not exist yet AFAIK. Therefore, I tried to piece together a Causal Inference course based on the criteria mentioned above.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;designing-an-introductory-causal-inference-course&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Designing an introductory causal inference course&lt;/h1&gt;
&lt;p&gt;Explicit goal was to contrast/combine the causal graph (DAG) approach with what some call &amp;quot;Quasi-experimental designs&amp;quot;, i.e. the econometric causal effects toolkit (Regression Discontinuity Design, matching, instrumental variables etc).&lt;/p&gt;
&lt;p&gt;In the end, I decided to combine the two causal chapters from Gelman &amp;amp; Hill (2007) &lt;a href=&#34;https://statmodeling.stat.columbia.edu/2007/12/08/causal_inferenc_2/&#34;&gt;(freely available on Gelman&#39;s website)&lt;/a&gt; with the introductory chapter on Causal Graphical Models by Felix Elwert &lt;a href=&#34;https://www.ssc.wisc.edu/~felwert/causality/&#34;&gt;(freely available on Elwert&#39;s website)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The Gelman &amp;amp; Hill chapters already come with a set of exercises. However, for DAGs, i could not find a suitable set of exercises.&lt;/p&gt;
&lt;p&gt;So I created two R markdown notebooks with exercises in R, that make use of the &lt;a href=&#34;http://dagitty.net/&#34;&gt;DAGitty tool&lt;/a&gt;, created by Johannes Textor and freely available as R package.&lt;/p&gt;
&lt;p&gt;Some exercises are taken from &lt;a href=&#34;http://bayes.cs.ucla.edu/PRIMER/&#34;&gt;Causal inference in statistics: A Primer&lt;/a&gt; by Pearl, Glymour &amp;amp; Jewell. (I probably should own this book. So I just ordered it :))&lt;/p&gt;
&lt;p&gt;All materials are available in a &lt;a href=&#34;https://github.com/gsverhoeven/causal_course&#34;&gt;GitHub repository&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;outline-of-the-course&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Outline of the course&lt;/h1&gt;
&lt;p&gt;The course has four parts.&lt;/p&gt;
&lt;div id=&#34;general-introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;General introduction&lt;/h2&gt;
&lt;p&gt;The course starts with the first causal chapter of Gelman &amp;amp; Hill&#39;s book, &amp;quot;Causal inference using regression on the treatment variable&amp;quot;. This creates a first complete experience with identifying and estimating causal effects. However, there are no causal diagrams, which is unfortunate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;identification-of-causal-effects-using-dags&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Identification of Causal effects using DAGs&lt;/h2&gt;
&lt;p&gt;Next we dive into causal identification using the causal diagram approach. For this we use the chapter &amp;quot;Causal Graphical Models&amp;quot; by Felix Elwert. Two R markdown Notebooks with exercises using Dagitty complete this part.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;identification-and-estimation-strategies&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Identification and estimation strategies&lt;/h2&gt;
&lt;p&gt;We then continue with the second causal chapter of Gelman &amp;amp; Hill &amp;quot;Causal inference using more advanced models&amp;quot;. This covers matching, regression discontinuity design, and instrumental variables. This material is combined with a paper by Scheiner et al, that contains DAGs for these methods. In our study group DAGs greatly facilitated discussion of the various designs.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;varying-treatment-effects-using-machine-learning&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Varying treatment effects using Machine Learning&lt;/h2&gt;
&lt;p&gt;Finally, and this part of the course has yet to take place, is the topic of estimating heterogeneous (i.e. subgroup, or even individual) treatment effects. This covers recent developements based on (forests of) regression trees. The plan is to cover both bayesian (BART, Chipman &amp;amp; mcCullough) and non-bayesian (GRF, Athey &amp;amp; Wager) methods.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;looking-back-so-far&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Looking back so far&lt;/h1&gt;
&lt;p&gt;The causal diagram / DAG approach is nonparametric and its purpose is to&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make assumptions on the data generating process explicit&lt;/li&gt;
&lt;li&gt;Formalize identification of causal effects&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thus, it is separate from, and complements statistical estimation. The distinction between identification and estimation is not so explicitly made in the Gelman &amp;amp; Hill chapters, at least this is my impression. It would really benefit from adding DAGs, as Richard mcElreath is doing in his upcoming second edition of Statistical Rethinking.&lt;/p&gt;
&lt;p&gt;After having worked through these materials, I think reading Shalizi&#39;s chapters on Causal Effects would be a smart move. This is part III of his book &lt;a href=&#34;https://www.stat.cmu.edu/~cshalizi/ADAfaEPoV/&#34;&gt;&amp;quot;Advanced Data Analysis from an Elementary Point of View&amp;quot;&lt;/a&gt;, which is awesome in its clarity, practical remarks a.k.a. normative statements by the author, and breadth.&lt;/p&gt;
&lt;p&gt;If you have a question, would like to comment or share ideas feel free to &lt;a href=&#34;https://gsverhoeven.github.io/#contact&#34;&gt;contact me&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>BART vs Causal forests showdown</title>
      <link>/post/bart_vs_grf/bart-vs-grf-showdown/</link>
      <pubDate>Sat, 15 Dec 2018 00:00:00 +0000</pubDate>
      <guid>/post/bart_vs_grf/bart-vs-grf-showdown/</guid>
      <description>
&lt;link href=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;load-packages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Load packages&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# library(devtools)
#devtools::install_github(&amp;quot;vdorie/dbarts&amp;quot;)
library(dbarts)
library(ggplot2)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ tibble  3.0.4     ✔ dplyr   1.0.2
## ✔ tidyr   1.1.2     ✔ stringr 1.4.0
## ✔ readr   1.4.0     ✔ forcats 0.5.0
## ✔ purrr   0.3.4&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ tidyr::extract() masks dbarts::extract()
## ✖ dplyr::filter()  masks stats::filter()
## ✖ dplyr::lag()     masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(grf)
#devtools::install_github(&amp;quot;vdorie/aciccomp/2017&amp;quot;)
library(aciccomp2017)
library(cowplot)

source(&amp;quot;CalcPosteriors.R&amp;quot;)

fullrun &amp;lt;- 0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;dataset-1-simulated-dataset-from-friedman-mars-paper&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Dataset 1: Simulated dataset from Friedman MARS paper&lt;/h1&gt;
&lt;p&gt;This is not a causal problem but a prediction problem.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## y = f(x) + epsilon , epsilon ~ N(0, sigma)
## x consists of 10 variables, only first 5 matter

f &amp;lt;- function(x) {
    10 * sin(pi * x[,1] * x[,2]) + 20 * (x[,3] - 0.5)^2 +
      10 * x[,4] + 5 * x[,5]
}

set.seed(99)
sigma &amp;lt;- 1.0
n     &amp;lt;- 100

x  &amp;lt;- matrix(runif(n * 10), n, 10)
Ey &amp;lt;- f(x)
y  &amp;lt;- rnorm(n, Ey, sigma)

df &amp;lt;- data.frame(x, y, y_true = Ey)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;fit-bart-model-on-simulated-friedman-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;fit BART model on simulated Friedman data&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if(fullrun){
## run BART
  set.seed(99)
  bartFit &amp;lt;- bart(x, y)
  saveRDS(bartFit, &amp;quot;s1.rds&amp;quot;)
} else { bartFit &amp;lt;- readRDS(&amp;quot;s1.rds&amp;quot;)}

plot(bartFit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bart_vs_grf/BART-vs-grf_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;MCMC or sigma looks ok.&lt;/p&gt;
&lt;div id=&#34;compare-bart-fit-to-true-values&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;compare BART fit to true values&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df2 &amp;lt;- data.frame(df, 
  ql = apply(bartFit$yhat.train, length(dim(bartFit$yhat.train)), quantile,probs=0.05),
  qm = apply(bartFit$yhat.train, length(dim(bartFit$yhat.train)), quantile,probs=.5),
  qu &amp;lt;- apply(bartFit$yhat.train, length(dim(bartFit$yhat.train)), quantile,probs=0.95)
)

bartp &amp;lt;- ggplot(df2, aes(x= y, y = qm)) + geom_linerange(aes(ymin = ql, ymax = qu), col = &amp;quot;grey&amp;quot;) +
  geom_point() + geom_smooth() +
  geom_abline(intercept = 0, slope = 1, col = &amp;quot;red&amp;quot;, size = 1)

bartp&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bart_vs_grf/BART-vs-grf_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This looks nice.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-grf-regression-forest-on-friedman-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fit Grf regression forest on Friedman data&lt;/h2&gt;
&lt;p&gt;From the manual: Trains a regression forest that can be used to estimate the conditional mean function mu(x) = E[Y | X = x]&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if(fullrun){
  reg.forest = regression_forest(x, y, num.trees = 2000)
  saveRDS(reg.forest, &amp;quot;s00.rds&amp;quot;)
} else {reg.forest &amp;lt;- readRDS(&amp;quot;s00.rds&amp;quot;)}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df3 &amp;lt;- CalcPredictionsGRF(x, reg.forest)

df3 &amp;lt;- data.frame(df3, y)

ggplot(df3, aes(x= y, y = qm)) + geom_linerange(aes(ymin = ql, ymax = qu), col = &amp;quot;grey&amp;quot;) +
  geom_point() + 
  geom_abline(intercept = 0, slope = 1, col = &amp;quot;red&amp;quot;, size = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bart_vs_grf/BART-vs-grf_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is pretty bad compared to BART. What&#39;s wrong here?&lt;/p&gt;
&lt;p&gt;From reference.md: &lt;strong&gt;GRF isn&#39;t working well on a small dataset&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you observe poor performance on a dataset with a small number of examples, it may be worth trying out two changes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Disabling honesty. As noted in the section on honesty above, when honesty is enabled, the training subsample is further split in half before performing splitting. This may not leave enough information for the algorithm to determine high-quality splits.&lt;/li&gt;
&lt;li&gt;Skipping the variance estimate computation, by setting ci.group.size to 1 during training, then increasing sample.fraction. Because of how variance estimation is implemented, sample.fraction cannot be greater than 0.5 when it is enabled. If variance estimates are not needed, it may help to disable this computation and use a larger subsample size for training.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Dataset is pretty small (n=100). Maybe turn of honesty? We cannot turn off variance estimate computation, because we want the CI&#39;s&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if(fullrun){
  reg.forest2 = regression_forest(x, y, num.trees = 2000,
                                 honesty = FALSE)
  saveRDS(reg.forest2, &amp;quot;s001.rds&amp;quot;)
} else {reg.forest2 &amp;lt;- readRDS(&amp;quot;s001.rds&amp;quot;)}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df2 &amp;lt;- CalcPredictionsGRF(x, reg.forest2)

df2 &amp;lt;- data.frame(df2, y)

grfp &amp;lt;- ggplot(df2, aes(x= y, y = qm)) + geom_linerange(aes(ymin = ql, ymax = qu), col = &amp;quot;grey&amp;quot;) +
  geom_point() + geom_smooth() +
  geom_abline(intercept = 0, slope = 1, col = &amp;quot;red&amp;quot;, size = 1)

grfp&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bart_vs_grf/BART-vs-grf_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Ah! better now. But Grf still worse than BART. We ran with 2000 trees and turned of honesty. Perhaps dataset too small? Maybe check out the sample.fraction parameter? Sample.fraction is set by default at 0.5, so only half of data is used to grow tree. OR use tune.parameters = TRUE&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;compare-methods&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Compare methods&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gp &amp;lt;- plot_grid(bartp, grfp)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;
## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gp &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bart_vs_grf/BART-vs-grf_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;dataset-2-simulated-data-from-acic-2017&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Dataset 2: Simulated data from ACIC 2017&lt;/h1&gt;
&lt;p&gt;This is a bigger dataset, N=4302.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Treatment effect &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; is a function of covariates x3, x24, x14, x15&lt;/li&gt;
&lt;li&gt;Probability of treatment &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; is a function of covariates x1, x43, x10.&lt;/li&gt;
&lt;li&gt;Outcome is a function of x43&lt;/li&gt;
&lt;li&gt;Noise is a function of x21&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(input_2017[, c(3,24,14,15)])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   x_3  x_24 x_14 x_15
## 1  20 white    0    2
## 2   0 black    0    0
## 3   0 white    0    1
## 4  10 white    0    0
## 5   0 black    0    0
## 6   1 white    0    0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check transformed covariates used to create simulated datasets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# zit hidden in package
head(aciccomp2017:::transformedData_2017)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              x_1   x_3  x_10  x_14  x_15 x_21 x_24       x_43
## 2665 -1.18689448  gt_0 leq_0 leq_0  gt_0    J    E -1.0897971
## 22   -0.04543705 leq_0 leq_0 leq_0 leq_0    J    B  1.1223750
## 2416  0.13675482 leq_0 leq_0 leq_0  gt_0    J    E  0.6136700
## 1350 -0.24062700  gt_0 leq_0 leq_0 leq_0    J    E -0.2995632
## 3850  1.02054653 leq_0 leq_0 leq_0 leq_0    I    B  0.6136700
## 4167 -1.18689448  gt_0 leq_0 leq_0 leq_0    K    E -1.5961206&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we find that we should not take the functions in Dorie 2018 (debrief.pdf) literately. x_3 used to calculate the treatment effect is &lt;strong&gt;derived&lt;/strong&gt; from x_3 in the input data. x_24 used to calculate the treatment effect is &lt;strong&gt;derived&lt;/strong&gt; from x_24 in the input data. Both have become binary variables.&lt;/p&gt;
&lt;p&gt;Turns out that this was a feature of the 2016 ACIC and IS mentioned in the debrief.pdf&lt;/p&gt;
&lt;p&gt;We pick the iid, strong signal, low noise, low confounding first. Actually from estimated PS (W.hat) it seems that every obs has probability of treatment 50%.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;parameters_2017[21,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    errors magnitude noise confounding
## 21    iid         1     0           0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# easiest?&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Grab the first replicate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim &amp;lt;- dgp_2017(21, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;fit-bart-to-acic-2017-dataset&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fit BART to ACIC 2017 dataset&lt;/h2&gt;
&lt;p&gt;Need also counterfactual predictions. Most efficient seems to create x.test with Z reversed. This will give use a y.test as well as y.train in the output. We expect draws for both. Plotting a histogram of the difference gives us the treatment effect with uncertainty.&lt;/p&gt;
&lt;p&gt;From the MCMC draws for sigma we infer that we need to drop more &amp;quot;burn in&amp;quot; samples.&lt;/p&gt;
&lt;p&gt;Prepare data for BART, including x.test with treatment reversed:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# combine x and y
y &amp;lt;- sim$y
x &amp;lt;- model.matrix(~. ,cbind(z = sim$z, input_2017))

# flip z for counterfactual predictions (needed for BART)
x.test &amp;lt;- model.matrix(~. ,cbind(z = 1 - sim$z, input_2017))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## run BART
#fullrun &amp;lt;- 0
if(fullrun){
  set.seed(99)

  bartFit &amp;lt;- bart(x, y, x.test, nskip = 350, ntree = 1000)
  saveRDS(bartFit, &amp;quot;s2.rds&amp;quot;)
} else { bartFit &amp;lt;- readRDS(&amp;quot;s2.rds&amp;quot;)}

plot(bartFit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bart_vs_grf/BART-vs-grf_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;extract-individual-treatment-effect-ite-cate-plus-uncertainty-from-bartfit&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Extract individual treatment effect (ITE / CATE) plus uncertainty from bartfit&lt;/h3&gt;
&lt;p&gt;This means switching z from 0 to 1 and looking at difference in y + uncertainty in y.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#source(&amp;quot;calcPosteriors.R&amp;quot;)
sim &amp;lt;- CalcPosteriorsBART(sim, bartFit, &amp;quot;z&amp;quot;)

sim &amp;lt;- sim %&amp;gt;% arrange(alpha)

bartp &amp;lt;- ggplot(sim, aes(x = 1:nrow(sim), qm))  + 
  geom_linerange(aes(ymin = ql, ymax = qu), col = &amp;quot;grey&amp;quot;) +
  geom_point() + 
  geom_smooth() + geom_point(aes(y = alpha), col = &amp;quot;red&amp;quot;) + ylim(-2.5, 4.5)

bartp&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;gam&amp;#39; and formula &amp;#39;y ~ s(x, bs = &amp;quot;cs&amp;quot;)&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 1 rows containing missing values (geom_smooth).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bart_vs_grf/BART-vs-grf_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This looks sort of ok, but still weird. Some points it gets REALLY wrong.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;calculate-coverage&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Calculate coverage&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim &amp;lt;- sim %&amp;gt;% mutate(in_ci = ql &amp;lt; alpha &amp;amp; qu &amp;gt; alpha) 

mean(sim$in_ci)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.4363087&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Pretty bad coverage. Look into whats going on here. Here it should be 0.9&lt;/p&gt;
&lt;p&gt;The iid plot for method 2 gives coverage 0.7 (where it should be 0.95)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;calculate-rmse-of-cate&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Calculate RMSE of CATE&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sqrt(mean((sim$alpha - sim$ite)^2))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1587338&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For All i.i.d. (averaged over 250 replicates averaged over 8 scenarios) method 2 (BART should have RMSE of CATE of 0.35-0.4)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-grf-to-acic-2017-dataset&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fit grf to ACIC 2017 dataset&lt;/h2&gt;
&lt;p&gt;need large num.trees for CI.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# prep data for Grf
# combine x and y
sim &amp;lt;- dgp_2017(21, 1)

Y &amp;lt;- sim$y
X &amp;lt;- model.matrix(~. ,input_2017)
W = sim$z

# Train a causal forest.
#fullrun &amp;lt;- 0

if(fullrun){
  grf.fit_alt &amp;lt;- causal_forest(X, Y, W, num.trees = 500)
  saveRDS(grf.fit_alt, &amp;quot;s3.rds&amp;quot;)
} else{grf.fit_alt &amp;lt;- readRDS(&amp;quot;s3.rds&amp;quot;)}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It appears that using 4000 trees consumes too much memory (bad_alloc)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;compare-predictions-vs-true-value&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Compare predictions vs true value&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_sep2 &amp;lt;- CalcPredictionsGRF(X, grf.fit_alt)

df_sep2 &amp;lt;- data.frame(df_sep2, Y, W, TAU = sim$alpha)

df_sep2 &amp;lt;- df_sep2 %&amp;gt;% arrange(TAU)

grfp &amp;lt;- ggplot(df_sep2, aes(x = 1:nrow(df_sep2), y = qm))   +
  geom_linerange(aes(ymin = ql, ymax = qu), col = &amp;quot;grey&amp;quot;) + geom_point() + geom_smooth() + 
  geom_point(aes(y = TAU), col = &amp;quot;red&amp;quot;) + ylim(-2.5, 4.5)

grfp&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;gam&amp;#39; and formula &amp;#39;y ~ s(x, bs = &amp;quot;cs&amp;quot;)&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bart_vs_grf/BART-vs-grf_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This works ok now.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;compare-both-methods&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Compare both methods&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gp &amp;lt;- plot_grid(bartp, grfp)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;gam&amp;#39; and formula &amp;#39;y ~ s(x, bs = &amp;quot;cs&amp;quot;)&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 1 rows containing missing values (geom_smooth).&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;gam&amp;#39; and formula &amp;#39;y ~ s(x, bs = &amp;quot;cs&amp;quot;)&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gp&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bart_vs_grf/BART-vs-grf_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;dataset-3-simulated-data-used-by-grf-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Dataset 3: simulated data used by grf example&lt;/h1&gt;
&lt;p&gt;THis dataset is used in the Grf manual page. Size N = 2000. Probability of treatment function of X1. Treatment effect function of X1.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Generate data.
set.seed(123)
n = 2000; p = 10
X = matrix(rnorm(n*p), n, p)

# treatment
W = rbinom(n, 1, 0.4 + 0.2 * (X[,1] &amp;gt; 0))
# outcome (parallel max)
Y = pmax(X[,1], 0) * W + X[,2] + pmin(X[,3], 0) + rnorm(n)

# TAU is true treatment effect
df &amp;lt;- data.frame(X, W, Y, TAU = pmax(X[,1], 0))&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;fit-grf&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fit GRF&lt;/h2&gt;
&lt;p&gt;Default settings are honesty = TRUE.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Train a causal forest.
if(fullrun){
  tau.forest = causal_forest(X, Y, W, num.trees = 2000)
  saveRDS(tau.forest, &amp;quot;s4.rds&amp;quot;)
} else {tau.forest &amp;lt;- readRDS(&amp;quot;s4.rds&amp;quot;)}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;oob-predictions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;OOB predictions&lt;/h2&gt;
&lt;p&gt;From the GRF manual:&lt;/p&gt;
&lt;p&gt;Given a test example, the GRF algorithm computes a prediction as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;For each tree, the test example is &amp;#39;pushed down&amp;#39; to determine what leaf it falls in.
Given this information, we create a list of neighboring training examples, weighted by how many times the example fell in the same leaf as the test example.
A prediction is made using this weighted list of neighbors, using the relevant approach for the type of forest. In causal prediction, we calculate the treatment effect using the outcomes and treatment status of the neighbor examples.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Those familiar with classic random forests might note that this approach differs from the way forest prediction is usually described. The traditional view is that to predict for a test example, each tree makes a prediction on that example. To make a final prediction, the tree predictions are combined in some way, for example through averaging or through &#39;majority voting&#39;. It&#39;s worth noting that for regression forests, the GRF algorithm described above is identical this &#39;ensemble&#39; approach, where each tree predicts by averaging the outcomes in each leaf, and predictions are combined through a weighted average.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Estimate treatment effects for the training data using out-of-bag prediction.
tau.hat.oob = predict(tau.forest)

res &amp;lt;- data.frame(df, pred = tau.hat.oob$predictions)

ggplot(res, aes(x = X1, y = pred)) + geom_point() + geom_smooth() + geom_abline(intercept = 0, slope = 1) +
  geom_line(aes(y = TAU), col = &amp;quot;red&amp;quot;, size = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;gam&amp;#39; and formula &amp;#39;y ~ s(x, bs = &amp;quot;cs&amp;quot;)&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bart_vs_grf/BART-vs-grf_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ate-att&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;ATE &amp;amp; ATT&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Estimate the conditional average treatment effect on the full sample (CATE).
average_treatment_effect(tau.forest, target.sample = &amp;quot;all&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   estimate    std.err 
## 0.37316437 0.04795009&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(res$TAU)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.4138061&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Estimate the conditional average treatment effect on the treated sample (CATT).
# Here, we don&amp;#39;t expect much difference between the CATE and the CATT, since
# treatment assignment was randomized.
average_treatment_effect(tau.forest, target.sample = &amp;quot;treated&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   estimate    std.err 
## 0.47051526 0.04850751&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(res[res$W == 1,]$TAU)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5010723&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-more-trees-for-cis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fit more trees for CI&#39;s&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Add confidence intervals for heterogeneous treatment effects; growing more
# trees is now recommended.
if(fullrun){
  tau.forest_big = causal_forest(X, Y, W, num.trees = 4000)
  saveRDS(tau.forest_big, &amp;quot;s5.rds&amp;quot;)
} else {tau.forest_big &amp;lt;- readRDS(&amp;quot;s5.rds&amp;quot;)}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-cis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot CI&#39;s&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## PM
#source(&amp;quot;CalcPosteriors.R&amp;quot;)
df_res &amp;lt;- CalcPredictionsGRF(df, tau.forest_big)

grfp &amp;lt;- ggplot(df_res, aes(x = X1, y = qm)) + 
  geom_linerange(aes(ymin = ql, ymax = qu), col = &amp;quot;grey&amp;quot;) +
  geom_point()  + 
  geom_smooth() + geom_line(aes(y = TAU), col = &amp;quot;red&amp;quot;, size = 1) +
   ylim(-1,3.5)

grfp&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;gam&amp;#39; and formula &amp;#39;y ~ s(x, bs = &amp;quot;cs&amp;quot;)&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bart_vs_grf/BART-vs-grf_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-bart-on-this-dataset&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fit BART on this dataset&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x.train &amp;lt;- model.matrix(~. ,data.frame(W, X))
x.test &amp;lt;- model.matrix(~. ,data.frame(W = 1 - W, X))
y.train &amp;lt;- Y

if(fullrun){
  bartFit &amp;lt;- bart(x.train, y.train, x.test, ntree = 2000, ndpost = 1000, nskip = 100)
  saveRDS(bartFit, &amp;quot;s10.rds&amp;quot;)
} else {bartFit &amp;lt;- readRDS(&amp;quot;s10.rds&amp;quot;)}
plot(bartFit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bart_vs_grf/BART-vs-grf_files/figure-html/unnamed-chunk-29-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bart-check-fit-and-cis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;BART: Check fit and CI&#39;s&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#source(&amp;quot;calcPosteriors.R&amp;quot;)
sim &amp;lt;- CalcPosteriorsBART(df, bartFit, treatname = &amp;quot;W&amp;quot;)


bartp &amp;lt;- ggplot(sim, aes(x = X1, qm)) + geom_linerange(aes(ymin = ql, ymax = qu), col = &amp;quot;grey&amp;quot;) +
  geom_point() + geom_smooth() +
  geom_line(aes(y = TAU), col = &amp;quot;red&amp;quot;, size = 1) + ylim(-1,3.5)

bartp&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;gam&amp;#39; and formula &amp;#39;y ~ s(x, bs = &amp;quot;cs&amp;quot;)&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bart_vs_grf/BART-vs-grf_files/figure-html/unnamed-chunk-30-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;compare&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Compare&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gp &amp;lt;- plot_grid(bartp, grfp)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;gam&amp;#39; and formula &amp;#39;y ~ s(x, bs = &amp;quot;cs&amp;quot;)&amp;#39;
## `geom_smooth()` using method = &amp;#39;gam&amp;#39; and formula &amp;#39;y ~ s(x, bs = &amp;quot;cs&amp;quot;)&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gp&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bart_vs_grf/BART-vs-grf_files/figure-html/unnamed-chunk-31-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here Grf appears more accurate. Mental note: Both W and TAU function of X1.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;dataset-4-fit-separate-grf-forests-for-y-and-w&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Dataset 4: Fit separate grf forests for Y and W&lt;/h1&gt;
&lt;p&gt;This dataset has a complex propensity of treatment function (Exponential of X1 and X2), as well as hetergeneous treatment effect that is exponential function of X3. It has size N=4000.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# In some examples, pre-fitting models for Y and W separately may
# be helpful (e.g., if different models use different covariates).
# In some applications, one may even want to get Y.hat and W.hat
# using a completely different method (e.g., boosting).
set.seed(123)
# Generate new data.
n = 4000; p = 20
X = matrix(rnorm(n * p), n, p)
TAU = 1 / (1 + exp(-X[, 3]))
W = rbinom(n ,1, 1 / (1 + exp(-X[, 1] - X[, 2])))
Y = pmax(X[, 2] + X[, 3], 0) + rowMeans(X[, 4:6]) / 2 + W * TAU + rnorm(n)

df_sep4 &amp;lt;- data.frame(X, TAU, W, Y)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;grf-two-step-first-fit-model-for-w-ps&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Grf two-step: First fit model for W (PS)&lt;/h2&gt;
&lt;p&gt;Regression forest to predict W from X. This is a propensity score.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if(fullrun){
  forest.W &amp;lt;- regression_forest(X, W, tune.parameters = c(&amp;quot;min.node.size&amp;quot;, &amp;quot;honesty.prune.leaves&amp;quot;), 
                               num.trees = 2000)
  saveRDS(forest.W, &amp;quot;s6.rds&amp;quot;)
} else {forest.W &amp;lt;- readRDS(&amp;quot;s6.rds&amp;quot;)}

W.hat = predict(forest.W)$predictions&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;grfthen-fit-model-for-y-selecting-covariates&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Grf:Then Fit model for Y, selecting covariates&lt;/h3&gt;
&lt;p&gt;This predict Y from X, ignoring treatment.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if(fullrun){
  forest.Y = regression_forest(X, Y, tune.parameters = c(&amp;quot;min.node.size&amp;quot;, &amp;quot;honesty.prune.leaves&amp;quot;), 
                               num.trees = 2000)
  saveRDS(forest.Y, &amp;quot;s7.rds&amp;quot;)
} else {forest.Y &amp;lt;- readRDS(&amp;quot;s7.rds&amp;quot;)}

Y.hat = predict(forest.Y)$predictions&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;grfselect-variables-that-predict-y.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Grf:Select variables that predict Y.&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;forest.Y.varimp = variable_importance(forest.Y)
# Note: Forests may have a hard time when trained on very few variables
# (e.g., ncol(X) = 1, 2, or 3). We recommend not being too aggressive
# in selection.
selected.vars = which(forest.Y.varimp / mean(forest.Y.varimp) &amp;gt; 0.2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This selects five variables of 20. Indeed these are the variables that were used to simulate Y.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;grf-finally-fit-causal-forest-using-ps-and-selected-covariates&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Grf: Finally, Fit causal forest using PS and selected covariates&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if(fullrun){
tau.forest2 = causal_forest(X[, selected.vars], Y, W,
                           W.hat = W.hat, Y.hat = Y.hat,
                           tune.parameters = c(&amp;quot;min.node.size&amp;quot;, &amp;quot;honesty.prune.leaves&amp;quot;), 
                           num.trees = 4000)
  saveRDS(tau.forest2, &amp;quot;s8.rds&amp;quot;)
} else {tau.forest2 &amp;lt;- readRDS(&amp;quot;s8.rds&amp;quot;)}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;grf-check-fit-and-cis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Grf: Check fit and CI&#39;s&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_sep2 &amp;lt;- CalcPredictionsGRF(df_sep4[,selected.vars], tau.forest2)

grfp &amp;lt;- ggplot(df_sep2, aes(x = X3, y = qm))   +
  geom_linerange(aes(ymin = ql, ymax = qu), col = &amp;quot;grey&amp;quot;) + geom_point() + 
  geom_smooth() + 
  geom_line(aes(y = TAU), col = &amp;quot;red&amp;quot;, size = 1) + ylim(-0.7,2)

grfp&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;gam&amp;#39; and formula &amp;#39;y ~ s(x, bs = &amp;quot;cs&amp;quot;)&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bart_vs_grf/BART-vs-grf_files/figure-html/unnamed-chunk-37-1.png&#34; width=&#34;672&#34; /&gt; This looks ok.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-bart-on-this-dataset-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fit BART on this dataset&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x.train &amp;lt;- model.matrix(~. ,data.frame(W, X))
x.test &amp;lt;- model.matrix(~. ,data.frame(W = 1 - W, X))
y.train &amp;lt;- Y

if(fullrun){
  bartFit &amp;lt;- bart(x.train, y.train, x.test, ntree = 4000)
  saveRDS(bartFit, &amp;quot;s9.rds&amp;quot;)
} else {bartFit &amp;lt;- readRDS(&amp;quot;s9.rds&amp;quot;)}
plot(bartFit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bart_vs_grf/BART-vs-grf_files/figure-html/unnamed-chunk-38-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bart-check-fit-and-cis-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;BART: Check fit and CI&#39;s&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#source(&amp;quot;calcPosteriors.R&amp;quot;)
sim &amp;lt;- CalcPosteriorsBART(df_sep4, bartFit, treatname = &amp;quot;W&amp;quot;)


bartp &amp;lt;- ggplot(sim, aes(x = X3, qm)) + geom_linerange(aes(ymin = ql, ymax = qu), col = &amp;quot;grey&amp;quot;) +
  geom_point() + geom_smooth() +
  geom_line(aes(y = TAU), col = &amp;quot;red&amp;quot;, size = 1) + ylim(-0.7,2)

bartp&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;gam&amp;#39; and formula &amp;#39;y ~ s(x, bs = &amp;quot;cs&amp;quot;)&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bart_vs_grf/BART-vs-grf_files/figure-html/unnamed-chunk-39-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;compare-bart-and-grf&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Compare BART and grf&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gp &amp;lt;- plot_grid(bartp, grfp)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;gam&amp;#39; and formula &amp;#39;y ~ s(x, bs = &amp;quot;cs&amp;quot;)&amp;#39;
## `geom_smooth()` using method = &amp;#39;gam&amp;#39; and formula &amp;#39;y ~ s(x, bs = &amp;quot;cs&amp;quot;)&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gp&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bart_vs_grf/BART-vs-grf_files/figure-html/unnamed-chunk-40-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Very similar results. BART appears slightly more accurate, especially for low values of X3.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
